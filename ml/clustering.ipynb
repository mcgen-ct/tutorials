{
 "nbformat": 4,
 "metadata": {
  "language_info": {
   "pygments_lexer": "ipython3",
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "version": 3,
    "name": "ipython"
   },
   "nbconvert_exporter": "python",
   "version": "3.10.12",
   "name": "python"
  },
  "colab": {
   "provenance": [],
   "collapsed_sections": [
    "Simple_ML_introducion",
    "Introduction",
    "Clustering",
    "Jet_Clustering",
    "Density_Estimation"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat_minor": 5,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Simple ML introducion\n",
    "\n",
    "Written by:\n",
    "- Manuel Szewc (School of Physics, University of Cincinnati)\n",
    "- Philip Ilten (School of Physics, University of Cincinnati)\n",
    "$\\renewcommand{\\gtrsim}{\\raisebox{-2mm}{\\hspace{1mm}$\\stackrel{>}{\\sim}$\\hspace{1mm}}}\\renewcommand{\\lessim}{\\raisebox{-2mm}{\\hspace{1mm}$\\stackrel{<}{\\sim}$\\hspace{1mm}}}\\renewcommand{\\as}{\\alpha_{\\mathrm{s}}}\\renewcommand{\\aem}{\\alpha_{\\mathrm{em}}}\\renewcommand{\\kT}{k_{\\perp}}\\renewcommand{\\pT}{p_{\\perp}}\\renewcommand{\\pTs}{p^2_{\\perp}}\\renewcommand{\\pTe}{\\p_{\\perp\\mrm{evol}}}\\renewcommand{\\pTse}{\\p^2_{\\perp\\mrm{evol}}}\\renewcommand{\\pTmin}{p_{\\perp\\mathrm{min}}}\\renewcommand{\\pTsmim}{p^2_{\\perp\\mathrm{min}}}\\renewcommand{\\pTmax}{p_{\\perp\\mathrm{max}}}\\renewcommand{\\pTsmax}{p^2_{\\perp\\mathrm{max}}}\\renewcommand{\\pTL}{p_{\\perp\\mathrm{L}}}\\renewcommand{\\pTD}{p_{\\perp\\mathrm{D}}}\\renewcommand{\\pTA}{p_{\\perp\\mathrm{A}}}\\renewcommand{\\pTsL}{p^2_{\\perp\\mathrm{L}}}\\renewcommand{\\pTsD}{p^2_{\\perp\\mathrm{D}}}\\renewcommand{\\pTsA}{p^2_{\\perp\\mathrm{A}}}\\renewcommand{\\pTo}{p_{\\perp 0}}\\renewcommand{\\shat}{\\hat{s}}\\renewcommand{\\a}{{\\mathrm a}}\\renewcommand{\\b}{{\\mathrm b}}\\renewcommand{\\c}{{\\mathrm c}}\\renewcommand{\\d}{{\\mathrm d}}\\renewcommand{\\e}{{\\mathrm e}}\\renewcommand{\\f}{{\\mathrm f}}\\renewcommand{\\g}{{\\mathrm g}}\\renewcommand{\\hrm}{{\\mathrm h}}\\renewcommand{\\lrm}{{\\mathrm l}}\\renewcommand{\\n}{{\\mathrm n}}\\renewcommand{\\p}{{\\mathrm p}}\\renewcommand{\\q}{{\\mathrm q}}\\renewcommand{\\s}{{\\mathrm s}}\\renewcommand{\\t}{{\\mathrm t}}\\renewcommand{\\u}{{\\mathrm u}}\\renewcommand{\\A}{{\\mathrm A}}\\renewcommand{\\B}{{\\mathrm B}}\\renewcommand{\\D}{{\\mathrm D}}\\renewcommand{\\F}{{\\mathrm F}}\\renewcommand{\\H}{{\\mathrm H}}\\renewcommand{\\J}{{\\mathrm J}}\\renewcommand{\\K}{{\\mathrm K}}\\renewcommand{\\L}{{\\mathrm L}}\\renewcommand{\\Q}{{\\mathrm Q}}\\renewcommand{\\R}{{\\mathrm R}}\\renewcommand{\\T}{{\\mathrm T}}\\renewcommand{\\W}{{\\mathrm W}}\\renewcommand{\\Z}{{\\mathrm Z}}\\renewcommand{\\bbar}{\\overline{\\mathrm b}}\\renewcommand{\\cbar}{\\overline{\\mathrm c}}\\renewcommand{\\dbar}{\\overline{\\mathrm d}}\\renewcommand{\\fbar}{\\overline{\\mathrm f}}\\renewcommand{\\pbar}{\\overline{\\mathrm p}}\\renewcommand{\\qbar}{\\overline{\\mathrm q}}\\renewcommand{\\rbar}{\\overline{\\mathrm{r}}}\\renewcommand{\\sbar}{\\overline{\\mathrm s}}\\renewcommand{\\tbar}{\\overline{\\mathrm t}}\\renewcommand{\\ubar}{\\overline{\\mathrm u}}\\renewcommand{\\Bbar}{\\overline{\\mathrm B}}\\renewcommand{\\Fbar}{\\overline{\\mathrm F}}\\renewcommand{\\Qbar}{\\overline{\\mathrm Q}}\\renewcommand{\\tms}{{t_{\\mathrm{\\tiny MS}}}}\\renewcommand{\\Oas}[1]{{\\mathcal{O}\\left(\\as^{#1}\\right)}}$"
   ],
   "metadata": {
    "id": "Simple_ML_introducion"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introduction"
   ],
   "metadata": {
    "id": "Introduction"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This notebook wants to implement simple Machine Learning algorithms"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "# To generate data and handle arrays\n",
    "import numpy as np\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "mpl.rc(\"axes\", labelsize=14)\n",
    "mpl.rc(\"xtick\", labelsize=12)\n",
    "mpl.rc(\"ytick\", labelsize=12)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Clustering"
   ],
   "metadata": {
    "id": "Clustering"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "gt_center = np.array([[3.0, 3.0], [-3.0, -3.0], [-3.0, 3.0], [3.0, -3.0]])\n",
    "X, t = make_blobs(\n",
    "    1000,\n",
    "    n_features=2,\n",
    "    centers=gt_center,\n",
    "    cluster_std=1.0,\n",
    "    random_state=1234,\n",
    ")"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "plt.scatter(X[t == 0, 0], X[t == 0, 1], c=\"red\", label=\"$C_{0}$\")\n",
    "plt.scatter(X[t == 1, 0], X[t == 1, 1], c=\"blue\", label=\"$C_{1}$\")\n",
    "plt.scatter(X[t == 2, 0], X[t == 2, 1], c=\"limegreen\", label=\"$C_{2}$\")\n",
    "plt.scatter(X[t == 3, 0], X[t == 3, 1], c=\"salmon\", label=\"$C_{3}$\")\n",
    "\n",
    "plt.legend(loc=\"upper left\")"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c=\"black\", label=\"Data\")\n",
    "\n",
    "plt.legend(loc=\"upper left\")"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "class KMeansClustering:\n",
    "    def __init__(self, nclasses=2, ndim=2, scale_init=5, mean_init=0, seed=42):\n",
    "        np.random.seed(seed)\n",
    "        self.nclasses = nclasses\n",
    "        self.ndim = ndim\n",
    "        self.means = mean_init + scale_init * np.random.randn(nclasses, ndim)\n",
    "\n",
    "    def fit(self, X, nepochs=10, min_change=0.01):\n",
    "        for nepoch in range(nepochs):\n",
    "            indexes = self.class_assigner(X)\n",
    "            for nclass in range(self.nclasses):\n",
    "                self.means[nclass] = np.sum(X[indexes == nclass], 0) / np.sum(\n",
    "                    indexes == nclass\n",
    "                )\n",
    "        return self\n",
    "\n",
    "    def class_assigner(self, X):\n",
    "        distances = np.sum((X[:, np.newaxis] - self.means[np.newaxis]) ** 2, 2)\n",
    "        indexes = np.argmin(distances, 1)\n",
    "        return indexes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "clusterer = KMeansClustering(nclasses=4, seed=42)\n",
    "clusterer.fit(X)\n",
    "labels = clusterer.class_assigner(X)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "plt.scatter(X[labels == 0, 0], X[labels == 0, 1], c=\"red\", label=\"$C_{0}$\")\n",
    "plt.scatter(X[labels == 1, 0], X[labels == 1, 1], c=\"blue\", label=\"$C_{1}$\")\n",
    "plt.scatter(X[labels == 2, 0], X[labels == 2, 1], c=\"limegreen\", label=\"$C_{2}$\")\n",
    "plt.scatter(X[labels == 3, 0], X[labels == 3, 1], c=\"salmon\", label=\"$C_{3}$\")\n",
    "\n",
    "plt.legend(loc=\"upper left\")"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Jet Clustering"
   ],
   "metadata": {
    "id": "Jet_Clustering"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Density Estimation"
   ],
   "metadata": {
    "id": "Density_Estimation"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Gaussian mixture"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "gt_center = np.array([[3.0, 3.0], [-3.0, -3.0], [-3.0, 3.0], [3.0, -3.0]])\n",
    "X, t = make_blobs(\n",
    "    1000,\n",
    "    n_features=2,\n",
    "    centers=gt_center,\n",
    "    cluster_std=1.0,\n",
    "    random_state=1234,\n",
    ")"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "plt.scatter(X[t == 0, 0], X[t == 0, 1], c=\"red\", label=\"$C_{0}$\")\n",
    "plt.scatter(X[t == 1, 0], X[t == 1, 1], c=\"blue\", label=\"$C_{1}$\")\n",
    "plt.scatter(X[t == 2, 0], X[t == 2, 1], c=\"limegreen\", label=\"$C_{2}$\")\n",
    "plt.scatter(X[t == 3, 0], X[t == 3, 1], c=\"salmon\", label=\"$C_{3}$\")\n",
    "\n",
    "plt.legend(loc=\"upper left\")"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c=\"black\", label=\"Data\")\n",
    "\n",
    "plt.legend(loc=\"upper left\")"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "class GaussianMixtureModel:\n",
    "    def __init__(\n",
    "        self, nclasses=2, ndim=2, scale_init=5, mean_init=0, epsilon=1e-10, seed=42\n",
    "    ):\n",
    "        np.random.seed(seed)\n",
    "        self.nclasses = nclasses\n",
    "        self.ndim = ndim\n",
    "        self.w = np.ones(self.nclasses) / self.nclasses\n",
    "        self.means = mean_init + scale_init * np.random.randn(nclasses, ndim)\n",
    "        self.covs = np.array([np.eye(self.ndim) for _ in range(self.nclasses)])\n",
    "        self.precision_matrix = np.array(\n",
    "            [np.eye(self.ndim) for _ in range(self.nclasses)]\n",
    "        )\n",
    "        self.epsilon = epsilon * np.array(\n",
    "            [np.eye(self.ndim) for _ in range(self.nclasses)]\n",
    "        )\n",
    "\n",
    "    def fit(self, X, nepochs=10, min_change=0.01):\n",
    "        log_likelihood = self.log_likelihood(X)\n",
    "        for nepoch in range(nepochs):\n",
    "            probas = self.E_step(X)\n",
    "            self.M_step(X, probas)\n",
    "            self.precision_matrix = np.linalg.inv(self.covs + self.epsilon)\n",
    "            log_likelihood_new = self.log_likelihood(X)\n",
    "            # if log_likelihood_new < (1.0+min_change)*log_likelihood:\n",
    "            #     break\n",
    "            log_likelihood = log_likelihood_new\n",
    "        # print(nepoch)\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        ### get likelihoods\n",
    "        likelihood = self.gaussian_likelihood(X)\n",
    "        ### reweight using weights\n",
    "        weighted_likelihood = np.einsum(\"nk, k -> nk\", likelihood, self.w)\n",
    "        ### normalize\n",
    "        probas = np.einsum(\n",
    "            \"nk,n -> nk\", weighted_likelihood, 1 / np.sum(weighted_likelihood, 1)\n",
    "        )\n",
    "        return probas\n",
    "\n",
    "    def predict(self, X):\n",
    "        ### get likelihoods\n",
    "        likelihood = self.gaussian_likelihood(X)\n",
    "        ### reweight using weights\n",
    "        weighted_likelihood = np.einsum(\"nk, k -> nk\", likelihood, self.w)\n",
    "        ### normalize\n",
    "        probas = np.einsum(\n",
    "            \"nk,n -> nk\", weighted_likelihood, 1 / np.sum(weighted_likelihood, 1)\n",
    "        )\n",
    "        return np.argmin(probas, 1)\n",
    "\n",
    "    def gaussian_likelihood(self, X):\n",
    "        ### distance vector is NxKxD\n",
    "        distance_vector = X[:, np.newaxis] - self.means[np.newaxis]\n",
    "        ### weighted distance for denominator, now it's NxK\n",
    "        weighted_distance = np.einsum(\n",
    "            \"nki, kij, nkj -> nk\",\n",
    "            distance_vector,\n",
    "            self.precision_matrix,\n",
    "            distance_vector,\n",
    "        )\n",
    "        ### likelihood per event per class\n",
    "        likelihood = np.einsum(\n",
    "            \"k,nk -> nk\",\n",
    "            (np.power(2 * np.pi, -self.ndim / 2))\n",
    "            * (1.0 / np.sqrt(np.linalg.det(self.covs))),\n",
    "            np.exp(-0.5 * weighted_distance),\n",
    "        )\n",
    "        return likelihood\n",
    "\n",
    "    def E_step(self, X):\n",
    "        probas = self.predict_proba(X)\n",
    "        return probas\n",
    "\n",
    "    def M_step(self, X, probas):\n",
    "        Nk = np.sum(probas, 0)\n",
    "        self.w = Nk / len(X)\n",
    "        self.means = np.einsum(\"nk, nd, k -> kd\", probas, X, 1 / Nk)\n",
    "        distance_vector = X[:, np.newaxis] - self.means[np.newaxis]\n",
    "        self.covs = np.einsum(\n",
    "            \"nk, nki, nkj, k -> kij\", probas, distance_vector, distance_vector, 1 / Nk\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def log_likelihood(self, X):\n",
    "        ### get likelihoods\n",
    "        likelihood = self.gaussian_likelihood(X)\n",
    "        ### reweight using weights\n",
    "        weighted_likelihood = np.einsum(\"nk, k -> nk\", likelihood, self.w)\n",
    "        return np.sum(np.log(np.sum(weighted_likelihood, 1)))"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "gmm = GaussianMixtureModel(nclasses=4, ndim=2, seed=156)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "gmm.means.shape, gmm.covs.shape"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "gmm.predict(X)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "gmm.log_likelihood(X)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "gmm.fit(X, nepochs=100, min_change=1)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "gmm.w"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "gmm.means"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "gmm.covs[0]"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "gmm.precision_matrix[0]"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "probas = gmm.predict_proba(X)\n",
    "labels = np.argmin(probas, 1)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "plt.scatter(X[labels == 0, 0], X[labels == 0, 1], c=\"red\", label=\"$C_{0}$\")\n",
    "plt.scatter(X[labels == 1, 0], X[labels == 1, 1], c=\"blue\", label=\"$C_{1}$\")\n",
    "plt.scatter(X[labels == 2, 0], X[labels == 2, 1], c=\"limegreen\", label=\"$C_{2}$\")\n",
    "plt.scatter(X[labels == 3, 0], X[labels == 3, 1], c=\"salmon\", label=\"$C_{3}$\")\n",
    "\n",
    "plt.legend(loc=\"upper left\")"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Seed dependence"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "nmodels = 100\n",
    "log_likelihoods = np.zeros(nmodels)\n",
    "seeds = np.zeros(nmodels)\n",
    "nmodel = 0\n",
    "nmodel_accepted = 0\n",
    "while nmodel_accepted < nmodels:\n",
    "    gmm = GaussianMixtureModel(nclasses=4, ndim=2, seed=nmodel)\n",
    "    gmm.fit(X, nepochs=100)\n",
    "    log_likelihood = gmm.log_likelihood(X)\n",
    "    if np.isnan(log_likelihood) == False:\n",
    "        log_likelihoods[nmodel_accepted] = log_likelihood\n",
    "        seeds[nmodel_accepted] = nmodel\n",
    "        nmodel_accepted += 1\n",
    "        nmodel += 1\n",
    "    else:\n",
    "        nmodel += 1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "np.isnan(log_likelihoods[0])"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "plt.hist(log_likelihoods)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "np.argmax(log_likelihoods)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "best_model = GaussianMixtureModel(\n",
    "    nclasses=4, ndim=2, seed=int(seeds[np.argmax(log_likelihoods)])\n",
    ")\n",
    "best_model.fit(X, nepochs=100)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "best_model.w, best_model.means, best_model.covs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "probas = best_model.predict_proba(X)\n",
    "labels = np.argmin(probas, 1)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "plt.scatter(X[labels == 0, 0], X[labels == 0, 1], c=\"red\", label=\"$C_{0}$\")\n",
    "plt.scatter(X[labels == 1, 0], X[labels == 1, 1], c=\"blue\", label=\"$C_{1}$\")\n",
    "plt.scatter(X[labels == 2, 0], X[labels == 2, 1], c=\"limegreen\", label=\"$C_{2}$\")\n",
    "plt.scatter(X[labels == 3, 0], X[labels == 3, 1], c=\"salmon\", label=\"$C_{3}$\")\n",
    "\n",
    "plt.legend(loc=\"upper left\")"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "x1vals = np.linspace(0.99 * np.min(X[:, 0]), 1.01 * np.max(X[:, 0]), 1000)\n",
    "x2vals = np.linspace(0.99 * np.min(X[:, 1]), 1.01 * np.max(X[:, 1]), 1000)\n",
    "X1, X2 = np.meshgrid(x1vals, x2vals)\n",
    "Xvals = np.array([X1.ravel(), X2.ravel()]).T\n",
    "Z = best_model.predict(Xvals).reshape(X1.shape)\n",
    "plt.contourf(\n",
    "    X1,\n",
    "    X2,\n",
    "    Z,\n",
    "    colors=[\"limegreen\", \"salmon\", \"red\", \"blue\"],\n",
    "    levels=[-0.5, 0.5, 1.5, 2.5, 3.5],\n",
    "    alpha=0.25,\n",
    ")\n",
    "plt.colorbar()\n",
    "plt.scatter(X[t == 0, 0], X[t == 0, 1], c=\"red\", label=\"$C_{0}$\")\n",
    "plt.scatter(X[t == 1, 0], X[t == 1, 1], c=\"blue\", label=\"$C_{1}$\")\n",
    "plt.scatter(X[t == 2, 0], X[t == 2, 1], c=\"limegreen\", label=\"$C_{2}$\")\n",
    "plt.scatter(X[t == 3, 0], X[t == 3, 1], c=\"salmon\", label=\"$C_{3}$\")\n",
    "plt.tight_layout()\n",
    "plt.legend(loc=\"center\")"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {}
  }
 ]
}