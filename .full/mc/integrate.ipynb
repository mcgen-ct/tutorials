{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Integration_and_Sampling"
   },
   "source": [
    "# Integration and Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we first investigate sampling random numbers other than uniform, and then use random number sampling to calculate integrals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Requirements"
   },
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a random number generator. We could use one of the RNGs implemented in [`rng.ipynb`](rng.ipynb), but instead we will use the default `numpy` RNG. We also need the `math` module and `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the `numpy` and `math` modules.\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Import the `matplotlib` module.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create an RNG, with a seed of 10.\n",
    "rng = np.random.default_rng(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Introduction"
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typical events produced within the Large Hadron Collider (LHC) from colliding protons have $\\mathcal{O}(100)$ or more particles produced. When calculating a cross-section for a two-to-two process we typically only need to integrate over two variables, $\\theta$ and $\\phi$. A two-to-$n$ process requires integrating over $3n -4$ variables, so a typical LHC event would require integrating over $\\mathcal{O}(300)$ variables. This is numerically challenging, at best, and with current technology is just simply not possible. To calcululate LHC events, we can instead factorise the problem into more manageable parts using probabilistic methods. Even still, calculating a perturbative cross-section for a $4$-body final state requires integrating over $8$ variables which is a challenging numerical integration. The bottom line is that performing high dimension integrals quickly and efficiently is a core problem in particle physic, and is very numerically challenging.\n",
    "\n",
    "However, before we tackle integration with MC, we need to first discuss how we can efficiently sample distributions. In the [`rng.ipynb`](mc/rng.ipynb) notebook, we have hard to make a good generator for uniformly-distributed random variates. In practice, however, the probability distributions of interest are not uniform. Fortunately, uniform random variates can either be transformed into a different distribution or used as part of an accept/reject algorithm that converges to the desired probability distribution. Random variates -- uniform or not -- are also a primary part of the Monte Carlo integration method, so it is worthwhile to know how to transform uniform into complicated.\n",
    "\n",
    "In this notebook, we only consider continous distributions, but everything that we say can be applied, with some modification, to discrete distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Analytic_Sampling"
   },
   "source": [
    "## Analytic Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analytic, or inverse cumulative distribution function (CDF) sampling allows us to transform a uniform distribution into our target distribution, $f(x)$. However, this is not possible for every $f(x)$. To sample $f(x)$ the following must generally be fulfilled.\n",
    "\n",
    "1. The sampling of $f(x)$ is bounded, where over this range $f(x)$ is positive.\n",
    "\n",
    "$$\n",
    "f(x) \\geq 0 \\text{ for } x_\\min < x < x_\\max\n",
    "$$\n",
    "\n",
    "2. The integral of $f(x)$ can be calculated.\n",
    "\n",
    "$$\n",
    "F(x) = \\int \\text{d}x\\, f(x)\n",
    "$$\n",
    "\n",
    "3. The integral of $f(x)$ can be inverted, which we label $F^{-1}(x)$.\n",
    "\n",
    "With these three conditions met we can then sample a distribution for $f(x)$ as follows. First, we can consider integrating a distribution from $x_\\min$ to $x$, as shown in the figure below.\n",
    "\n",
    "![Schematic of analytic sampling.](https://github.com/mcgen-ct/tutorials/blob/main/.full/mc/figures/sample_analytic.png?raw=1)\n",
    "\n",
    "We then draw a uniform random number $R$ which gives us the following relation.\n",
    "\n",
    "$$\n",
    "\\int_{x_{\\min}}^x \\text{d}x'\\, f(x') = R \\int_{x_{\\min}}^{x_{\\max}} \\text{d}{x'}\\, f(x')\n",
    "$$\n",
    "\n",
    "We then perform the integration, where $F(x)$ is the indefinite integral of $f(x)$.\n",
    "\n",
    "$$\n",
    "F(x) - F(x_{\\min}) = R(F(x_\\max) - F(x_\\min))\n",
    "$$\n",
    "\n",
    "We can then write $F(x_\\max) - F(x_\\min)$ as $A$, the area under the integral.\n",
    "$$\n",
    "F(x) - F(x_{\\min}) = R A\n",
    "$$\n",
    "\n",
    "We then solve for $x$.\n",
    "\n",
    "$$\n",
    "x = F^{-1}(F(x_{\\min}) + R A)\n",
    "$$\n",
    "\n",
    "So, we can uniformly sample $R$ and then use the final relation to transform this into $x$, as sampled from $f(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Exercise:_generic_sampler"
   },
   "source": [
    "### Exercise: generic sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we try to generate any specific distributions using this method, let us first set up a generic sampler class which uses the steps above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "class SampleAnalytic:\n",
    "    \"\"\"\n",
    "    Base class to analytically sample a distribution from a random\n",
    "    distribution.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rng, xmin, xmax):\n",
    "        \"\"\"\n",
    "        Initialize the sampler, given the limits on f(x).\n",
    "\n",
    "        rng:  uniform random number generator, should have method `uniform()`.\n",
    "        xmin: lower bound of the sampling region.\n",
    "        xmax: upper bound of the sampling region.\n",
    "        \"\"\"\n",
    "        self.rng = rng\n",
    "        self.xmin = xmin\n",
    "        self.xmax = xmax\n",
    "        self.F_xmin = self.F(xmin)\n",
    "        self.area = self.F(xmax) - self.F(xmin)\n",
    "\n",
    "    def f(self, x):\n",
    "        \"\"\"\n",
    "        Return the function being sampled, f(x). This method is not necessary,\n",
    "        but very useful for importance sampling and checking the distribution.\n",
    "\n",
    "        x: value to calculate f(x) for.\n",
    "        \"\"\"\n",
    "        # Implment f(x) here.\n",
    "        return 0.0\n",
    "\n",
    "    def F(self, x):\n",
    "        \"\"\"\n",
    "        Returns F(x), the indefinite integral for f(x).\n",
    "\n",
    "        x: value to calculate the indefinite integral for f(x).\n",
    "        \"\"\"\n",
    "        # Implement F(x) here.\n",
    "        return 0.0\n",
    "\n",
    "    def F_inv(self, f):\n",
    "        \"\"\"\n",
    "        Returns the inverse of the F(x).\n",
    "\n",
    "        F: the value of F(x) to calculate the inverse.\n",
    "        \"\"\"\n",
    "        # Implement F^-1(x) here.\n",
    "        return 0.0\n",
    "\n",
    "    def __call__(self):\n",
    "        \"\"\"\n",
    "        Return the sampled value.\n",
    "        \"\"\"\n",
    "        # Define the function from above that transforms a uniformly sampled\n",
    "        # random number to the desired distribution.\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "class SampleAnalytic:\n",
    "    \"\"\"\n",
    "    Base class to analytically sample a distribution from a random\n",
    "    distribution.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rng, xmin, xmax):\n",
    "        \"\"\"\n",
    "        Initialize the sampler, given the limits on f(x).\n",
    "\n",
    "        rng:  uniform random number generator, should have method `uniform()`.\n",
    "        xmin: lower bound of the sampling region.\n",
    "        xmax: upper bound of the sampling region.\n",
    "        \"\"\"\n",
    "        self.rng = rng\n",
    "        self.xmin = xmin\n",
    "        self.xmax = xmax\n",
    "        self.F_xmin = self.F(xmin)\n",
    "        self.area = self.F(xmax) - self.F(xmin)\n",
    "\n",
    "    def f(self, x):\n",
    "        \"\"\"\n",
    "        Return the function being sampled, f(x). This method is not necessary,\n",
    "        but very useful for importance sampling and checking the distribution.\n",
    "\n",
    "        x: value to calculate f(x) for.\n",
    "        \"\"\"\n",
    "        return 0.0\n",
    "\n",
    "    def F(self, x):\n",
    "        \"\"\"\n",
    "        Returns F(x), the indefinite integral for f(x).\n",
    "\n",
    "        x: value to calculate the indefinite integral for f(x).\n",
    "        \"\"\"\n",
    "        return 0.0\n",
    "\n",
    "    def F_inv(self, f):\n",
    "        \"\"\"\n",
    "        Returns the inverse of the F(x).\n",
    "\n",
    "        F: the value of F(x) to calculate the inverse.\n",
    "        \"\"\"\n",
    "        return 0.0\n",
    "\n",
    "    def __call__(self):\n",
    "        \"\"\"\n",
    "        Return the sampled value.\n",
    "        \"\"\"\n",
    "        # Sample the uniform random number.\n",
    "        r = self.rng.uniform()\n",
    "        return self.F_inv(self.F_xmin + r * self.area)\n",
    "\n",
    "\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Exercise:_linear_function"
   },
   "source": [
    "### Exercise: linear function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample from a linear distribution with the following form.\n",
    "\n",
    "$$\n",
    "f(x) = mx + b\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "class SampleLinear(SampleAnalytic):\n",
    "    \"\"\"\n",
    "    Class to analytically sample a linear function.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rng, xmin, xmax, m, b):\n",
    "        \"\"\"\n",
    "        Initialize the sampler, given the limits on f(x) and the linear\n",
    "        parameters.\n",
    "\n",
    "        f(x) = mx + b\n",
    "\n",
    "        rng:  uniform random number generator, should have method `uniform()`.\n",
    "        xmin: lower bound of the sampling region.\n",
    "        xmax: upper bound of the sampling region.\n",
    "        m:    slope of the linear distribution.\n",
    "        b:    intercept of the linear distribution.\n",
    "        \"\"\"\n",
    "        # Set the linear parameters. This must be done before the base class\n",
    "        # is initialized.\n",
    "        # Initialize the base class.\n",
    "\n",
    "    def f(self, x):\n",
    "        \"\"\"\n",
    "        Return the function being sampled, f(x).\n",
    "\n",
    "        x: value to calculate f(x) for.\n",
    "        \"\"\"\n",
    "        return 0.0\n",
    "\n",
    "    def F(self, x):\n",
    "        \"\"\"\n",
    "        Returns F(x), the indefinite integral for f(x).\n",
    "\n",
    "        x: value to calculate the indefinite integral for f(x).\n",
    "        \"\"\"\n",
    "        return 0.0\n",
    "\n",
    "    def F_inv(self, f):\n",
    "        \"\"\"\n",
    "        Returns the inverse of the F(x).\n",
    "\n",
    "        F: the value of F(x) to calculate the inverse.\n",
    "        \"\"\"\n",
    "        # Handle the special case of no slope.\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "class SampleLinear(SampleAnalytic):\n",
    "    \"\"\"\n",
    "    Class to analytically sample a linear function.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rng, xmin, xmax, m, b):\n",
    "        \"\"\"\n",
    "        Initialize the sampler, given the limits on f(x) and the linear\n",
    "        parameters.\n",
    "\n",
    "        f(x) = mx + b\n",
    "\n",
    "        rng:  uniform random number generator, should have method `uniform()`.\n",
    "        xmin: lower bound of the sampling region.\n",
    "        xmax: upper bound of the sampling region.\n",
    "        m:    slope of the linear distribution.\n",
    "        b:    intercept of the linear distribution.\n",
    "        \"\"\"\n",
    "        # Set the linear parameters. This must be done before the base class\n",
    "        # is initialized.\n",
    "        self.m = m\n",
    "        self.b = b\n",
    "        # Initialize the base class.\n",
    "        super().__init__(rng, xmin, xmax)\n",
    "\n",
    "    def f(self, x):\n",
    "        \"\"\"\n",
    "        Return the function being sampled, f(x).\n",
    "\n",
    "        x: value to calculate f(x) for.\n",
    "        \"\"\"\n",
    "        return self.m * x + self.b\n",
    "\n",
    "    def F(self, x):\n",
    "        \"\"\"\n",
    "        Returns F(x), the indefinite integral for f(x).\n",
    "\n",
    "        x: value to calculate the indefinite integral for f(x).\n",
    "        \"\"\"\n",
    "        return self.m * x**2 / 2 + self.b * x\n",
    "\n",
    "    def F_inv(self, f):\n",
    "        \"\"\"\n",
    "        Returns the inverse of the F(x).\n",
    "\n",
    "        F: the value of F(x) to calculate the inverse.\n",
    "        \"\"\"\n",
    "        # Handle the special case of no slope.\n",
    "        if self.m == 0:\n",
    "            return f / self.b\n",
    "        else:\n",
    "            return abs(((self.b**2 + 2 * self.m * f) ** 0.5 - self.b) / self.m)\n",
    "\n",
    "\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us test whether this sampler works for $m = 3$ and $b = 2$ between $0$ and $1$. We will want to test a number of distributions, so let us first write a little method that does just that. The following method plots the normalized sampled distribution and compares this to the normalized target function $f(x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sampler(sampler, n=100000, bins=50, points=1000):\n",
    "    \"\"\"\n",
    "    Plots the distribution from a sampler for a specific distribution.\n",
    "\n",
    "    sampler: random number sampler.\n",
    "    n:       number of points to sample.\n",
    "    bins:    number of bins in the histogram.\n",
    "    points:  number of points to evaluate for the function.\n",
    "    \"\"\"\n",
    "    # Sample the distribution.\n",
    "    rns = []\n",
    "    for i in range(0, n):\n",
    "        # Store the value.\n",
    "        rns += [sampler()]\n",
    "\n",
    "    # Calculate the target function.\n",
    "    xs = np.linspace(sampler.xmin, sampler.xmax, points)\n",
    "    fs = [sampler.f(x) / sampler.area for x in xs]\n",
    "\n",
    "    # Create the plot.\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Draw the histogram.\n",
    "    ax.hist(rns, bins=bins, density=True, label=\"generated\")\n",
    "\n",
    "    # Draw the target function, make sure to normalize.\n",
    "    ax.plot(xs, fs, label=\"target\")\n",
    "\n",
    "    # Draw the legend.\n",
    "    ax.legend()\n",
    "\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this method, test to see if the distribution being generated matches the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "# Create the sampler.\n",
    "\n",
    "# Call the `plot_sampler` method.\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "# Create the sampler.\n",
    "sampler = SampleLinear(rng, 0, 1, 3, 2)\n",
    "\n",
    "# Plot the comparison.\n",
    "plot_sampler(sampler);\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Exercise:_Breit-Wigner"
   },
   "source": [
    "### Exercise: Breit-Wigner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also known as a Cauchy distribution, the relativistic Breit-Wigner is of particular importance in particle physics because it can describe the distribution of masses for a specific particle type, e.g., a $Z$ boson. If we want to be able to efficiently sample a mass distribution, then we need to be able to sample a relativistic Breit-Wigner. The form of the function is as follows.\n",
    "\n",
    "$$\n",
    "f(x) = \\frac{1}{\\pi}\\left(\\frac{\\gamma}{(x - x_0)^2 + \\gamma^2}\\right)\n",
    "$$\n",
    "\n",
    "Rememner, the normalization of this function does not matter. In a particle physics context, $\\gamma$ is $M\\Gamma$ where $M$ is the mass of the particle and $\\Gamma$ is its width. Then, $x_0$ is $M$.\n",
    "\n",
    "Implement a sampler for the Breit-Wigner distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "class SampleCauchy(SampleAnalytic):\n",
    "    \"\"\"\n",
    "    Class to analytically sample a Cauchy function.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rng, xmin, xmax, x0, gamma):\n",
    "        \"\"\"\n",
    "        Initialize the sampler, given the limits on f(x) and the linear\n",
    "        parameters.\n",
    "\n",
    "        f(x) = 1/pi * (gamma/(x - x0)^2 + gamma^2)\n",
    "\n",
    "        rng:   uniform random number generator, should have method `uniform()`.\n",
    "        xmin:  lower bound of the sampling region.\n",
    "        xmax:  upper bound of the sampling region.\n",
    "        x0:    location parameter.\n",
    "        gamma: scale parameter.\n",
    "        \"\"\"\n",
    "        # Set the parameters.\n",
    "        # Initialize the base class.\n",
    "        super().__init__(rng, xmin, xmax)\n",
    "\n",
    "    def f(self, x):\n",
    "        \"\"\"\n",
    "        Return the function being sampled, f(x).\n",
    "\n",
    "        x: value to calculate f(x) for.\n",
    "        \"\"\"\n",
    "        return 0.0\n",
    "\n",
    "    def F(self, x):\n",
    "        \"\"\"\n",
    "        Returns F(x), the indefinite integral for f(x).\n",
    "\n",
    "        x: value to calculate the indefinite integral for f(x).\n",
    "        \"\"\"\n",
    "        return 0.0\n",
    "\n",
    "    def F_inv(self, f):\n",
    "        \"\"\"\n",
    "        Returns the inverse of the F(x).\n",
    "\n",
    "        F: the value of F(x) to calculate the inverse.\n",
    "        \"\"\"\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "class SampleCauchy(SampleAnalytic):\n",
    "    \"\"\"\n",
    "    Class to analytically sample a Cauchy function.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rng, xmin, xmax, x0, gamma):\n",
    "        \"\"\"\n",
    "        Initialize the sampler, given the limits on f(x) and the linear\n",
    "        parameters.\n",
    "\n",
    "        f(x) = 1/pi * (gamma/(x - x0)^2 + gamma^2)\n",
    "\n",
    "        rng:   uniform random number generator, should have method `uniform()`.\n",
    "        xmin:  lower bound of the sampling region.\n",
    "        xmax:  upper bound of the sampling region.\n",
    "        x0:    location parameter.\n",
    "        gamma: scale parameter.\n",
    "        \"\"\"\n",
    "        # Set the parameters.\n",
    "        self.x0 = x0\n",
    "        self.gamma = gamma\n",
    "        # Initialize the base class.\n",
    "        super().__init__(rng, xmin, xmax)\n",
    "\n",
    "    def f(self, x):\n",
    "        \"\"\"\n",
    "        Return the function being sampled, f(x).\n",
    "\n",
    "        x: value to calculate f(x) for.\n",
    "        \"\"\"\n",
    "        return 1 / math.pi * self.gamma / ((x - self.x0) ** 2 + self.gamma**2)\n",
    "\n",
    "    def F(self, x):\n",
    "        \"\"\"\n",
    "        Returns F(x), the indefinite integral for f(x).\n",
    "\n",
    "        x: value to calculate the indefinite integral for f(x).\n",
    "        \"\"\"\n",
    "        return 1 / math.pi * math.atan((x - self.x0) / self.gamma) + 1 / 2\n",
    "\n",
    "    def F_inv(self, f):\n",
    "        \"\"\"\n",
    "        Returns the inverse of the F(x).\n",
    "\n",
    "        F: the value of F(x) to calculate the inverse.\n",
    "        \"\"\"\n",
    "        return self.x0 + self.gamma * math.tan(math.pi * (f - 1 / 2))\n",
    "\n",
    "\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check this distribution for a $\\gamma = 5$, $x_0 = 20$, and range of $0$ to $40$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "# Create the sampler.\n",
    "\n",
    "# Plot the comparison.\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "# Create the sampler.\n",
    "sampler = SampleCauchy(rng, 0, 40, 20, 5)\n",
    "\n",
    "# Plot the comparison.\n",
    "plot_sampler(sampler);\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Exercise:_Gaussian"
   },
   "source": [
    "### Exercise: Gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps one of the most sampled distributions out there is the Gaussian.\n",
    "\n",
    "$$\n",
    "f(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}e^{-(x-\\mu)^2/(2\\sigma^2)}\n",
    "$$\n",
    "\n",
    "As a matter of fact, the Gaussian is critical for many machine learning techniques. However, looking at the function above, it is clear that it is not possible to calculate a closed analytic form for either $F(x)$ or $F^{-1}(x)$. So, our analytic method from above fails. What do we do instead? One option is to numerically calculate the $F(x)$ and $F^{-1}(x)$, of which there are relatively efficient methods.\n",
    "\n",
    "However, it turns out there is a very clever transform that you can do, commonly called the Box-Muller transform. We won't go through the derivation here, but it has to do with relating Cartesian and polar coordinates. Anyhow, the method is as follows.\n",
    "\n",
    "1. Sample two random numbers $R_1$ and $R_2$.\n",
    "2. Transform these into two indepdent Gaussian distributed numbers $x_1$ and $x_2$ with the following.\n",
    "\n",
    "$$\n",
    "x_1 = \\sqrt{-2\\log(R_1)}\\cos(2\\pi R_2)\n",
    "$$\n",
    "\n",
    "$$\n",
    "x_2 = \\sqrt{-2\\log(R_1)}\\sin(2\\pi R_2)\n",
    "$$\n",
    "\n",
    "3. These $x$ are for a Gaussian with $\\mu = 0$ and $\\sigma = 1$, so they need to be muplitied by $\\sigma$ with $\\mu$ added on.\n",
    "\n",
    "What is great about this method is that not only is it simple and fast, it also is not bounded, which is required of the method we used above! Using this transformation, define a Gaussian sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "class SampleGaussian:\n",
    "    \"\"\"\n",
    "    Class to sample a Gaussian distribution.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rng, xmin, xmax, mu, sigma):\n",
    "        \"\"\"\n",
    "        Initialize the sampler. Note, the limits `xmin` and `xmax` here only\n",
    "        define the limits when used for drawing with the `plot_sampler` method.\n",
    "        Sampling is performed without any limits.\n",
    "\n",
    "        rng:   uniform random number generator, should have method `uniform()`.\n",
    "        xmin:  minimum x for plotting (not sampling).\n",
    "        xmax:  maximum x for plotting (not sampling).\n",
    "        mu:    mean of Gaussian.\n",
    "        sigma: width of Gaussian.\n",
    "        \"\"\"\n",
    "        # Set the parameters.\n",
    "        self.rng = rng\n",
    "        self.xmin = xmin\n",
    "        self.xmax = xmax\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "\n",
    "        # Set the area being sampled. This distribution is normalized.\n",
    "        self.area = 1\n",
    "\n",
    "    def f(self, x):\n",
    "        \"\"\"\n",
    "        Return the function being sampled, f(x).\n",
    "\n",
    "        x: value to calculate f(x) for.\n",
    "        \"\"\"\n",
    "        return (\n",
    "            1\n",
    "            / (2 * math.pi * self.sigma**2) ** 0.5\n",
    "            * math.exp(-((x - self.mu) ** 2) / (2 * self.sigma**2))\n",
    "        )\n",
    "\n",
    "    def __call__(self):\n",
    "        \"\"\"\n",
    "        Return the sampled value.\n",
    "        \"\"\"\n",
    "        # Sample the two uniform random numbers.\n",
    "        r1 = self.rng.uniform()\n",
    "        r2 = self.rng.uniform()\n",
    "        # Return only one of the two transformed values.\n",
    "        return (\n",
    "            self.sigma * (-2 * math.log(r1)) ** 0.5 * math.cos(2 * math.pi * r2)\n",
    "            + self.mu\n",
    "        )\n",
    "\n",
    "\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check this distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "# Create the sampler.\n",
    "\n",
    "# Plot the comparison.\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "# Create the sampler.\n",
    "sampler = SampleGaussian(rng, 0, 10, 5, 2)\n",
    "\n",
    "# Plot the comparison.\n",
    "plot_sampler(sampler);\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Binned_Sampling"
   },
   "source": [
    "## Binned Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea behind binned sampling is exactly the same as for analytic sampling, but rather than inverting the CDF analytically, we do it numerically. The idea is as follows. First, we create a binned probability distribution function (PDF).\n",
    "\n",
    "![Binned probability distribution function.](https://github.com/mcgen-ct/tutorials/blob/main/.full/mc/figures/sample_bin_pdf.png?raw=1)\n",
    "\n",
    "We can think of this as splitting $f(x)$ up into $g_i$ divisions (bins). Next, we create the CDF for this distribution. We can do this by creating a new histogram, where each entry is given by the sum of bins, up to that point.\n",
    "\n",
    "![Binned cumulative distribution function.](https://github.com/mcgen-ct/tutorials/blob/main/.full/mc/figures/sample_bin_cdf.png?raw=1)\n",
    "\n",
    "Finally, we invert this CDF by effectively swapping our bin edges $x$ for our function values $y$.\n",
    "\n",
    "![Inverted binned cumulative distribution function.](https://github.com/mcgen-ct/tutorials/blob/main/.full/mc/figures/sample_bin_icdf.png?raw=1)\n",
    "\n",
    "Let's now try to implement this type of sampling. The algorithm is then as follows.\n",
    "\n",
    "1. Sample a uniform random number $R$.\n",
    "2. Find the corresponding bin $i$ of $G^{-1}_i(x)$.\n",
    "3. Uniformly sample an $R$ between the bin edges, this is our transformed value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Example:_histograms"
   },
   "source": [
    "### Example: histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A key ingredient to binned sampling is the histogram, so we need to build a little histogram class. Below is an outline of how we can do this. Fill in the missing parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "class Histogram:\n",
    "    \"\"\"\n",
    "    Histogram for binned sampling.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, f, xmin, xmax, bins=50):\n",
    "        \"\"\"\n",
    "        Initialize the histogram.\n",
    "\n",
    "        f:     function to sample, should be callable, `f(x)`.\n",
    "        xmin:  minimum x value.\n",
    "        xman:  maximum x value.\n",
    "        nbins: number of bins.\n",
    "        \"\"\"\n",
    "        # Store the x minimum and maximum. Not necessary, but useful to\n",
    "        # keep track of.\n",
    "        self.xmin = xmin\n",
    "        self.xmax = xmax\n",
    "\n",
    "        # Define the histogram edges, use `numpy.linspace`.\n",
    "        self.edges = np.linspace(xmin, xmax, bins)\n",
    "\n",
    "        # Define the PDF and CDF.\n",
    "        self.pdf = []\n",
    "        self.cdf = []\n",
    "        pdf_sum = 0\n",
    "        for i, xmax in enumerate(self.edges[1:]):\n",
    "            # Calculate the PDF and append.\n",
    "\n",
    "            # Calculate the CDF and append.\n",
    "            pass\n",
    "\n",
    "        # We store the normalization for the PDF. This is just `pdf_sum` times\n",
    "        # bin width.\n",
    "\n",
    "        # The PDF is not yet a PDF, so we normalize it.\n",
    "\n",
    "        # The CDF is also not yet a CDF, so we normalize it.\n",
    "\n",
    "        # We now turn the CDF into edges for the inverse CDF, by prepending\n",
    "        # the CDF by 0, since the CDF must start at 0.\n",
    "\n",
    "    def bin(self, x, edges=None):\n",
    "        \"\"\"\n",
    "        Return the bin for a given x.\n",
    "\n",
    "        x:     value to find the bin for.\n",
    "        edges: optionally, edges of the histogram. The default is to use the\n",
    "               edges of the histogram. This allows us to use this method when\n",
    "               finding the bin for the inverse CDF.\n",
    "        \"\"\"\n",
    "        # If no edges are provided, default to `self.edges`.\n",
    "\n",
    "        # Loop over the edges. Skip the\n",
    "        for bin, edge in enumerate(edges[1:]):\n",
    "            # Return if `x` is less than the edge.\n",
    "            # For underflow, just return the first bin.\n",
    "            pass\n",
    "\n",
    "        # If overflow, just return the last bin.\n",
    "\n",
    "    def bin_icdf(self, r):\n",
    "        \"\"\"\n",
    "        Return the bin from the inverse CDF.\n",
    "        \"\"\"\n",
    "        # Set the `edges` argument to `self.edges_icdf` and use the `bin`\n",
    "        # method.\n",
    "        return self.bin(r, self.edges_icdf)\n",
    "\n",
    "\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "class Histogram:\n",
    "    \"\"\"\n",
    "    Histogram for binned sampling.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, f, xmin, xmax, bins=50):\n",
    "        \"\"\"\n",
    "        Initialize the histogram.\n",
    "\n",
    "        f:     function to sample, should be callable, `f(x)`.\n",
    "        xmin:  minimum x value.\n",
    "        xman:  maximum x value.\n",
    "        nbins: number of bins.\n",
    "        \"\"\"\n",
    "        # Store the x minimum and maximum. Not necessary, but useful to\n",
    "        # keep track of.\n",
    "        self.xmin = xmin\n",
    "        self.xmax = xmax\n",
    "\n",
    "        # Define the histogram edges, use `numpy.linspace`.\n",
    "        self.edges = np.linspace(xmin, xmax, bins)\n",
    "\n",
    "        # Define the PDF and CDF.\n",
    "        self.pdf = []\n",
    "        self.cdf = []\n",
    "        pdf_sum = 0\n",
    "        for i, xmax in enumerate(self.edges[1:]):\n",
    "            # Calculate the PDF and append.\n",
    "            xmin = self.edges[i]\n",
    "            pdf = f((xmin + xmax) / 2)\n",
    "            self.pdf += [pdf]\n",
    "\n",
    "            # Calculate the CDF and append.\n",
    "            pdf_sum += pdf\n",
    "            self.cdf += [pdf_sum]\n",
    "\n",
    "        # We store the normalization for the PDF. This is just `pdf_sum` times\n",
    "        # bin width.\n",
    "        self.norm = (self.edges[1] - self.edges[0]) * pdf_sum\n",
    "\n",
    "        # The PDF is not yet a PDF, so we normalize it.\n",
    "        self.pdf = [bin / self.norm for bin in self.pdf]\n",
    "\n",
    "        # The CDF is also not yet a CDF, so we normalize it.\n",
    "        self.cdf = [bin / pdf_sum for bin in self.cdf]\n",
    "\n",
    "        # We now turn the CDF into edges for the inverse CDF, by prepending\n",
    "        # the CDF by 0, since the CDF must start at 0.\n",
    "        self.edges_icdf = [0] + self.cdf\n",
    "\n",
    "    def bin(self, x, edges=None):\n",
    "        \"\"\"\n",
    "        Return the bin for a given x.\n",
    "\n",
    "        x:     value to find the bin for.\n",
    "        edges: optionally, edges of the histogram. The default is to use the\n",
    "               edges of the histogram. This allows us to use this method when\n",
    "               finding the bin for the inverse CDF.\n",
    "        \"\"\"\n",
    "        # If no edges are provided, default to `self.edges`.\n",
    "        if edges == None:\n",
    "            edges = self.edges\n",
    "\n",
    "        # Loop over the edges. Skip the\n",
    "        for bin, edge in enumerate(edges[1:]):\n",
    "            # Return if `x` is less than the edge.\n",
    "            if x < edge:\n",
    "                # For underflow, just return the first bin.\n",
    "                return bin\n",
    "\n",
    "        # Return an overflow, just return the last bin.\n",
    "        return bin\n",
    "\n",
    "    def bin_icdf(self, r):\n",
    "        \"\"\"\n",
    "        Return the bin from the inverse CDF.\n",
    "        \"\"\"\n",
    "        # Set the `edges` argument to `self.edges_icdf` and use the `bin`\n",
    "        # method.\n",
    "        return self.bin(r, self.edges_icdf)\n",
    "\n",
    "\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would now like to test our histogram class. Let's use the function `f` from our linear sampler for the range $0$ to $1$, $m = 3$, and $b = 2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "# Create the linear sampler for its function and integral.\n",
    "\n",
    "# Create a histogram for the function of this sampler.\n",
    "\n",
    "# Create a figure.\n",
    "\n",
    "# Plot the binned PDF.\n",
    "\n",
    "# Plot the analytic PDF. We need to make sure to normalize the integral here.\n",
    "\n",
    "# Create the legend.\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "# Create the linear sampler for its function and integral.\n",
    "line = SampleLinear(rng, 0, 1, 3, 2)\n",
    "\n",
    "# Create a histogram for the function of this sampler.\n",
    "hist = Histogram(line.f, line.xmin, line.xmax)\n",
    "\n",
    "# Create a figure.\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the binned PDF.\n",
    "xs = np.linspace(hist.xmin, hist.xmax, 1000)\n",
    "bys = [hist.pdf[hist.bin(x)] for x in xs]\n",
    "ax.plot(xs, bys, label=\"binned PDF\")\n",
    "\n",
    "# Plot the analytic PDF. We need to make sure to normalize the integral here.\n",
    "ays = [line.f(x) / line.area for x in xs]\n",
    "ax.plot(xs, ays, label=\"analytic PDF\")\n",
    "\n",
    "# Create the legend.\n",
    "ax.legend();\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the CDF makes sense as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "# Create a figure.\n",
    "\n",
    "# Plot the binned CDF.\n",
    "\n",
    "# Plot the analytic CDF.\n",
    "\n",
    "# Create the legend.\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "# Create a figure.\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the binned CDF.\n",
    "xs = np.linspace(hist.xmin, hist.xmax, 1000)\n",
    "bys = [hist.cdf[hist.bin(x)] for x in xs]\n",
    "ax.plot(xs, bys, label=\"binned PDF\")\n",
    "\n",
    "# Plot the analytic CDF.\n",
    "ays = [line.F(x) / line.area for x in xs]\n",
    "ax.plot(xs, ays, label=\"analytic PDF\")\n",
    "\n",
    "# Create the legend.\n",
    "ax.legend();\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Example:_binned_sampling"
   },
   "source": [
    "### Example: binned sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a binned sampler given the code skeleton below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "class SampleBinned:\n",
    "    \"\"\"\n",
    "    Sampler using binned sampling.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rng, hist):\n",
    "        \"\"\"\n",
    "        Initialize the sampler.\n",
    "\n",
    "        rng:  uniform random number generator, should have method `uniform()`.\n",
    "        hist: histogram to sample from.\n",
    "        \"\"\"\n",
    "        # Store the RNG, histogram, xmin, and xmax.\n",
    "\n",
    "        # Set the area for `plot_sampler`. Since the binned PDF is normalized,\n",
    "        # this is just 1.\n",
    "\n",
    "    def f(self, x):\n",
    "        \"\"\"\n",
    "        Return the sampled function. This is the binned PDF being sampled.\n",
    "        Needed for `plot_sampler`.\n",
    "\n",
    "        x: value to calculate f(x) for.\n",
    "        \"\"\"\n",
    "        # Return 0 if outside the range.\n",
    "        # Return the binned PDF otherwise.\n",
    "\n",
    "    def __call__(self):\n",
    "        \"\"\"\n",
    "        Return the sampled value.\n",
    "        \"\"\"\n",
    "        # Sample a uniform random number.\n",
    "\n",
    "        # Get the bin from the inverted CDF.\n",
    "\n",
    "        # Get the edges for this bin.\n",
    "\n",
    "        # Uniformly sample between these values and return.\n",
    "\n",
    "\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "class SampleBinned:\n",
    "    \"\"\"\n",
    "    Sampler using binned sampling.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rng, hist):\n",
    "        \"\"\"\n",
    "        Initialize the sampler.\n",
    "\n",
    "        rng:  uniform random number generator, should have method `uniform()`.\n",
    "        hist: histogram to sample from.\n",
    "        \"\"\"\n",
    "        # Store the RNG, histogram, xmin, and xmax.\n",
    "        self.rng = rng\n",
    "        self.hist = hist\n",
    "        self.xmin = hist.xmin\n",
    "        self.xmax = hist.xmax\n",
    "\n",
    "        # Set the area for `plot_sampler`. Since the binned PDF is normalized,\n",
    "        # this is just 1.\n",
    "        self.area = 1\n",
    "\n",
    "    def f(self, x):\n",
    "        \"\"\"\n",
    "        Return the sampled function. This is the binned PDF being sampled.\n",
    "        Needed for `plot_sampler`.\n",
    "\n",
    "        x: value to calculate f(x) for.\n",
    "        \"\"\"\n",
    "        # Return 0 if outside the range.\n",
    "        if x < self.xmin or x > self.xmax:\n",
    "            return 0.0\n",
    "        # Return the binned PDF otherwise.\n",
    "        return self.hist.pdf[self.hist.bin(x)]\n",
    "\n",
    "    def __call__(self):\n",
    "        \"\"\"\n",
    "        Return the sampled value.\n",
    "        \"\"\"\n",
    "        # Sample a uniform random number.\n",
    "        r = self.rng.uniform()\n",
    "\n",
    "        # Get the bin from the inverted CDF.\n",
    "        i = hist.bin_icdf(r)\n",
    "\n",
    "        # Get the edges for this bin.\n",
    "        xmin = hist.edges[i]\n",
    "        xmax = hist.edges[i + 1]\n",
    "\n",
    "        # Uniformly sample between these values and return.\n",
    "        r = self.rng.uniform()\n",
    "        return r * (xmax - xmin) + xmin\n",
    "\n",
    "\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have sampler, let's check that it generates what we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "# Create the linear sampler for its function and integral.\n",
    "\n",
    "# Create the histogram.\n",
    "\n",
    "# Create the sampler.\n",
    "\n",
    "# Plot the comparison.\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "# Create the linear sampler for its function and integral.\n",
    "line = SampleLinear(rng, 0, 1, 3, 2)\n",
    "\n",
    "# Create the histogram.\n",
    "hist = Histogram(line.f, line.xmin, line.xmax)\n",
    "\n",
    "# Create the sampler.\n",
    "sampler = SampleBinned(rng, hist)\n",
    "\n",
    "# Plot the comparison.\n",
    "plot_sampler(sampler);\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the number of bins we have, and the number of points we are sampling, we don't see the discrete nature of the PDF. Make the comparison again, but now using only $5$ bins in the discrete PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "# Create the linear sampler for its function and integral.\n",
    "\n",
    "# Create the histogram.\n",
    "\n",
    "# Create the sampler.\n",
    "\n",
    "# Plot the comparison.\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "# Create the linear sampler for its function and integral.\n",
    "line = SampleLinear(rng, 0, 1, 3, 2)\n",
    "\n",
    "# Create the histogram.\n",
    "hist = Histogram(line.f, line.xmin, line.xmax, bins=5)\n",
    "\n",
    "# Create the sampler.\n",
    "sampler = SampleBinned(rng, hist)\n",
    "\n",
    "# Plot the comparison.\n",
    "plot_sampler(sampler);\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Accept-or-Reject_Sampling"
   },
   "source": [
    "## Accept-or-Reject Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the analytic and binned sampling use a fixed number of uniform random numbers per random number generated according to the target distribution. With analytic sampling, we require just one uniform random number which is then transformed to the target distribution. For binned sampling, we generate one uniform random number to select the bin, and another to select the location within that bin. For accept-or-reject (AOR) sampling, an indeterminate number of uniform random numbers may need to be sampled before the random number from the target distribution is obtained. This is the main short-coming of AOR. However, the simplicity and generality of AOR make it a go-to sampling method in MC.\n",
    "\n",
    "For AOR to work, the target function $f(x)$ must satify two conditions.\n",
    "\n",
    "1. The sampling of $f(x)$ is bounded, where over this range $f(x)$ is positive.\n",
    "\n",
    "$$\n",
    "f(x) \\geq 0 \\text{ for } x_\\min < x < x_\\max\n",
    "$$\n",
    "\n",
    "2. Within the range $x_\\min$ to $x_\\max$ $f(x)$ is finite.\n",
    "\n",
    "The idea behind AOR is then as follows.\n",
    "\n",
    "1. Find the maximum of $f(x)$ within the sampling range, $f_\\max$.\n",
    "2. Generate a uniform random number $R_1$ and map this to the range $x_\\min$ to $x_\\max$.\n",
    "\n",
    "$$\n",
    "x = x_\\min + R_1(x_\\max - x_\\min)\n",
    "$$\n",
    "\n",
    "3. Select a uniform random number $R_2$ and map this to the range $0$ to $f_\\max$.\n",
    "\n",
    "$$\n",
    "y = R_2 f_\\max\n",
    "$$\n",
    "\n",
    "4. If $y > f(x)$ then reject the point and return to (2), otherwise accept the point and return the value $x$.\n",
    "\n",
    "The following figure illustrates this process.\n",
    "\n",
    "![Accept-or-reject sampling.](https://github.com/mcgen-ct/tutorials/blob/main/.full/mc/figures/sample_aor.png?raw=1)\n",
    "\n",
    "In this example, for a given $x$ to possible $y$ samplings are shown, $y_1$ and $y_2$. Here, $y_1$ falls below $f(x)$ so it is accepted, while $y_2$ falls above $f(x)$ so it is rejected. Note that this method can be easily expanded to $n$ dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Exercise:_general_AOR"
   },
   "source": [
    "### Exercise: general AOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The beauty of AOR is that all we really need to know is how to evaluate the function, and the maximum of the function over the sampling range. That's it. Let us create a general class that performs AOR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "class SampleAOR:\n",
    "    \"\"\"\n",
    "    Class to perform accept-or-reject sampling.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rng, xmin, xmax, f, fmax=None, grid=100):\n",
    "        \"\"\"\n",
    "        Initialize the sampler.\n",
    "\n",
    "        rng:    uniform random number generator, should have method `uniform()`.\n",
    "        xmin:   minimum x value.\n",
    "        xman:   maximum x value.\n",
    "        f:      function to sample, should be callable, `f(x)`.\n",
    "        fmax:   maximum of f(x), if not provided, then found numerically.\n",
    "        grid:   number of points to numerically find maximum of f(x).\n",
    "        \"\"\"\n",
    "        # Store the necessary members.\n",
    "\n",
    "        # It is useful to track the efficiency of the generator. Store the\n",
    "        # number of accept and reject attempts.\n",
    "\n",
    "        # Find the maximum for f(x) with a simple grid search if not supplied.\n",
    "\n",
    "    def e(self):\n",
    "        \"\"\"\n",
    "        Return the current efficiency of the sampler.\n",
    "        \"\"\"\n",
    "        # This is defined as n_accept/n_total.\n",
    "\n",
    "    def __call__(self, nmax=10000):\n",
    "        \"\"\"\n",
    "        Sample from the target distribution.\n",
    "\n",
    "        nmax: only sample this many times before giving up.\n",
    "        \"\"\"\n",
    "        # Loop over the maximum number of attempts.\n",
    "        for i in range(0, nmax):\n",
    "            # Generate the two necessary uniform random numbers.\n",
    "            # Transform `r1` to an x.\n",
    "            # Transform `r2` to y.\n",
    "            # Check if y < f(x).\n",
    "            pass\n",
    "\n",
    "\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "class SampleAOR:\n",
    "    \"\"\"\n",
    "    Class to perform accept-or-reject sampling.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rng, xmin, xmax, f, fmax=None, grid=100):\n",
    "        \"\"\"\n",
    "        Initialize the sampler.\n",
    "\n",
    "        rng:    uniform random number generator, should have method `uniform()`.\n",
    "        xmin:   minimum x value.\n",
    "        xman:   maximum x value.\n",
    "        f:      function to sample, should be callable, `f(x)`.\n",
    "        fmax:   maximum of f(x), if not provided, then found numerically.\n",
    "        grid:   number of points to numerically find maximum of f(x).\n",
    "        \"\"\"\n",
    "        # Store the necessary members.\n",
    "        self.rng = rng\n",
    "        self.xmin = xmin\n",
    "        self.xmax = xmax\n",
    "        self.f = f\n",
    "\n",
    "        # It is useful to track the efficiency of the generator. Store the\n",
    "        # number of accept and reject attempts.\n",
    "        self.accept = 0\n",
    "        self.reject = 0\n",
    "\n",
    "        # Find the maximum for f(x) with a simple grid search if not supplied.\n",
    "        if fmax == None:\n",
    "            self.fmax = 0\n",
    "            for x in np.linspace(xmin, xmax, grid):\n",
    "                self.fmax = max(self.fmax, f(x))\n",
    "            # Add 5% head room on this.\n",
    "            self.fmax *= 1.05\n",
    "        else:\n",
    "            self.fmax = fmax\n",
    "\n",
    "    def e(self):\n",
    "        \"\"\"\n",
    "        Return the current efficiency of the sampler.\n",
    "        \"\"\"\n",
    "        # This is defined as n_accept/n_total.\n",
    "        return self.accept / (self.accept + self.reject)\n",
    "\n",
    "    def __call__(self, nmax=10000):\n",
    "        \"\"\"\n",
    "        Sample from the target distribution.\n",
    "\n",
    "        nmax: only sample this many times before giving up.\n",
    "        \"\"\"\n",
    "        # Loop over the maximum number of attempts.\n",
    "        for i in range(0, nmax):\n",
    "            # Generate the two necessary uniform random numbers.\n",
    "            r1 = self.rng.uniform()\n",
    "            r2 = self.rng.uniform()\n",
    "            # Transform `r1` to an x.\n",
    "            x = self.xmin + r1 * (self.xmax - self.xmin)\n",
    "            # Transform `r2` to y.\n",
    "            y = r2 * self.fmax\n",
    "            # Check if y < f(x).\n",
    "            if y < self.f(x):\n",
    "                self.accept += 1\n",
    "                return x\n",
    "            else:\n",
    "                self.reject += 1\n",
    "\n",
    "\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see how well this works. Let us first try sampling the linear distribution from before. To make the comparison with `plot_sampler` we need the sampler object to have the member `area`, which is the integral of the function over the sampling range. This is used to normalize the generated distribution to the PDF, but is not actually required for the sampling method. Later on, we will see in the [MC Integration](#scrollTo=MC_Integration) how we can simultaneously calculate the integral while sampling. For now, we can simply set the area of the sampler object to that of the line sampler class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "# Create the linear sampler for its function and integral.\n",
    "line = SampleLinear(rng, 0, 1, 3, 2)\n",
    "\n",
    "# Create the sampler.\n",
    "sampler = SampleAOR(rng, line.xmin, line.xmax, line.f)\n",
    "\n",
    "# Set the area of the `sampler` to that of the `line`.\n",
    "sampler.area = line.area\n",
    "\n",
    "# Plot the comparison.\n",
    "plot_sampler(sampler);\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "# Create the linear sampler for its function and integral.\n",
    "line = SampleLinear(rng, 0, 1, 3, 2)\n",
    "\n",
    "# Create the sampler.\n",
    "sampler = SampleAOR(rng, line.xmin, line.xmax, line.f)\n",
    "\n",
    "# Set the area of the `sampler` to that of the `line`.\n",
    "sampler.area = line.area\n",
    "\n",
    "# Plot the comparison.\n",
    "plot_sampler(sampler);\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the efficiency of this sampler?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "# Use the `e()` method of the `SampleAOR` class.\n",
    "print(sampler.e())\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "# Use the `e()` method of the `SampleAOR` class.\n",
    "print(sampler.e())\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we sample a more complicated function? Try applying this sampler to the Cauchy distribution that we generated before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "# Create the Cauchy sampler for its function and integral.\n",
    "\n",
    "# Create the sampler.\n",
    "\n",
    "# Set the area of the `sampler` to that of the `cauchy`.\n",
    "\n",
    "# Plot the comparison.\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "# Create the Cauchy sampler for its function and integral.\n",
    "cauchy = SampleCauchy(rng, 0, 40, 20, 5)\n",
    "\n",
    "# Create the sampler.\n",
    "sampler = SampleAOR(rng, cauchy.xmin, cauchy.xmax, cauchy.f)\n",
    "\n",
    "# Set the area of the `sampler` to that of the `cauchy`.\n",
    "sampler.area = cauchy.area\n",
    "\n",
    "# Plot the comparison.\n",
    "plot_sampler(sampler);\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the efficiency for this sampling? Is this better or worse than for the line?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "# Use the `e()` method of the `SampleAOR` class.\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "# Use the `e()` method of the `SampleAOR` class.\n",
    "print(sampler.e())\n",
    "\n",
    "# We get a value that is less than for the line sampling.\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully we see that this sampling is less efficient. We throw away around $70\\%$ of the points we sample.\n",
    "\n",
    "Finally, let's see what happens if we don't choose our $f_\\max$ correctly. We can do this by explicitly setting `fmax` to $f(x_0)$, which will be half our maximum for this particular function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "# Create the Cauchy sampler for its function and integral.\n",
    "\n",
    "# Incorrectly set an `fmax` that is half f(x0).\n",
    "\n",
    "# Create the sampler.\n",
    "\n",
    "# Set the area of the `sampler` to that of the `cauchy`.\n",
    "\n",
    "# Plot the comparison.\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "# Create the Cauchy sampler for its function and integral.\n",
    "cauchy = SampleCauchy(rng, 0, 40, 20, 5)\n",
    "\n",
    "# Incorrectly set an `fmax` that is half f(x0).\n",
    "fmax = cauchy.f(cauchy.x0) / 2\n",
    "\n",
    "# Create the sampler.\n",
    "sampler = SampleAOR(rng, cauchy.xmin, cauchy.xmax, cauchy.f, fmax)\n",
    "\n",
    "# Set the area of the `sampler` to that of the `cauchy`.\n",
    "sampler.area = cauchy.area\n",
    "\n",
    "# Plot the comparison.\n",
    "plot_sampler(sampler);\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should see that distribution does not look correct. This critical to the AOR method. The maximum must truly be the maximum for that function over the sampling range, otherwise sculpting effects of the distribution will occur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Importance_Sampling"
   },
   "source": [
    "## Importance Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importance sampling is still accept-or-reject, we just choose a distribution that better bounds the function $f(x)$. Spefically, we choose a function $g(x)$ that we can sample easily, whether analytic or some other method, that is already greater than $f(x)$.\n",
    "\n",
    "$$\n",
    "g(x) > f(x) \\text{ for } x_\\min < x < x_\\max\n",
    "$$\n",
    "\n",
    "Using the same example given at the start of the [Accept-or-Reject Sampling](#scrollTo=Accept-or-Reject_Sampling), we can imagine a bounding function like the green one given in the plot below.\n",
    "\n",
    "![Importance sampling example.](https://github.com/mcgen-ct/tutorials/blob/main/.full/mc/figures/sample_importance.png?raw=1)\n",
    "\n",
    "1. Find $g(x)$ which bounds $f(x)$ within the sampling range.\n",
    "2. Generate $x$ distributed according to $g(x)$.\n",
    "3. Select a uniform random number $R$ and map this to the range $0$ to $g(x)$.\n",
    "\n",
    "$$\n",
    "y = R g(x)\n",
    "$$\n",
    "\n",
    "4. If $y > f(x)$ then reject the point and return to (2), otherwise accept the point and return the value $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Exercise:_general_importance_sampler"
   },
   "source": [
    "### Exercise: general importance sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try to implement a general importance sampler in the skeleton given below. The result should look relatively similar to the AOB sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "class SampleImportance:\n",
    "    \"\"\"\n",
    "    Class to perform importance sampling.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rng, xmin, xmax, f, g, grng):\n",
    "        \"\"\"\n",
    "        Initialize the sampler.\n",
    "\n",
    "        rng:  uniform random number generator, with method `uniform()`.\n",
    "        xmin: minimum x value.\n",
    "        xman: maximum x value.\n",
    "        f:    function to sample, should be callable, `f(x)`.\n",
    "        g:    function that bounds f(x), should be callable `g(x)`.\n",
    "        grng: samples `g(x)`, should be callable `gnrg()`.\n",
    "        \"\"\"\n",
    "        # Store the necessary members.\n",
    "\n",
    "        # It is useful to track the efficiency of the generator. Store the\n",
    "        # number of accept and reject attempts.\n",
    "\n",
    "    def e(self):\n",
    "        \"\"\"\n",
    "        Return the current efficiency of the sampler.\n",
    "        \"\"\"\n",
    "        # This is defined as n_accept/n_total.\n",
    "\n",
    "    def __call__(self, nmax=10000):\n",
    "        \"\"\"\n",
    "        Sample from the target distribution.\n",
    "\n",
    "        nmax: only sample this many times before giving up.\n",
    "        \"\"\"\n",
    "        # Loop over the maximum number of attempts.\n",
    "        for i in range(0, nmax):\n",
    "            # Generate `x` from the g(x) sampler.\n",
    "            # Generate a uniform random number.\n",
    "            # Transform `r` to y.\n",
    "            # Check if y < f(x).\n",
    "            pass\n",
    "\n",
    "\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "class SampleImportance:\n",
    "    \"\"\"\n",
    "    Class to perform importance sampling.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rng, xmin, xmax, f, g, grng):\n",
    "        \"\"\"\n",
    "        Initialize the sampler.\n",
    "\n",
    "        rng:  uniform random number generator, with method `uniform()`.\n",
    "        xmin: minimum x value.\n",
    "        xman: maximum x value.\n",
    "        f:    function to sample, should be callable, `f(x)`.\n",
    "        g:    function that bounds f(x), should be callable `g(x)`.\n",
    "        grng: samples `g(x)`, should be callable `gnrg()`.\n",
    "        \"\"\"\n",
    "        # Store the necessary members.\n",
    "        self.rng = rng\n",
    "        self.xmin = xmin\n",
    "        self.xmax = xmax\n",
    "        self.f = f\n",
    "        self.g = g\n",
    "        self.grng = grng\n",
    "\n",
    "        # It is useful to track the efficiency of the generator. Store the\n",
    "        # number of accept and reject attempts.\n",
    "        self.accept = 0\n",
    "        self.reject = 0\n",
    "\n",
    "    def e(self):\n",
    "        \"\"\"\n",
    "        Return the current efficiency of the sampler.\n",
    "        \"\"\"\n",
    "        # This is defined as n_accept/n_total.\n",
    "        return self.accept / (self.accept + self.reject)\n",
    "\n",
    "    def __call__(self, nmax=10000):\n",
    "        \"\"\"\n",
    "        Sample from the target distribution.\n",
    "\n",
    "        nmax: only sample this many times before giving up.\n",
    "        \"\"\"\n",
    "        # Loop over the maximum number of attempts.\n",
    "        for i in range(0, nmax):\n",
    "            # Generate `x` from the g(x) sampler.\n",
    "            x = self.grng()\n",
    "            # Generate a uniform random number.\n",
    "            r = self.rng.uniform()\n",
    "            # Transform `r` to y.\n",
    "            y = r * self.g(x)\n",
    "            # Check if y < f(x).\n",
    "            if y < self.f(x):\n",
    "                self.accept += 1\n",
    "                return x\n",
    "            else:\n",
    "                self.reject += 1\n",
    "\n",
    "\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Exercise:_even_more_linear_sampling"
   },
   "source": [
    "### Exercise: even more linear sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there are any number of interesting functions we could try to importance sample, let us return to a linear function to allow us to cross-check that our importance sampler is working correctly. Let us target the distribution $m = 3$ and $b = 2$ between $0$ and $1$. We can choose an oversampling function that is implemented with the `SampleLinear` class to provide our $g(x)$. Here, let us choose the oversampling function with $m = 4$ and $b = 3$. First let us just plot these two functions. We can use the `SampleLinear` class, which is complete overkill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the two samplers.\n",
    "f_sampler = SampleLinear(rng, 0, 1, 3, 2)\n",
    "g_sampler = SampleLinear(rng, 0, 1, 4, 3)\n",
    "\n",
    "# Create our x points.\n",
    "xs = np.linspace(0, 1)\n",
    "\n",
    "# Create our plot.\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the two lines.\n",
    "ax.plot(xs, [f_sampler.f(x) for x in xs], label=\"f(x)\")\n",
    "ax.plot(xs, [g_sampler.f(x) for x in xs], label=\"g(x)\")\n",
    "\n",
    "# Draw a legend.\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly $g(x)$ bounds $f(x)$. Now, let us set up our sampler and compare the generated distribution to the expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "# Create the f(x) linear sampler for its function and integral.\n",
    "\n",
    "# Create the g(x) linear sampler.\n",
    "\n",
    "# Create the sampler.\n",
    "\n",
    "# Set the area of the `sampler` to that of the `line`.\n",
    "\n",
    "# Plot the comparison.\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "# Create the f(x) linear sampler for its function and integral.\n",
    "line = SampleLinear(rng, 0, 1, 3, 2)\n",
    "\n",
    "# Create the g(x) linear sampler.\n",
    "grng = SampleLinear(rng, 0, 1, 4, 3)\n",
    "\n",
    "# Create the sampler.\n",
    "sampler = SampleImportance(rng, line.xmin, line.xmax, line.f, grng.f, grng)\n",
    "\n",
    "# Set the area of the `sampler` to that of the `line`.\n",
    "sampler.area = line.area\n",
    "\n",
    "# Plot the comparison.\n",
    "plot_sampler(sampler);\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the efficiency of this sampling? Can you calculate what this efficiency is exactly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "# Use the `e()` method of the `SampleImportance` class.\n",
    "\n",
    "# The exact efficiency should just be the integral of f(x) over g(x).\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "# Use the `e()` method of the `SampleImportance` class.\n",
    "print(f\"efficiency = {sampler.e():.2f}\")\n",
    "\n",
    "# The exact efficiency should just be the integral of f(x) over g(x).\n",
    "print(f\"exact efficiency = {line.area/grng.area:.2f}\")\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could we make this efficiency $100\\%$? Create an importance sampler that does this. Check the distribution and efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "# Create the f(x) linear sampler for its function and integral.\n",
    "\n",
    "# If g(x) = f(x), we then we are completely efficient.\n",
    "# Create the g(x) linear sampler.\n",
    "\n",
    "# Create the sampler.\n",
    "\n",
    "# Set the area of the `sampler` to that of the `line`.\n",
    "\n",
    "# Plot the comparison.\n",
    "\n",
    "# Use the `e()` method of the `SampleImportance` class.\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "# Create the f(x) linear sampler for its function and integral.\n",
    "line = SampleLinear(rng, 0, 1, 3, 2)\n",
    "\n",
    "# If g(x) = f(x), we then we are completely efficient.\n",
    "# Create the g(x) linear sampler.\n",
    "grng = SampleLinear(rng, 0, 1, 3, 2)\n",
    "\n",
    "# Create the sampler.\n",
    "sampler = SampleImportance(rng, line.xmin, line.xmax, line.f, grng.f, grng)\n",
    "\n",
    "# Set the area of the `sampler` to that of the `line`.\n",
    "sampler.area = line.area\n",
    "\n",
    "# Plot the comparison.\n",
    "plot_sampler(sampler)\n",
    "\n",
    "# Use the `e()` method of the `SampleImportance` class.\n",
    "print(f\"efficiency = {sampler.e()}\")\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Exercise:_Lund_fragmentation_function"
   },
   "source": [
    "### Exercise: Lund fragmentation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example above is perhaps not particularly satisfying, so you are encouraged to try more complex functions. In the [`hadronization.ipynb`](hadronize.ipynb) notebook, we will introduce the Lund fragmentation function,\n",
    "\n",
    "$$\n",
    "f(x) = \\frac{(1-x)^a}{x}\\exp \\left(-b \\frac{m^2}{x} \\right),\n",
    "$$\n",
    "\n",
    "where $a$, $b$, and $m$ are parameters, and $x$ runs from $0$ to $1$. It turns out that this function is much harder to sample, and in that notebook we perform a relatively simple importance sampling of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Multichannel_Sampling"
   },
   "source": [
    "## Multichannel Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, we would like to perform importance sampling, but we don't have a single $g(x)$ which bounds $f(x)$. Consider the example below.\n",
    "\n",
    "![Multichannel sampling example.](https://github.com/mcgen-ct/tutorials/blob/main/.full/mc/figures/sample_multi.png?raw=1)\n",
    "\n",
    "Here, the sum of the two functions $g_1(x)$ and $g_2(x)$ bounds $f(x)$. The algorithm is as follows.\n",
    "\n",
    "1. Select $g_i(x)$ from $n$ channels with relative probability.\n",
    "\n",
    "$$\n",
    "\\frac{G_i(x_\\max) - G_i(x_\\min)}{\\sum_{j = 1}^n G_j(x_\\max) - G_j(x_\\min}\n",
    "$$\n",
    "\n",
    "2. Generate $x$ distributed according to $g_i(x)$.\n",
    "3. Select a uniform random number $R$ and map this to the range $0$ to $g_i(x)$.\n",
    "\n",
    "$$\n",
    "y = R g_i(x)\n",
    "$$\n",
    "\n",
    "4. If $y > f(x)$ then reject the point and return to (2), otherwise accept the point and return the value $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Exercise:_general_multichannel"
   },
   "source": [
    "### Exercise: general multichannel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as for the importance sampling, let us first implement a general multichannel sampler. When we implemented the importance sampling, we factorized the $g(x)$ function definition from the $g(x)$ sampler. Here, we also need the integral of $G(x)$. This can be obtained numerically, but for simplicity in this example, let us limit our selves to analytic sampling. This means that we can just require a list of samplers deriving from the `SampleAnalytic` class, where all these functions are already defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleMulti:\n",
    "    \"\"\"\n",
    "    Class to perform multichannel sampling.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rng, xmin, xmax, f, grngs):\n",
    "        \"\"\"\n",
    "        Initialize the sampler.\n",
    "\n",
    "        rng:   uniform random number generator, with method `uniform()`.\n",
    "        xmin:  minimum x value.\n",
    "        xman:  maximum x value.\n",
    "        f:     function to sample, should be callable, `f(x)`.\n",
    "        grngs: samplers for g_i(x) which summed bound f(x). Should be derived\n",
    "               from `SampleAnalytic` class.\n",
    "        \"\"\"\n",
    "        # Store the necessary members.\n",
    "        self.rng = rng\n",
    "        self.xmin = xmin\n",
    "        self.xmax = xmax\n",
    "        self.f = f\n",
    "        self.grngs = grngs\n",
    "\n",
    "        # Calculate the channel weights. This is the integral over the sampling\n",
    "        # range per channel. We could also just use the `area` member.\n",
    "        areas = [grng.F(xmax) - grng.F(xmin) for grng in grngs]\n",
    "        # Next, we calculate the total sum.\n",
    "        area_sum = sum(areas)\n",
    "        # Finally, we construct `wgts` to be the running cumulative weight.\n",
    "        # We can then sample a uniform random number, and loop over the weights\n",
    "        # to select the channel. This is implemented in the `channel` method.\n",
    "        wgt_sum = 0\n",
    "        self.wgts = []\n",
    "        for area in areas:\n",
    "            wgt_sum += area / area_sum\n",
    "            self.wgts += [wgt_sum]\n",
    "\n",
    "        # It is useful to track the efficiency of the generator. Store the\n",
    "        # number of accept and reject attempts.\n",
    "        self.accept = 0\n",
    "        self.reject = 0\n",
    "\n",
    "    def e(self):\n",
    "        \"\"\"\n",
    "        Return the current efficiency of the sampler.\n",
    "        \"\"\"\n",
    "        # This is defined as n_accept/n_total.\n",
    "        return self.accept / (self.accept + self.reject)\n",
    "\n",
    "    def channel(self):\n",
    "        \"\"\"\n",
    "        Randomly sample one of the channels according to their\n",
    "        probabilities.\n",
    "        \"\"\"\n",
    "        r = self.rng.uniform()\n",
    "        for i, wgt in enumerate(self.wgts):\n",
    "            if r < wgt:\n",
    "                return i\n",
    "        return i\n",
    "\n",
    "    def __call__(self, nmax=10000):\n",
    "        \"\"\"\n",
    "        Sample from the target distribution.\n",
    "\n",
    "        nmax: only sample this many times before giving up.\n",
    "        \"\"\"\n",
    "        # Loop over the maximum number of attempts.\n",
    "        for i in range(0, nmax):\n",
    "            # Choose the channel.\n",
    "            i = self.channel()\n",
    "            # Generate `x` from the g(x) sampler.\n",
    "            x = self.grngs[i]()\n",
    "            # Generate a uniform random number.\n",
    "            r = self.rng.uniform()\n",
    "            # Transform `r` to y.\n",
    "            y = r * self.grngs[i].f(x)\n",
    "            # Check if y < f(x).\n",
    "            if y < self.f(x):\n",
    "                self.accept += 1\n",
    "                return x\n",
    "            else:\n",
    "                self.reject += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Exercise:_signal_on_background"
   },
   "source": [
    "### Exercise: signal on background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider an example which does not fully capture the power of multichannel sampling, but is of high energy physics interest. We oftentimes will have resonance signals on continuum backgrounds like the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our signal and background functions.\n",
    "signal = SampleCauchy(rng, 2, 6, 3.1, 0.1)\n",
    "background = SampleLinear(rng, signal.xmin, signal.xmax, -1, 6)\n",
    "\n",
    "# Create our x points.\n",
    "xs = np.linspace(signal.xmin, signal.xmax, 1000)\n",
    "\n",
    "# Create our plot.\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the two lines.\n",
    "ax.plot(xs, [signal.f(x) + background.f(x) for x in xs]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To sample this, we might be very tempted to just sample the signal distribution, $x_1$, and add this to a sample from the background disribution $x_2$. This will not work! Adding randomly sampled variables from PDFs is not equivalent to adding the PDFs themselves. Actually, this makes for an interesting distribution, but certainly not the one we want. Plot this distribution below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "# Sample the distributions and add together.\n",
    "\n",
    "# Create the plot.\n",
    "\n",
    "# Draw the histogram.\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "# Sample the distributions and add together.\n",
    "rs = [signal() + background() for i in range(0, 100000)]\n",
    "\n",
    "# Create the plot.\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Draw the histogram.\n",
    "ax.hist(rs, bins=50);\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, we need to use multichannel sampling. Because we already have two functions that we can generate the distributions for, finding the summed $g_i(x)$ that bounds our $f(x)$ is straight forward, and also exact. Construct a multichannel sampler that does this and compare with the target distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "# Create our signal and background functions.\n",
    "\n",
    "# Create a function that is the sum of the signal and background.\n",
    "# We use a lambda function, which is an anonymous function (we don't\n",
    "# use `def` to define it).\n",
    "\n",
    "# Create the sampler.\n",
    "\n",
    "# Set the area of the `sampler` to that of the signal + background. This\n",
    "# is not needed for the sampling, just the comparison.\n",
    "\n",
    "# Plot the comparison.\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "# Create our signal and background functions.\n",
    "signal = SampleCauchy(rng, 2, 6, 3.1, 0.1)\n",
    "background = SampleLinear(rng, signal.xmin, signal.xmax, -1, 6)\n",
    "\n",
    "# Create a function that is the sum of the signal and background.\n",
    "# We use a lambda function, which is an anonymous function (we don't\n",
    "# use `def` to define it).\n",
    "both = lambda x: signal.f(x) + background.f(x)\n",
    "\n",
    "# Create the sampler.\n",
    "sampler = SampleMulti(rng, signal.xmin, signal.xmax, both, [signal, background])\n",
    "\n",
    "# Set the area of the `sampler` to that of the signal + background. This\n",
    "# is not needed for the sampling, just the comparison.\n",
    "sampler.area = signal.area + background.area\n",
    "\n",
    "# Plot the comparison.\n",
    "plot_sampler(sampler);\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Quadrature_Integration"
   },
   "source": [
    "## Quadrature Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerical integration is a critical tool for many scientific disciplines. Prior to computers, integrals that could not be calculated analytically were sometimes calculated physically. The function would be plotted on a piece of paper, the paper would then be cut along the line of the function, and the resulting paper was weighed. Dividing this weight by the weight of the paper before cutting would then give the relative integral. Computers make this process a little faster, but we need to make sure we use the right technique for the job.\n",
    "\n",
    "One method of integration is called quadrature where we approximate the function we are trying to integrate with piecewise functions that we know the integrals for already. While there are any number of quadrature methods out there, we will only consider a few here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Exercise:_midpoint_rule"
   },
   "source": [
    "### Exercise: midpoint rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a function $f(x)$ and its integral over the range $a$ to $b$. One of the simplest non-Monte Carlo methods for performing this integral is to evaluate the function at its midpoint between $a$ and $b$, and then multiply this by $b - a$.\n",
    "\n",
    "![Midpoint rule.](https://github.com/mcgen-ct/tutorials/blob/main/.full/mc/figures/integrate_midpoint.png?raw=1)\n",
    "\n",
    "$$\n",
    "\\int_a^b \\text{d}x\\, f(x) \\approx (b - a)f\\left(\\tfrac{a + b}{2}\\right)\n",
    "$$\n",
    "\n",
    "This method is called the midpoint rule. Note that the midpoint rule requires just a single function evaluation. If the function is computationally expensive to compute, it is important to reduce the number of function evaluations. Of course, the midpoint might not provide a good estimate of the function, so instead we can divide the integral into multiple peices and for each division evaluate the midpoint rule. This is the composite midpoint rule.\n",
    "\n",
    "Implement the composite midpoint rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "def integrate_midpoint(f, xmin, xmax, ndiv=1000):\n",
    "    \"\"\"\n",
    "    Evaluate the definite integral of f(x) using the midpoint rule.\n",
    "\n",
    "    f:    function to integrate, should be callable as `f(x)`.\n",
    "    xmin: lower bound.\n",
    "    xmax: upper bound.\n",
    "    ndiv: number of divisions.\n",
    "    \"\"\"\n",
    "    # Subdivide into division over the range of integration.\n",
    "    # Calculate the division width.\n",
    "    # Sum the integral for each midpoint.\n",
    "\n",
    "\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "def integrate_midpoint(f, xmin, xmax, ndiv=1000):\n",
    "    \"\"\"\n",
    "    Evaluate the definite integral of f(x) using the midpoint rule.\n",
    "\n",
    "    f:    function to integrate, should be callable as `f(x)`.\n",
    "    xmin: lower bound.\n",
    "    xmax: upper bound.\n",
    "    ndiv: number of divisions.\n",
    "    \"\"\"\n",
    "    # Subdivide into division over the range of integration.\n",
    "    xs = np.linspace(xmin, xmax, ndiv)\n",
    "    # Calculate the division width.\n",
    "    dx = xs[1] - xs[0]\n",
    "    # Sum the integral for each midpoint.\n",
    "    integral = 0\n",
    "    for i, b in enumerate(xs[1:]):\n",
    "        a = xs[i]\n",
    "        integral += dx * f((a + b) / 2)\n",
    "    return integral\n",
    "\n",
    "\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Evaluate the integral of the Lund fragmentation function,\n",
    "\n",
    "$$\n",
    "f(x) = \\frac{(1-x)^a}{x}\\exp \\left(-b \\frac{m^2}{x} \\right)\n",
    "$$\n",
    "\n",
    "with $a = 0.6$, $b = 0.9$, and $m = 0.1$ over the interval $0$ to $1$ using the composite midpoint rule with $10$ divisions. Just to clarify, the $a$ and $b$ of this function are parameters, and are not related to the $a$ and $b$ of the midpoint rule which define the integration limits. First, define the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "def function_lff(x, a, b, m):\n",
    "    \"\"\"\n",
    "    Return the Lund fragmentation function.\n",
    "\n",
    "    a: the power shape parameter.\n",
    "    b: the exponential shape parameter.\n",
    "    m: the transverse mass parameter.\n",
    "    \"\"\"\n",
    "    # Return 0 if x is 0.\n",
    "    # Return the function.\n",
    "\n",
    "\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "def function_lff(x, a, b, m):\n",
    "    \"\"\"\n",
    "    Return the Lund fragmentation function.\n",
    "\n",
    "    a: the power shape parameter.\n",
    "    b: the exponential shape parameter.\n",
    "    m: the transverse mass parameter.\n",
    "    \"\"\"\n",
    "    # Return 0 if x is 0.\n",
    "    if x == 0:\n",
    "        return 0.0\n",
    "    # Return the function.\n",
    "    return ((1 - x) ** a / x) * math.exp(-(b * m**2) / x)\n",
    "\n",
    "\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this function look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "# Create the x values.\n",
    "\n",
    "# Define the parameters.\n",
    "\n",
    "# Calculate the function at these points.\n",
    "\n",
    "# Create the plot and plot the curve.\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "# Create the x values.\n",
    "xs = np.linspace(0, 1, 1000)\n",
    "\n",
    "# Define the parameters.\n",
    "a, b, m = 0.6, 0.9, 0.1\n",
    "\n",
    "# Calculate the function at these points.\n",
    "ys = [function_lff(x, a, b, m) for x in xs]\n",
    "\n",
    "# Create the plot and plot the curve.\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(xs, ys);\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, integrate the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "# The integrate method cannot pass arguments to f(x). So we use a lambda\n",
    "# function here to pass the parameters that we want.\n",
    "\n",
    "# Perform the integration and print.\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "# The integrate method cannot pass arguments to f(x). So we use a lambda\n",
    "# function here to pass the parameters that we want.\n",
    "f = lambda x: function_lff(x, a, b, m)\n",
    "\n",
    "# Perform the integration and print.\n",
    "integral = integrate_midpoint(f, 0, 1, 10)\n",
    "print(f\"midpoint integral (n = 10) = {integral:.5e}\")\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare with divisions of $10$, $100$, $1000$, and $10000$. Print to the integral to $6$ significant digits. How many divisions are needed for convergence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "# The integrate method cannot pass arguments to f(x). So we use a lambda\n",
    "# function here to pass the parameters that we want.\n",
    "\n",
    "# Perform the integration and print.\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "# The integrate method cannot pass arguments to f(x). So we use a lambda\n",
    "# function here to pass the parameters that we want.\n",
    "f = lambda x: function_lff(x, a, b, m)\n",
    "\n",
    "# Perform the integration and print.\n",
    "for ndiv in (10, 100, 1000, 10000):\n",
    "    integral = integrate_midpoint(f, 0, 1, ndiv)\n",
    "    print(f\"midpoint integral (n = {ndiv:5d}) = {integral:.5e}\")\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Exercise:_trapezoid_rule"
   },
   "source": [
    "### Exercise: trapezoid rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The midpoint rule approximates the function as a zero order polynomial, e.g., just a horizontal line, for which the integral is known. But, we can approximate $f(x)$ using other functions with simple analytic integrals, which may describe $f(x)$ better. With the trapezoidal rule, the function is approximated as a line from point $a$ to point $b$, forming a trapezoid.\n",
    "\n",
    "![Midpoint rule.](https://github.com/mcgen-ct/tutorials/blob/main/.full/mc/figures/integrate_trapezoid.png?raw=1)\n",
    "\n",
    "$$\n",
    "\\int_a^b \\text{d}{x}\\, f(x) \\approx \\frac{b - a}{2}\\Big(f(a) + f(b)\\Big)\n",
    "$$\n",
    "\n",
    "Note that this method requires two function evaluations. Again, the integral can be divided into smaller intervals and the trapezoid rule can be performed for each division. Implement the trapezoid rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "def integrate_trapezoid(f, xmin, xmax, ndiv=1000):\n",
    "    \"\"\"\n",
    "    Evaluate the definite integral of f(x) using the trapezoid rule.\n",
    "\n",
    "    f:    function to integrate, should be callable as `f(x)`.\n",
    "    xmin: lower bound.\n",
    "    xmax: upper bound.\n",
    "    ndiv: number of divisions.\n",
    "    \"\"\"\n",
    "    # Subdivide into division over the range of integration.\n",
    "    # Calculate the division width.\n",
    "    # Sum the integral for each trapezoid.\n",
    "\n",
    "\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "def integrate_trapezoid(f, xmin, xmax, ndiv=1000):\n",
    "    \"\"\"\n",
    "    Evaluate the definite integral of f(x) using the trapezoid rule.\n",
    "\n",
    "    f:    function to integrate, should be callable as `f(x)`.\n",
    "    xmin: lower bound.\n",
    "    xmax: upper bound.\n",
    "    ndiv: number of divisions.\n",
    "    \"\"\"\n",
    "    # Subdivide into division over the range of integration.\n",
    "    xs = np.linspace(xmin, xmax, ndiv)\n",
    "    # Calculate the division width.\n",
    "    dx = xs[1] - xs[0]\n",
    "    # Sum the integral for each trapezoid.\n",
    "    integral = 0\n",
    "    for i, b in enumerate(xs[1:]):\n",
    "        a = xs[i]\n",
    "        integral += dx / 2 * (f(a) + f(b))\n",
    "    return integral\n",
    "\n",
    "\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the integral for the Lund fragmentation function using the trapezoid rule for $10$, $100$, $1000$, and $10000$ divisions. How does this compare to the midpoint rule for the same number of divisions? Which of the two converges faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "# The integrate method cannot pass arguments to f(x). So we use a lambda\n",
    "# function here to pass the parameters that we want.\n",
    "\n",
    "# Perform the integration and print.\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "# The integrate method cannot pass arguments to f(x). So we use a lambda\n",
    "# function here to pass the parameters that we want.\n",
    "f = lambda x: function_lff(x, a, b, m)\n",
    "\n",
    "# Perform the integration and print.\n",
    "for ndiv in (10, 100, 1000, 10000):\n",
    "    integral = integrate_midpoint(f, 0, 1, ndiv)\n",
    "    print(f\" midpoint integral (n = {ndiv:5d}) = {integral:.5e}\")\n",
    "    integral = integrate_trapezoid(f, 0, 1, ndiv)\n",
    "    print(f\"trapezoid integral (n = {ndiv:5d}) = {integral:.5e}\")\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now calculate with $1000$. How does this compare to the midpoint rule and the $10$ division calculation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use even higher order polynomials for the approximating function, which really is just used to interpolate $f(x)$. For Simpson's rule, a second order polynomial is used.\n",
    "\n",
    "![Simpson's rule.](https://github.com/mcgen-ct/tutorials/blob/main/.full/mc/figures/integrate_simpson.png?raw=1)\n",
    "\n",
    "$$\n",
    "\\int_a^b \\text{d}{x}\\, f(x) \\approx \\frac{b - a}{6}\\Big(f(a) + 4f\\left(\\tfrac{a + b}{2}\\right) + f(b)\\Big)\n",
    "$$\n",
    "\n",
    "This approximation requires three function evaluations. In general, these types of approximations are called the Newton-Cotes formulas. However, as the degree of the approximating polynomial becomes very high, the approximation can perform very poorly. This is because high order interpolating polynomials suffer from Runge's phenomenon, where the polynomial begins to fluctuate wildly. Despite this, any Newton-Cotes method can be used for composite integration. In the example above with the Lund fragmentation function, we already see that a higher order interpolation does not necessarily mean a faster convergence of the integral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MC_Integration"
   },
   "source": [
    "## MC Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to integrate a function is Monte Carlo (MC) integration. Given a function $f(x)$, sample $x$ from a uniform distribution and then calculate $f(x)$. If we calculate the mean for $f(x)$ we and multiply this by the integration range, we will then converge to the integral for a large enough number of sampled $x$.\n",
    "\n",
    "$$\n",
    "\\int_a^b \\text{d}{x}\\, f(x) \\approx \\langle f(x) \\rangle (b - a)\n",
    "$$\n",
    "\n",
    "The nice thing about MC integration is that extending it to higher dimensions is very straightforward.\n",
    "\n",
    "$$\n",
    "\\int_V \\text{d}\\,{\\vec{x}} f(\\vec{x}) \\approx \\langle f(\\vec{x}) \\rangle V\n",
    "$$\n",
    "\n",
    "Here, $V$ is just the volume of the hypercube which defines the limits of the integral. For the quadrature methods, extending to higher dimensions is also possible, but correctly implementing the interpolating function can be non-trivial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Exercise:_1D_MC_integration"
   },
   "source": [
    "### Exercise: 1D MC integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement 1D MC integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "def integrate_mc(rng, f, xmin, xmax, nsample=1000):\n",
    "    \"\"\"\n",
    "    Evaluate the definite integral of f(x) using MC integration.\n",
    "\n",
    "    rng:     random number generator with `uniform()` method.\n",
    "    f:       function to integrate, should be callable as `f(x)`.\n",
    "    xmin:    lower bound.\n",
    "    xmax:    upper bound.\n",
    "    nsample: number of points to sample.\n",
    "    \"\"\"\n",
    "    # Sample the points while tracking the sum of the function.\n",
    "    for i in range(0, nsample):\n",
    "        # Sample a uniform random number between xmin and xmax.\n",
    "        # Calculate the function and sum.\n",
    "        pass\n",
    "    # Return the mean times the volume.\n",
    "\n",
    "\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "def integrate_mc(rng, f, xmin, xmax, nsample=1000):\n",
    "    \"\"\"\n",
    "    Evaluate the definite integral of f(x) using MC integration.\n",
    "\n",
    "    rng:     random number generator with `uniform()` method.\n",
    "    f:       function to integrate, should be callable as `f(x)`.\n",
    "    xmin:    lower bound.\n",
    "    xmax:    upper bound.\n",
    "    nsample: number of points to sample.\n",
    "    \"\"\"\n",
    "    # Sample the points while tracking the sum of the function.\n",
    "    f_sum = 0\n",
    "    for i in range(0, nsample):\n",
    "        # Sample a uniform random number between xmin and xmax.\n",
    "        r = rng.uniform() * (xmax - xmin) + xmin\n",
    "        # Calculate the function and sum.\n",
    "        f_sum += f(r)\n",
    "    # Return the mean times the volume.\n",
    "    return f_sum / nsample * (xmax - xmin)\n",
    "\n",
    "\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the MC integration method with the quadrature methods for $n$ is $10$, $100$, $1000$, and $10000$, where $n$ is either the number of divisions or sampling points. How quickly is the MC integral converging?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "# The integrate method cannot pass arguments to f(x). So we use a lambda\n",
    "# function here to pass the parameters that we want.\n",
    "\n",
    "# Perform the integration and print.\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "# The integrate method cannot pass arguments to f(x). So we use a lambda\n",
    "# function here to pass the parameters that we want.\n",
    "f = lambda x: function_lff(x, a, b, m)\n",
    "\n",
    "# Perform the integration and print.\n",
    "for n in (10, 100, 1000, 10000):\n",
    "    integral = integrate_midpoint(f, 0, 1, n)\n",
    "    print(f\" midpoint integral (n = {n:5d}) = {integral:.5e}\")\n",
    "    integral = integrate_trapezoid(f, 0, 1, n)\n",
    "    print(f\"trapezoid integral (n = {n:5d}) = {integral:.5e}\")\n",
    "    integral = integrate_mc(rng, f, 0, 1, n)\n",
    "    print(f\"MC integral        (n = {n:5d}) = {integral:.5e}\")\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Exercise:_stratified_integration"
   },
   "source": [
    "### Exercise: stratified integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the previous example for a 1D function, MC integration does not converge quickly in comparison to quadrature methods. One way that this convergence can be enhanced is stratified sampling of the function. Just like for quadrature methods, where the function is subdivided, the same can be done for MC integration.\n",
    "\n",
    "$$\n",
    "\\int_a^b \\text{d}{x}\\, f(x) = \\sum \\int_{a_i}^{b_i} \\text{d}{x}\\, f(x) \\approx \\sum_i \\langle f(x) \\rangle_i (b_i - a_i)\n",
    "$$\n",
    "\n",
    "Here, $i$ indicates each subdivision of the integration limits. Again, the extension of this method to higher dimensions is relatively straight forward, where we now have $V_i$ indiciating each hypercube subdivision.\n",
    "\n",
    "$$\n",
    "\\int_V \\text{d}{\\vec{x}}\\, f(\\vec{x}) = \\sum \\int_{V_i} \\text{d}{\\vec{x}}\\,\n",
    "f(\\vec{x}) \\approx \\sum_i \\langle f(\\vec{x}) \\rangle_i V_i\n",
    "$$\n",
    "\n",
    "If we were to use regular subdivisions for stratified MC integration, and sample the same number of points from each subdivision, we would just recover our initial MC integration algorithm. So, how do we make this useful? We haven't talk about integration uncertainty in this notebook, but it is critical for setting up stratified integration. Without deriviation, the following can be shown.\n",
    "\n",
    "> The integration uncertainty is minimized if each subdivision is sampled proportional to the relative variance of that subdivision.\n",
    "\n",
    "So, how do we set up stratified integration?\n",
    "\n",
    "1. Create $m$ regular subdivisions of the integration limits.\n",
    "2. Track $\\sigma_i$, the variance of $f(x)$ for each subdivision. In practice, we actually store the mean of $f(x)$ and the mean of $f(x)^2$.\n",
    "3. Sample points from each subdivision proportional to the following probability.\n",
    "\n",
    "$$\n",
    "p_i = \\frac{\\sigma_i}{\\sum_j \\sigma_j}\n",
    "$$\n",
    "\n",
    "4. Track the MC integral for each subdivision, $F_i$.\n",
    "5. Return the sum of these integrals.\n",
    "\n",
    "Let us now implement a general stratified MC integration method with the skeleton below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "def integrate_mc_strat(rng, f, xmin, xmax, nsample=1000, mdiv=4, nwarm=100):\n",
    "    \"\"\"\n",
    "    Evaluate the definite integral of f(x) using stratified MC integration.\n",
    "    Returns a tuple of `integral`, `[counts]` so that the division of counts\n",
    "    can be analyzed.\n",
    "\n",
    "    rng:     random number generator with `uniform()` method.\n",
    "    f:       function to integrate, should be callable as `f(x)`.\n",
    "    xmin:    lower bound.\n",
    "    xmax:    upper bound.\n",
    "    nsample: number of points to sample.\n",
    "    mdiv:    number of subdivisions.\n",
    "    nwarm:   number of warmup points used to calculate the variance.\n",
    "    \"\"\"\n",
    "    # Set up the edges for the subdivisions. Since we sample x from a uniform\n",
    "    # distribution, these edges should just run from 0 to 1, we can then\n",
    "    # transform to xmin to max.\n",
    "\n",
    "    # Set up the sum of f(x) for each subdivision. We use this for the\n",
    "    # variance.\n",
    "    # Set up the number of sampled points per subdivision.\n",
    "\n",
    "    # We now need perform a warmup integration to determine our variances.\n",
    "    # There are other ways to do this, but for simplicity, we sample `nwarm`\n",
    "    # points per subdivision.\n",
    "    for j in range(0, mdiv - 1):\n",
    "        # Calculate the variance for this subdivision.\n",
    "        # Update the sum of variances.\n",
    "        pass\n",
    "\n",
    "    # Sample the points while tracking the sums of the function.\n",
    "    for i in range(0, nsample):\n",
    "        # Choose which subdivision `j` to sample from based on the relative\n",
    "        # variance.\n",
    "\n",
    "        # Sample a uniform random number between xmin and xmax for the chosen\n",
    "        # subdivision.\n",
    "        # Calculate the function and update the sums and counts.\n",
    "        pass\n",
    "\n",
    "    # Return the summed subdivision integrals.\n",
    "\n",
    "\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "def integrate_mc_strat(rng, f, xmin, xmax, nsample=1000, mdiv=4, nwarm=100):\n",
    "    \"\"\"\n",
    "    Evaluate the definite integral of f(x) using stratified MC integration.\n",
    "    Returns a tuple of `integral`, `[counts]` so that the division of counts\n",
    "    can be analyzed.\n",
    "\n",
    "    rng:     random number generator with `uniform()` method.\n",
    "    f:       function to integrate, should be callable as `f(x)`.\n",
    "    xmin:    lower bound.\n",
    "    xmax:    upper bound.\n",
    "    nsample: number of points to sample.\n",
    "    mdiv:    number of subdivisions.\n",
    "    nwarm:   number of warmup points used to calculate the variance.\n",
    "    \"\"\"\n",
    "    # Set up the edges for the subdivisions. Since we sample x from a uniform\n",
    "    # distribution, these edges should just run from 0 to 1, we can then\n",
    "    # transform to xmin to max.\n",
    "    edges = np.linspace(0, 1, mdiv)\n",
    "    dx = edges[1] - edges[0]\n",
    "\n",
    "    # Set up the sum of f(x) for each subdivision. We use this for the\n",
    "    # variance.\n",
    "    f_sums = [0] * mdiv\n",
    "    # Set up the number of sampled points per subdivision.\n",
    "    ns = [0] * mdiv\n",
    "\n",
    "    # We now need perform a warmup integration to determine our variances.\n",
    "    # There are other ways to do this, but for simplicity, we sample `nwarm`\n",
    "    # points per subdivision.\n",
    "    var_total = 0\n",
    "    var_sums = []\n",
    "    for j in range(0, mdiv - 1):\n",
    "        # Calculate the variance for this subdivision.\n",
    "        f_sum = 0\n",
    "        f2_sum = 0\n",
    "        for i in range(0, nwarm):\n",
    "            r = rng.uniform() * (edges[j + 1] - edges[j]) + edges[j]\n",
    "            fj = f(r)\n",
    "            f_sum += fj\n",
    "            f2_sum += fj**2\n",
    "        # Update the sum of variances.\n",
    "        var_total += (f2_sum - f_sum**2) / nwarm\n",
    "        var_sums += [var_total]\n",
    "\n",
    "    # Sample the points while tracking the sums of the function.\n",
    "    for i in range(0, nsample):\n",
    "        # Choose which subdivision `j` to sample from based on the relative\n",
    "        # variance.\n",
    "        r1 = rng.uniform()\n",
    "        for j, var_sum in enumerate(var_sums):\n",
    "            if r1 < var_sum / var_total:\n",
    "                break\n",
    "\n",
    "        # Sample a uniform random number between xmin and xmax for the chosen\n",
    "        # subdivision.\n",
    "        r = rng.uniform() * dx + edges[j]\n",
    "        # Calculate the function and update the sums and counts.\n",
    "        f_sums[j] += f(r)\n",
    "        ns[j] += 1\n",
    "\n",
    "    # Return the summed subdivision integrals.\n",
    "    total = 0\n",
    "    for j, (f_sum, n) in enumerate(zip(f_sums, ns)):\n",
    "        if n != 0:\n",
    "            total += f_sums[j] / n * dx\n",
    "    return total, ns\n",
    "\n",
    "\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us just check that our sratified integration is behaving sensibly. Our method returns both the integral and the number of counts per subdivision. Integrate the Lund fragmentation function we have been using with $1000$ sampling points (not including the warm up points) and $10$ subdivisions. The resulting number of counts per subdivision should roughly mirror the structure of the distribution, i.e., there should be more counts toward the peaking structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "# The integrate method cannot pass arguments to f(x). So we use a lambda\n",
    "# function here to pass the parameters that we want.\n",
    "\n",
    "# We perform the integration and print the returned number of counts list.\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "# The integrate method cannot pass arguments to f(x). So we use a lambda\n",
    "# function here to pass the parameters that we want.\n",
    "f = lambda x: function_lff(x, a, b, m)\n",
    "\n",
    "# We perform the integration and print the returned number of counts list.\n",
    "integral, ns = integrate_mc_strat(rng, f, 0, 1, 1000, 10)\n",
    "print(f\"sampled counts = {ns}\")\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us compare how quickly this converges with respect to the other methods. Note, this is not an entirely fair comparison, because we require $1000$ points for our \"warmup\" of sampling the variances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "# The integrate method cannot pass arguments to f(x). So we use a lambda\n",
    "# function here to pass the parameters that we want.\n",
    "\n",
    "# Perform the integration and print.\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "# The integrate method cannot pass arguments to f(x). So we use a lambda\n",
    "# function here to pass the parameters that we want.\n",
    "f = lambda x: function_lff(x, a, b, m)\n",
    "\n",
    "# Perform the integration and print.\n",
    "for n in (10, 100, 1000, 10000):\n",
    "    integral = integrate_midpoint(f, 0, 1, n)\n",
    "    print(f\" midpoint integral (n = {n:5d}) = {integral:.5e}\")\n",
    "    integral = integrate_trapezoid(f, 0, 1, n)\n",
    "    print(f\"trapezoid integral (n = {n:5d}) = {integral:.5e}\")\n",
    "    integral = integrate_mc(rng, f, 0, 1, n)\n",
    "    print(f\"MC integral        (n = {n:5d}) = {integral:.5e}\")\n",
    "    integral, ns = integrate_mc_strat(rng, f, 0, 1, n, 10)\n",
    "    print(f\"MC strat integral  (n = {n:5d}) = {integral:.5e}\")\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Exercise:_integration_with_AOR"
   },
   "source": [
    "### Exercise: integration with AOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the nice things about sampling with AOR, is that we can also perform an integral at the same time. The integral is just\n",
    "\n",
    "$$\n",
    "\\int_a^b \\text{d}x\\, f(x) \\approx \\varepsilon f_\\max (b - a),\n",
    "$$\n",
    "\n",
    "where $\\varepsilon$ is the sampling efficiency that we defined before. Again, this generalizes nicely to higher dimensions.\n",
    "\n",
    "$$\n",
    "\\int_V \\text{d}\\vec{x}\\, f(\\vec{x}) \\approx \\varepsilon V\n",
    "$$\n",
    "\n",
    "Use the `SampleAOB` class to integrate the Lund fragmentation function which we have been using as our test function. Sample $10000$ points. Do you expect this will converge faster or slower than the standard MC integration?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "# The integrate method cannot pass arguments to f(x). So we use a lambda\n",
    "# function here to pass the parameters that we want.\n",
    "\n",
    "# Create the sampler.\n",
    "\n",
    "# Sample 10000 points.\n",
    "\n",
    "# Calculate the integral from the efficiency and print.\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "# The integrate method cannot pass arguments to f(x). So we use a lambda\n",
    "# function here to pass the parameters that we want.\n",
    "f = lambda x: function_lff(x, a, b, m)\n",
    "\n",
    "# Create the sampler.\n",
    "sampler = SampleAOR(rng, 0, 1, line.f)\n",
    "\n",
    "# Sample 10000 points.\n",
    "for i in range(0, 10000):\n",
    "    sampler()\n",
    "\n",
    "# Calculate the integral from the efficiency and print.\n",
    "integral = sampler.e() * sampler.fmax * (sampler.xmax - sampler.xmin)\n",
    "print(f\"MC AOJ integral  (n = {n:5d}) = {integral:.5e}\")\n",
    "###STOP_SOLUTION"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Requirements",
    "Introduction",
    "Analytic_Sampling",
    "Exercise:_generic_sampler",
    "Exercise:_linear_function",
    "Exercise:_Breit-Wigner",
    "Exercise:_Gaussian",
    "Binned_Sampling",
    "Example:_histograms",
    "Example:_binned_sampling",
    "Accept-or-Reject_Sampling",
    "Exercise:_general_AOR",
    "Importance_Sampling",
    "Exercise:_general_importance_sampler",
    "Exercise:_even_more_linear_sampling",
    "Exercise:_Lund_fragmentation_function",
    "Multichannel_Sampling",
    "Exercise:_general_multichannel",
    "Exercise:_signal_on_background",
    "Quadrature_Integration",
    "Exercise:_midpoint_rule",
    "Exercise:_trapezoid_rule",
    "MC_Integration",
    "Exercise:_1D_MC_integration",
    "Exercise:_stratified_integration",
    "Exercise:_integration_with_AOR"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}