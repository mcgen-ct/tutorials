{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hadronization"
   },
   "source": [
    "# Hadronization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we'll develop an algorithm to hadronize a simple color-connected quark anti-quark ($q\\bar{q}$) system.\n",
    "\n",
    "Colliders probe energy scales where quarks and gluons interact perturbatively. As we saw in the previous tutorial, hard scattering events often produce colored partons that evolve via parton showers, radiating additional quarks and gluons. At the detector level, far below the QCD confinement scale, only color-neutral composite particles such as mesons, baryons, and occasionally exotic hadrons (e.g. tetraquarks or pentaquarks) are observed. To bridge this gap, Monte Carlo event generators must model the nonperturbative process that converts colored final state particles from the parton shower into observable hadrons. This process is known as hadronization. Many phenomenological models of hadronization exist, however, in modern event generators two models are favored: the Lund string model (Pythia) and the cluster model (Herwig, Sherpa). In this tutorial, we'll focus exclusively on the Lund string model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Requirements"
   },
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook requires a few external dependencies which are imported here. First we set up our plotting with `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Some additional plotting utilities for visualizing the light-cone and Lund\n",
    "# plane.\n",
    "from matplotlib.transforms import Affine2D\n",
    "from mpl_toolkits.axisartist.floating_axes import FloatingSubplot, GridHelperCurveLinear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we have a few local utilities that we need to represent vectors and particles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the `vector` and `particle` modules.\n",
    "!wget -q -N https://gitlab.com/mcgen-ct/tutorials/-/raw/main/.full/mc/vector.py\n",
    "!wget -q -N https://gitlab.com/mcgen-ct/tutorials/-/raw/main/.full/mc/particle.py\n",
    "\n",
    "# Import the necessary classes.\n",
    "from vector import FourVector\n",
    "from particle import ParticleDatabase, ParticleData, Particle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also need some particle data. We will use the Pythia particle data, which can be read by the `pdb` class we just imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the Pythia particle database.\n",
    "!wget -q -N https://gitlab.com/mcgen-ct/tutorials/-/raw/main/.full/mc/data/ParticleData.xml\n",
    "\n",
    "# Create a particle database we can use throughout this notebook.\n",
    "pdb = ParticleDatabase()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need a random number generator. We could use one of the RNGs implemented in [`rng.ipynb`](rng.ipynb), but instead we will use the default `numpy` RNG. We also need the `math` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the `numpy` and `math` modules.\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Create an RNG, with a seed of 10.\n",
    "rng = np.random.default_rng(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lund_string_model"
   },
   "source": [
    "## Lund string model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In QCD the potential between a static quark and anti-quark as a function of the distance between them is found to be\n",
    "\n",
    "$$\n",
    "V_{q\\bar{q}}(r) \\approx -\\frac{4\\alpha_s}{3}\\frac{1}{r} + \\kappa r .\n",
    "$$\n",
    "\n",
    "At short distances ($r < 0.1$ fm), the $1/r$ piece (stemming from one-gluon exchange (stemming from one-gluon exchange) dominates and the quarks behave as free \"Coulomb-like\" charged particles. At long distances, the linear component dominates, representing the collapse of gluonic field lines into a thin color flux tube or string with a constant tension (linear energy density) $\\kappa \\simeq 1 \\text{ GeV/fm} \\simeq 0.2 \\text{ GeV}^2$.\n",
    "\n",
    "The idea behind the Lund string model is that as a quark/anti-quark pair separate in position space, this flux tube is stretched out and the potential increases. At some point, it is more favorable to produce a new quark/anti-quark pair and break the string. The idea is that some initial string breaks multiple times to produce final state hadrons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "String_breaking"
   },
   "source": [
    "## String breaking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider center-of-mass frame of a $q_i \\bar{q}_i$ system where the (massless) partons, each with flavor index $i$ and initial energy $E$, travel with equal and opposite momenta along the $z$-axis. As the separation increases the confining force causes an approximately uniform cylindrical string (flux tube) of color field to form between the quark pair. In the absence of string breaks, our $q\\bar{q}$ system would follow an infinite \"yo-yo\" motion whereby the the systems energy oscillates between the kinetic energy of the quarks and the energy contained in the string.\n",
    "\n",
    "If we allow for string breaking during the separation process the energy in the string can be used to create $q'\\bar{q}'$ pairs out of the vacuum. This production breaks the original string into two fragments: a composite hadron $h \\equiv  q_i\\bar{q}'$ (or $q' \\bar{q_i}$) and another $q'\\bar{q}_i$ (or $q_i \\bar{q}'$)-string system. The ejected hadron inherits kinematics according to the model (and whose microscopic description in this model would be that of a mini-string following stable yo-yo motion as described above, i.e., yoyo-hadrons). The remaining string system continues its evolution and potentially fragments further into more hadrons.\n",
    "\n",
    "![Schematic illustration phase-space cuts.](https://github.com/mcgen-ct/tutorials/blob/main/.full/mc/figures/hadronization.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Exercise:_particle_data"
   },
   "source": [
    "### Exercise: particle data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get started creating a string system, we should make sure we understand how to work with the particle database. Access a charged pion and print all the relevant data that is stored for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "# The particle database is a dictionary. Access particles either by name or by\n",
    "# PDG ID.\n",
    "\n",
    "# Once you have the charged pion, then you can loop over its members, which\n",
    "# can be accessed via the `__dict__` member (which as you might guess is a\n",
    "# dictionary).\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "# Get the charged pion.\n",
    "pd = pdb[\"pi+\"]\n",
    "\n",
    "# Loop over its members and print.\n",
    "for key, val in pd.__dict__.items():\n",
    "    print(f\"--\\n{key}: {val}\")\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Exercise:_string_system"
   },
   "source": [
    "### Exercise: string system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now write a class to represent our string system consisting of two `Particle` instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QQBarString:\n",
    "    \"\"\"\n",
    "    Class to represent a quark-antiquark string system.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, e, pd):\n",
    "        \"\"\"\n",
    "        Initialize a symmetric q-qbar string system.\n",
    "\n",
    "        e:  energy of either string end in GeV.\n",
    "        pd: `ParticleData` for the type of quark.\n",
    "        \"\"\"\n",
    "        # Store the string-end energy.\n",
    "        self.e = e\n",
    "\n",
    "        # Define the particles.\n",
    "        self.q = Particle(pd, FourVector(e, 0, 0, e))\n",
    "        self.qbar = Particle(-pd, FourVector(e, 0, 0, -e))\n",
    "\n",
    "        # Store the string mass squared, ignoring thes masses of the quarks.\n",
    "        self.m2 = 4 * e**2\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"\n",
    "        Return a string to print this string system.\n",
    "        \"\"\"\n",
    "        return f\"q\\n{self.q}qbar\\n{self.qbar}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an instance of this string system with a string end energy of $50$ GeV and $u/\\bar{u}$ string ends. How do you access the momentum vector for each string end?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "# Create the string system.\n",
    "# Print the string system.\n",
    "# Print the momentum vector for each string end.\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "# Define the energy for each string end.\n",
    "e = 50.0\n",
    "\n",
    "# Create a QQBarString instance with the u/ubar ends.\n",
    "qqbar = QQBarString(e, pdb[\"u\"])\n",
    "\n",
    "# Print the string system.\n",
    "print(qqbar)\n",
    "\n",
    "# Print the momentum for each string end.\n",
    "print(f\"q:    {qqbar.q.p}\")\n",
    "print(f\"qbar: {qqbar.qbar.p}\")\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "String_Coordinates"
   },
   "source": [
    "## String Coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the string model, hadronization is typically implemented in momentum space as an iterative random walk through production (string-break) vertices, $v_i$. If we assume each string end to be massless, mass corrections can be incorporated later, they both follow light-like trajectories, motivating the use of light-cone coordinates. Given an arbitrary four-momentum $p^\\mu = (E, \\vec{p})$, the light-cone momenta are defined as:\n",
    "\n",
    "$$\n",
    "p^\\pm = E \\pm p_z\n",
    "$$\n",
    "\n",
    "and satisfy (in $1 + 1$ dimensions)\n",
    "\n",
    "$$\n",
    "p^+ p^- = m^2.\n",
    "$$\n",
    "\n",
    "Under Lorentz boosts, light-cone momenta have simple transformation properties\n",
    "\n",
    "$$\n",
    "p^{\\pm'} = e^{\\pm \\psi} p^\\pm, \\quad \\text{where } \\psi = \\frac{1}{2}\\ln{\\frac{1+\\beta}{1-\\beta}}\n",
    "$$\n",
    "\n",
    "with $\\beta$ defined as the boost velocity divided by the speed of light, $v/c$.\n",
    "\n",
    "The string itself has total light-cone momenta (defined at $t = 0$):\n",
    "\n",
    "$$\n",
    "P^+ = p_q^+ + p_{\\bar{q}}^+, \\quad P^- = p_q^- + q_{\\bar{q}}^-\n",
    "$$\n",
    "\n",
    "which in the string rest frame (both ends with equal energy, $E$, and opposite momenta along the $z$-axis, $p_z$) becomes,\n",
    "\n",
    "$$\n",
    "P^+ = 2E, \\quad P^- = 2E, \\quad P^+ P^- = M^2 = 4 E^2.\n",
    "$$\n",
    "\n",
    "where $M$ is the string mass.\n",
    "\n",
    "To further describe the fragmentation in dimensionless and string-normalized coordinates we also introduce light-cone momentum fractions, $x^{\\pm}$. These represent the light-cone separation between two breaks and are defined as\n",
    "\n",
    "$$\n",
    "x_i^{\\pm} = \\frac{p_i^\\pm}{P^\\pm}\n",
    "$$\n",
    "\n",
    "for the $i$-th hadron. These satisfy:\n",
    "\n",
    "$$\n",
    "x^+_i x^-_i = \\frac{m_i^2}{M^2}.\n",
    "$$\n",
    "\n",
    "For a specified hadron mass, we thus have a fixed relationship between $x^+_i$ and $x^-_i$. Note that the momentum fractions are normalized to the quark turning points such that $0 \\leq x^{\\pm} \\leq 1$. The figure below gives a useful schematic depiction of a fully hadronized string in energy-momentum space.\n",
    "\n",
    "![String system in momentum space.](https://github.com/mcgen-ct/tutorials/blob/main/.full/mc/figures/string.png?raw=1)\n",
    "\n",
    "where $\\hat{x}^{\\pm}$ represent the light-cone vertex coordinates, describing the location of production vertices.\n",
    "\n",
    "Very broadly, the hadronization of a string can be factorized into two components.\n",
    "1. **flavor production**: we need to choose the flavor of the hadrons that get produced and\n",
    "2. **kinematics**: we need to assign some four-momenta to each of the produced hadrons.\n",
    "Before jumping into the full hadronization algorithm we'll take a detour to build each of these components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Flavor"
   },
   "source": [
    "## Flavor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, for simplicity, we'll restrict the string breaks to $u\\bar{u}$ and $d\\bar{d}$ pairs, implying that the only (stable) hadrons available for production are the pions $\\pi^\\pm and \\pi^0$. This makes the problem of choosing hadron flavor relatively straight forward. For example, each of the four possible string ends have a unique assignment depending on the flavor of the break:\n",
    "1. $u$ string end\n",
    "    * $u\\bar{u}$ string break $\\to \\pi^0$\n",
    "    * $d\\bar{d}$ string break $\\to \\pi^+$\n",
    "2. $\\bar{u}$ string end\n",
    "    * $u\\bar{u}$ string break $\\to \\pi^0$\n",
    "    * $d\\bar{d}$ string break $\\to \\pi^-$\n",
    "3. $d$ string end\n",
    "    * $u\\bar{u}$ string break $\\to \\pi^-$\n",
    "    * $d\\bar{d}$ string break $\\to \\pi^0$\n",
    "4. $\\bar{d}$ string end\n",
    "    * $u\\bar{u}$ string break $\\to \\pi^+$\n",
    "    * $d\\bar{d}$ string break $\\to \\pi^0$\n",
    "\n",
    "So, given a string end, we can randomly select between a $u\\bar{u}$ or $d\\bar{d}$ break and assign hadron flavor accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StringFlav:\n",
    "    \"\"\"\n",
    "    Class to select a hadron flavor, given a string end.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rng, pdb):\n",
    "        \"\"\"\n",
    "        Initialize, given a random number generator and particle database.\n",
    "\n",
    "        pdb: `ParticleDatabase` object to access particle data.\n",
    "        \"\"\"\n",
    "        self.rng = rng\n",
    "        self.pdb = pdb\n",
    "\n",
    "    def __call__(self, end_pd):\n",
    "        \"\"\"\n",
    "        Return a new string end and hadron, each of type `ParticleData`.\n",
    "\n",
    "        end_pd: `ParticleData` object of the string end.\n",
    "        \"\"\"\n",
    "        # Given the string end, determine the possible hadrons and their\n",
    "        # corresponding probabilities. Given our simplified scenario,\n",
    "        # all the probabilites are [1/2, 1/2].\n",
    "        if end_pd.name == \"u\":\n",
    "            hadron_pds = [self.pdb[\"pi0\"], self.pdb[\"pi-\"]]\n",
    "            hadron_wgts = [1 / 2, 1 / 2]\n",
    "        elif end_pd.name == \"ubar\":\n",
    "            hadron_pds = [self.pdb[\"pi0\"], self.pdb[\"pi+\"]]\n",
    "            hadron_wgts = [1 / 2, 1 / 2]\n",
    "        elif end_pd.name == \"d\":\n",
    "            hadron_pds = [self.pdb[\"pi0\"], self.pdb[\"pi+\"]]\n",
    "            hadron_wgts = [1 / 2, 1 / 2]\n",
    "        elif end_pd.name == \"dbar\":\n",
    "            hadron_pds = [self.pdb[\"pi0\"], self.pdb[\"pi-\"]]\n",
    "            hadron_wgts = [1 / 2, 1 / 2]\n",
    "        else:\n",
    "            print(f\"Error: unsupported end_id {end_pd.pid}\")\n",
    "            return self.pdb[\"void\"], self.pdb[\"void\"]\n",
    "\n",
    "        # Select a hadron flavor based on the weights.\n",
    "        hadron_pd = rng.choice(hadron_pds, p=hadron_wgts)\n",
    "\n",
    "        # Use flavor conservation to determine the new string end.\n",
    "        # This list of PIDs are the constituent quark PIDs of the hadron.\n",
    "        quark_pids = hadron_pd.quarks()\n",
    "        # If the first quark matches the string end, use the second quark as\n",
    "        # the new string end, and vice versa.\n",
    "        if quark_pids[0] == abs(end_pd.pid):\n",
    "            new_pid = quark_pids[1]\n",
    "        elif quark_pids[1] == abs(end_pd.pid):\n",
    "            new_pid = quark_pids[0]\n",
    "        else:\n",
    "            new_pid = abs(end_pd.pid)\n",
    "\n",
    "        # Flip the sign if needed.\n",
    "        if end_pd.pid < 0:\n",
    "            new_pid = -new_pid\n",
    "\n",
    "        # Return the new string end and hadron.\n",
    "        return self.pdb[new_pid], hadron_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veryify that this selector correctly selects the flavor scenarios as outlined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "# Create the selector.\n",
    "#\n",
    "# Loop over the initial state quarks.\n",
    "# Print the string end.\n",
    "# Sample a few time and book-keep the states.\n",
    "# Print the result.\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "# Create the selector.\n",
    "flavor_selector = StringFlav(rng, pdb)\n",
    "# Loop over the initial state quarks.\n",
    "for i, end_pd in enumerate([pdb[\"u\"], pdb[\"ubar\"], pdb[\"d\"], pdb[\"dbar\"]]):\n",
    "    # Print the string end.\n",
    "    print(f\"({i + 1}) {end_pd.name}\")\n",
    "\n",
    "    # Sample a few times, and book-keep the states.\n",
    "    states = {}\n",
    "    for j in range(0, 1000):\n",
    "        new_pd, hadron_pd = flavor_selector(end_pd)\n",
    "        key = (new_pd, hadron_pd)\n",
    "        if not key in states:\n",
    "            states[key] = 1\n",
    "        else:\n",
    "            states[key] += 1\n",
    "\n",
    "    # Print the result.\n",
    "    total = sum([n for pds, n in states.items()])\n",
    "    states = [(n, pds) for pds, n in states.items()]\n",
    "    states.sort()\n",
    "    for n, (new_pd, hadron_pd) in states:\n",
    "        print(f\" -> {(n/total):.2f} {new_pd.name}, {hadron_pd.name}\")\n",
    "\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Exercise:_include_baryons"
   },
   "source": [
    "### Exercise: include baryons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How might baryon production be minimally included in the string model? The implementation is relatively non-trivial, we are not asking you to do that here, but rather just think about possible solutions. Identify the relevant particles in the particle database that could make this implementation possible. Hint, these particles have PIDs between 1000 and 6000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "# Loop over the particle database and check the PID is within the relevant\n",
    "# range.\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###START_SOLUTION\n",
    "\n",
    "If we want to produce a baryon, then this means that for a given string break we at a minimum we need to produce three quarks/anti-quarks plus the new string end, so four quarks/anti-quarks in total. Consider the following example.\n",
    "\n",
    "$$\n",
    "u \\to \\bar{q} ~(udd)\n",
    "$$\n",
    "\n",
    "There is no way that we can assign $\\bar{q}$ without violating quark number conservation, so that means that we really need to produce five.\n",
    "\n",
    "$$\n",
    "u \\to (\\bar{q}_i\\bar{q}_k) ~(udd)\n",
    "$$\n",
    "\n",
    "Now, we can actually assign $\\bar{q}_i$ and $\\bar{q_k}$ to make this work.\n",
    "\n",
    "$$\n",
    "u \\to (\\bar{d}\\bar{d})_j ~(udd)\n",
    "$$\n",
    "\n",
    "This composite object, $\\bar{d}\\bar{d})_j$ we call a diquark, where $j$ indicates the spin of that diquark. In this case $j = 1$.\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "# Loop over the particle database.\n",
    "# Only look at the integer keys.\n",
    "# Require exactly 2 quarks.\n",
    "# Sort and print the diquarks.\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "# Loop over the particle database.\n",
    "diquark_pds = []\n",
    "for name, pd in pdb.items():\n",
    "    # Only look at the integer keys.\n",
    "    if type(name) == int and 1000 < name < 6000:\n",
    "        # Require exactly 2 quarks.\n",
    "        quark_pids = pd.quarks()\n",
    "        if len(quark_pids) == 2:\n",
    "            diquark_pds += [pd]\n",
    "\n",
    "# Sort and print the diquarks.\n",
    "diquark_pds.sort()\n",
    "for diquark_pd in diquark_pds:\n",
    "    print(diquark_pd.name)\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kinematics"
   },
   "source": [
    "## Kinematics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the flavor selection of the previous selection, it is important to note that in our factorization, the flavor does not depend upon the kinematics. This is actually quite important when implementing the string model. It means that we can first select the flavor, and then select kinematics. It is important to note, however, that in some variants of the string model, the flavor does depend on the kinematics. This complicates the algorithm because the kinematics and flavor need to be either selected iteratively, or simulateously.\n",
    "\n",
    "In any case, with the model that we are building here, flavor does not depend upon kinematics. This means that we can now turn to sampling kinematics, assuming we already have selected a flavor.\n",
    "\n",
    "The longitudinal momentum fraction, $z$, is defined as the fraction of longitudinal momentum (light-cone momentum $p^{\\pm}_i$) absorbed by the $i$-th hadron from the remaining longitudinal momentum in the string system. This is similar, but distinct, from the light-cone momentum fractions we defined above. They are related by,\n",
    "\n",
    "$$\n",
    "x^+_1 = z_1, \\quad x^+_i = z_i \\prod_{j = 1}^{i-1}(1-z_j)\\text{ for }i > 1.\n",
    "$$\n",
    "\n",
    "From the transformations defined above, we see that $z^\\pm$ is manifestly invariant under boosts. The distribution from which $z$ is sampled is called the Lund left-right symmetric scaling fragmentation function, which is quite a mouthful so we will abbreviate it the LFF (Lund fragmentation function). The LFF is proportional to the following\n",
    "\n",
    "$$\n",
    "f(z)\\,\\text{d}z \\propto \\frac{(1-z)^a}{z}\\exp \\left(-b \\frac{m_h^2}{z} \\right) \\,\\text{d}z\n",
    "$$\n",
    "\n",
    "where $a$ and $b$ are tuneable phenomenological parameters fit to empirical data. Why do we only give the proportionality? It turns out normalizing this function to be a proper probability distribution function is not quite so trivial.\n",
    "\n",
    "It turns out that it is even harder to sample this distribution. If you need some more details on how to sample distributions, take a look at [`integrate.ipynb`](integrate.ipynb); good luck integrating and inverting this function. This means that we will need to use some other technique, so let's start off with accept-and-reject."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Exercise:_the_Lund_fragmentation_function"
   },
   "source": [
    "### Exercise: the Lund fragmentation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that it is even harder to sample this distribution. If you need some more details on how to sample distributions, take a look at [`integrate.ipynb`](integrate.ipynb); good luck integrating and inverting this function. This means that we will need to use some other technique, so let's start off with accept-and-reject. Since we will be slightly concerned with efficiency, we should also track the accept and rejects of this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "class StringZFlat:\n",
    "    \"\"\"\n",
    "    Class to sample the Lund fragmentation function using flat\n",
    "    accept-and-reject.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rng, a=0.68, b=0.98, fmax=10):\n",
    "        \"\"\"\n",
    "        Create a Lund fragmentation function sampler. The\n",
    "        default `a` and `b` values are taken from the Monash tune.\n",
    "\n",
    "        rng:  random number generator for sampling.\n",
    "        a:    `a` parameter from the LFF.\n",
    "        b:    `b` parameter from the LFF.\n",
    "        fmax: maximum value for the LFF.\n",
    "        \"\"\"\n",
    "        # Store the members of this class.\n",
    "        self.accept = 0\n",
    "        self.reject = 0\n",
    "\n",
    "    def e(self):\n",
    "        \"\"\"\n",
    "        Return the current efficiency of the sampler.\n",
    "        \"\"\"\n",
    "        return self.accept / (self.accept + self.reject)\n",
    "\n",
    "    def f(self, z, m):\n",
    "        \"\"\"\n",
    "        Return the Lund fragmentation function.\n",
    "\n",
    "        z: longitudinal momentum fraction.\n",
    "        m: mass of the hadron.\n",
    "        \"\"\"\n",
    "        return 0.0\n",
    "\n",
    "    def __call__(self, m, nmax=1000):\n",
    "        \"\"\"\n",
    "        Sample the Lund fragmentation function given a mass `m`.\n",
    "\n",
    "        m:    hadron mass to use when sampling.\n",
    "        nmax: number of times to sample before returning.\n",
    "        \"\"\"\n",
    "        # Loop over maximum number of samples.\n",
    "        # Uniformly sample `z`.\n",
    "        # Calculate `f`.\n",
    "        # Sample a number between 0 and `fmax`.\n",
    "        # Warn if we exceed our maximum.\n",
    "        # Return if accepted.\n",
    "        self.accept += 1\n",
    "        # Otherwise, increment reject.\n",
    "        self.reject += 1\n",
    "\n",
    "        # Return if max attempts.\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "class StringZFlat:\n",
    "    \"\"\"\n",
    "    Class to sample the Lund fragmentation function using flat\n",
    "    accept-and-reject.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rng, a=0.68, b=0.98, fmax=10):\n",
    "        \"\"\"\n",
    "        Create a Lund fragmentation function sampler. The\n",
    "        default `a` and `b` values are taken from the Monash tune.\n",
    "\n",
    "        rng:  random number generator for sampling.\n",
    "        a:    `a` parameter from the LFF.\n",
    "        b:    `b` parameter from the LFF.\n",
    "        fmax: maximum value for the LFF.\n",
    "        \"\"\"\n",
    "        # Store the members of this class.\n",
    "        self.rng = rng\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        self.fmax = fmax\n",
    "        # Only print the warnings once.\n",
    "        self.warn_over = True\n",
    "        self.warn_nmax = True\n",
    "        # Track the accept and rejects.\n",
    "        self.accept = 0\n",
    "        self.reject = 0\n",
    "\n",
    "    def e(self):\n",
    "        \"\"\"\n",
    "        Return the current efficiency of the sampler.\n",
    "        \"\"\"\n",
    "        return self.accept / (self.accept + self.reject)\n",
    "\n",
    "    def f(self, z, m):\n",
    "        \"\"\"\n",
    "        Return the Lund fragmentation function.\n",
    "\n",
    "        z: longitudinal momentum fraction.\n",
    "        m: mass of the hadron.\n",
    "        \"\"\"\n",
    "        if z == 0:\n",
    "            return 0.0\n",
    "        return ((1 - z) ** self.a / z) * math.exp(-(self.b * m**2) / z)\n",
    "\n",
    "    def __call__(self, m, nmax=1000):\n",
    "        \"\"\"\n",
    "        Sample the Lund fragmentation function given a mass `m`.\n",
    "\n",
    "        m:    hadron mass to use when sampling.\n",
    "        nmax: number of times to sample before returning.\n",
    "        \"\"\"\n",
    "        # Loop over maximum number of samples.\n",
    "        for i in range(0, nmax):\n",
    "            # Uniformly sample `z`.\n",
    "            z = self.rng.uniform()\n",
    "            # Calculate `f`.\n",
    "            f = self.f(z, m)\n",
    "            # Sample a number between 0 and `fmax`.\n",
    "            u = rng.uniform() * self.fmax\n",
    "            # Warn if we exceed our maximum.\n",
    "            if f > self.fmax and self.warn_over:\n",
    "                print(\"Warning: f(z) > f_max(z)\")\n",
    "                self.warn_over = False\n",
    "            # Return if accepted.\n",
    "            if u < f:\n",
    "                self.accept += 1\n",
    "                return z\n",
    "            else:\n",
    "                self.reject += 1\n",
    "        # Return, but warn about attempts.\n",
    "        if self.warn_nmax:\n",
    "            print(\"Warning: sampling f(z) exceeded `nmax` attempts\")\n",
    "        self.warn_nmax = False\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can sample some $z$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "# Create an LFF sampler.\n",
    "\n",
    "# Set the mass to sample, use the pi+.\n",
    "\n",
    "# Generate 10000 random z values.\n",
    "rzs = [0, 0.5, 1]\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "# Create an LFF sampler.\n",
    "kinematic_sampler = StringZFlat(rng)\n",
    "\n",
    "# Set the mass to sample, use the pi+.\n",
    "m = pdb[\"pi+\"].mass\n",
    "\n",
    "# Generate 10000 random z values.\n",
    "rzs = [kinematic_sampler(m) for i in range(0, 10000)]\n",
    "print(f\"sampling efficieny = {kinematic_sampler.e()}\")\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, we would like to know whether these $z$ values match our target distribution from the LFF. Set up a regularly spaced grid of $z$ values, calculate the LFF for each, and then normalize these values using numerical integration (the mid-point rule is sufficient)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "# Set up vector of z values to calculate the LFF.\n",
    "azs = [0, 1]\n",
    "\n",
    "# Calculate the analytic LFF values.\n",
    "afs = [1, 1]\n",
    "\n",
    "# Calculate normalization factor by the mid-point rule.\n",
    "\n",
    "# Normalize the `afs`.\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "# Set up vector of z values to calculate the LFF.\n",
    "azs = np.linspace(0, 1, 1000)\n",
    "\n",
    "# Calculate the analytic LFF values.\n",
    "afs = [kinematic_sampler.f(z, m) for z in azs]\n",
    "\n",
    "# Calculate normalization factor by the mid-point rule.\n",
    "dz = azs[1] - azs[0]\n",
    "nf = sum(afs) * dz\n",
    "\n",
    "# Normalize the `afs`.\n",
    "afs = [f / nf for f in afs]\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we plot the sampled distribution and analytic function, and compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the plot.\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot a normalize histogram of the sampled values.\n",
    "ax.hist(rzs, bins=100, density=True, label=\"sampled\")\n",
    "ax.set_xlabel(r\"$z$\")\n",
    "ax.set_ylabel(\"PDF($z$)\")\n",
    "\n",
    "# Plot the normalized analytic LFF.\n",
    "ax.plot(azs, afs, label=\"analytic\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This does not look so good, so what is going on? It turns out that we don't have the maximum of our function correct. We have taken a maximum of `fmax = 10`, so how badly do we violate this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "# Find the maximum of the LFF, without normalization.\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "print(f\"fmax = {max([kinematic_sampler.f(z, m) for z in azs])}\")\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that this is not so bad. Go back and see what happens if you increase your `fmax` when sampling $z$. Hopefully your distribution looks a little better. However, we are not very efficient with our sampling. Below, we implement a more efficient sampler using importance sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Exercise:_better_sampling"
   },
   "source": [
    "### Exercise: better sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to get a better picture for what the LFF looks like for different parameters. Choose a selection of $a$, $b$, and $m$ and plot the LFF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "# Set up vector of z values to calculate the LFF.\n",
    "\n",
    "# Create the plot.\n",
    "\n",
    "# Loop over the a, b, and m parameter space.\n",
    "# Get the analytic values of the LFF.\n",
    "# Divide these values by their maximum.\n",
    "# Plot the analytic LFF.\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "# Set up vector of z values to calculate the LFF.\n",
    "azs = np.linspace(0, 1, 100)\n",
    "\n",
    "# Create the plot.\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(r\"$z$\")\n",
    "ax.set_ylabel(\"PDF($z$)\")\n",
    "\n",
    "# Loop over the a and b parameter space.\n",
    "for a in np.linspace(0, 2, 3):\n",
    "    for b in np.linspace(0.2, 2, 3):\n",
    "        for m in np.linspace(0.1, 1, 3):\n",
    "            # Get the analytic values of the LFF.\n",
    "            kinematic_sampler = StringZFlat(rng, a, b)\n",
    "            afs = [kinematic_sampler.f(z, m) for z in azs]\n",
    "            fmax = max(afs)\n",
    "            afs = [f / fmax for f in afs]\n",
    "\n",
    "            # Plot the analytic LFF.\n",
    "            ax.plot(azs, afs, label=\"analytic\")\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns out this is a surprisingly complicated function. In Pythia, there is quite a bit of technical work that is done to sample this efficiently, which we are not going to do here.\n",
    "\n",
    "It is important to note that the what really changes the distribution is the mass of the hadron. So, if we limit the range of the hadron mass, this also means we can be more efficient with our sampling. So, let's do this and then perform importance sampling using a linear function defined as follows.\n",
    "\n",
    "1. Determine the maximum $f_\\max(z, m)$ within the range of $m$.\n",
    "2. Determine the maximum $f(1, m)$ within the range of $m$.\n",
    "3. Use these two points to define the oversampling function $g(z)$.\n",
    "\n",
    "There is some question about how we sample $g(x)$. We can either do this entirely analytically, or with multichannel sampling. Here, we opt for analytically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StringZ:\n",
    "    \"\"\"\n",
    "    Class to sample the Lund fragmentation function using\n",
    "    multi-channel sampling.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rng, a=0.68, b=0.98, mlim=(0.12, 0.15)):\n",
    "        \"\"\"\n",
    "        Create a Lund fragmentation function sampler.\n",
    "\n",
    "        rng:  random number generator for sampling.\n",
    "        a:    `a` parameter from the LFF.\n",
    "        b:    `b` parameter from the LFF.\n",
    "        mlim: limits on the hadron mass for sampling.\n",
    "        \"\"\"\n",
    "        # Store the members of this class.\n",
    "        self.rng = rng\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        # Only print the warnings once.\n",
    "        self.warn_over = True\n",
    "        self.warn_nmax = True\n",
    "        # Track the accept and rejects.\n",
    "        self.accept = 0\n",
    "        self.reject = 0\n",
    "\n",
    "        # Scan the sampling grid.\n",
    "        f1, z1 = 0, 0\n",
    "        f2, z2 = 0, 1\n",
    "        n = 0 if mlim[0] == mlim[1] else 100\n",
    "        for m in np.linspace(mlim[0], mlim[1], n):\n",
    "            for z in np.linspace(0, 1, 100):\n",
    "                f = self.f(z, m)\n",
    "                if f > f1:\n",
    "                    f1, z1 = f, z\n",
    "            if f > f2:\n",
    "                f2, z2 = f, 1.0\n",
    "\n",
    "        # Build the slope-intercept form.\n",
    "        if z1 == z2:\n",
    "            self.g_m = 0\n",
    "            self.g_b = f1\n",
    "        else:\n",
    "            self.g_m = (f2 - f1) / (z2 - z1)\n",
    "            self.g_b = f1 - self.g_m * z1\n",
    "\n",
    "        # Calculate the area and G(z_min).\n",
    "        self.area = self.G(1) - self.G(0)\n",
    "        self.g0 = self.G(0)\n",
    "\n",
    "    def e(self):\n",
    "        \"\"\"\n",
    "        Return the current efficiency of the sampler.\n",
    "        \"\"\"\n",
    "        return self.accept / (self.accept + self.reject)\n",
    "\n",
    "    def f(self, z, m):\n",
    "        \"\"\"\n",
    "        Return the Lund fragmentation function.\n",
    "\n",
    "        z: longitudinal momentum fraction.\n",
    "        m: mass of the hadron.\n",
    "        \"\"\"\n",
    "        if z == 0:\n",
    "            return 0.0\n",
    "        return ((1 - z) ** self.a / z) * math.exp(-(self.b * m**2) / z)\n",
    "\n",
    "    def g(self, z):\n",
    "        \"\"\"\n",
    "        Return the oversampling function.\n",
    "        \"\"\"\n",
    "        return self.g_m * z + self.g_b\n",
    "\n",
    "    def g_rand(self):\n",
    "        \"\"\"\n",
    "        Sample the oversampling function.\n",
    "        \"\"\"\n",
    "        r = self.rng.uniform()\n",
    "        return self.G_inv(self.g0 + self.area * r)\n",
    "\n",
    "    def G(self, z):\n",
    "        \"\"\"\n",
    "        Return the integrated oversampling function.\n",
    "        \"\"\"\n",
    "        return self.g_m * z**2 / 2 + self.g_b * z\n",
    "\n",
    "    def G_inv(self, f):\n",
    "        \"\"\"\n",
    "        Return the inverse of the integrated oversampling function.\n",
    "        \"\"\"\n",
    "        if self.g_m == 0:\n",
    "            return f / self.g_b\n",
    "        else:\n",
    "            return abs(\n",
    "                ((self.g_b**2 + 2 * self.g_m * f) ** 0.5 - self.g_b) / self.g_m\n",
    "            )\n",
    "\n",
    "    def __call__(self, m, nmax=1000):\n",
    "        \"\"\"\n",
    "        Sample the Lund fragmentation function given a mass `m`.\n",
    "\n",
    "        m:    hadron mass to use when sampling.\n",
    "        nmax: number of times to sample before returning.\n",
    "        \"\"\"\n",
    "        # Loop over maximum number of samples.\n",
    "        for i in range(0, nmax):\n",
    "            # Analytically sample `z` from g(z).\n",
    "            z = self.g_rand()\n",
    "            # Calculate `f`.\n",
    "            f = self.f(z, m)\n",
    "            # Sample a number between 0 and `g(z)`.\n",
    "            u = rng.uniform() * self.g(z)\n",
    "            # Warn if we exceed our maximum.\n",
    "            if f > self.g(z) and self.warn_over:\n",
    "                print(\"Warning: f(z) > g(z)\")\n",
    "                self.warn_over = False\n",
    "            # Return if accepted.\n",
    "            if u < f:\n",
    "                self.accept += 1\n",
    "                return z\n",
    "            else:\n",
    "                self.reject += 1\n",
    "        # Return, but warn about attempts.\n",
    "        if self.warn_nmax:\n",
    "            print(\"Warning: sampling f(z) exceeded `nmax` attempts\")\n",
    "        self.warn_nmax = False\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check whether our oversampling function is itself being sampled correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "# Create an LFF sampler.\n",
    "\n",
    "# Sample the distribution.\n",
    "\n",
    "# Calculate the analytic g(z) values.\n",
    "\n",
    "# Calculate normalization factor by the mid-point rule.\n",
    "\n",
    "# Create the plot.\n",
    "\n",
    "# Plot a normalize histogram of the sampled values.\n",
    "\n",
    "# Plot the normalized analytic LFF.\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "# Create an LFF sampler.\n",
    "kinematic_sampler = StringZ(rng)\n",
    "\n",
    "# Sample the distribution.\n",
    "rzs = [kinematic_sampler.g_rand() for i in range(0, 100000)]\n",
    "\n",
    "# Analytic z values.\n",
    "azs = np.linspace(0, 1, 1000)\n",
    "\n",
    "# Calculate the analytic g(z) values.\n",
    "ags = [kinematic_sampler.g(z) for z in azs]\n",
    "\n",
    "# Calculate normalization factor by the mid-point rule.\n",
    "dz = azs[1] - azs[0]\n",
    "ng = sum(ags) * dz\n",
    "\n",
    "# Normalize the `ags`.\n",
    "ags = [f / ng for f in ags]\n",
    "\n",
    "# Create the plot.\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot a normalize histogram of the sampled values.\n",
    "ax.hist(rzs, bins=100, density=True, label=\"sampled\")\n",
    "ax.set_xlabel(r\"$z$\")\n",
    "ax.set_ylabel(\"PDF($z$)\")\n",
    "\n",
    "# Plot the normalized analytic LFF.\n",
    "ax.plot(azs, ags, label=\"analytic\")\n",
    "ax.legend()\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the efficiency for this sampler?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "# Create an LFF sampler using the `StringZ` class.\n",
    "\n",
    "# Set the mass to sample, use the pi+.\n",
    "\n",
    "# Generate 10000 random z values.\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "# Create an LFF sampler.\n",
    "kinematic_sampler = StringZ(rng)\n",
    "\n",
    "# Set the mass to sample, use the pi+.\n",
    "m = pdb[\"pi+\"].mass\n",
    "\n",
    "# Generate 10000 random z values.\n",
    "rzs = [kinematic_sampler(m) for i in range(0, 10000)]\n",
    "print(f\"sampling efficieny = {kinematic_sampler.e()}\")\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The efficiency of this sampler is perhaps not as good as we might like. However, the really important feature is that we do not have to specify an `fmax` for a function, rather this is determined automatically. This is particularly important if we working with a wide range of hadron masses. This becomes even more import when we also include more dimensions in the string model. In any case, we should still check that our generated distribution matches our target analytic distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "# Set up vector of z values to calculate the LFF.\n",
    "azs = np.linspace(0, 1, 1000)\n",
    "\n",
    "# Calculate the analytic LFF values.\n",
    "afs = [kinematic_sampler.f(z, m) for z in azs]\n",
    "\n",
    "# Calculate normalization factor by the mid-point rule.\n",
    "dz = azs[1] - azs[0]\n",
    "nf = sum(afs) * dz\n",
    "\n",
    "# Normalize the `afs`.\n",
    "afs = [f / nf for f in afs]\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the plot.\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot a normalize histogram of the sampled values.\n",
    "ax.hist(rzs, bins=100, density=True, label=\"sampled\")\n",
    "ax.set_xlabel(r\"$z$\")\n",
    "ax.set_ylabel(\"PDF($z$)\")\n",
    "\n",
    "# Plot the normalized analytic LFF.\n",
    "ax.plot(azs, afs, label=\"analytic\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Algorithmic_overview"
   },
   "source": [
    "## Algorithmic overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, let's consider the fragmentation of the $q\\bar{q}$ system in 1 + 1 dimensions $(E, p_z)$ or $(t, z)$. Later we'll see how transverse momentum is included via string breaking. In terms of the iterative program for the left-right symmetric Lund model it can be summarized as follows:\n",
    "\n",
    "1. Randomly select from which string end the fragmentation will take place.\n",
    "2. Select a new $q'\\bar{q}'$ and hadron to be produced using `StringFlav`.\n",
    "3. Sample $z$ according to the Lund fragmentation function using `StringZ`.\n",
    "4. Compute production vertices.\n",
    "5. Update all momenta.\n",
    "6. Proceed through steps (1) - (5) until the center of mass energy of the new string system falls below a given cut off threshold $M^2_{\\text{min}}$.\n",
    "\n",
    "It's instructive to iterate through the algorithm a few time to get a feel for how it works. Let's assume, for simplicity, that we will only fragment from the $q$ side of the string (denoted as `fromPos` in the code). This is not how it's done in practice (equal probability between the $q$ or $\\bar{q}$ end) but the simplification reduces the algorithmic complexity and readability. At the end of the day, allowing for the string to randomly fragment from either side only requires extra bookkeeping.\n",
    "\n",
    "To start, we need to set up our $q\\bar{q}$ system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a system of u/ubar, where each quark has an energy of 0.5 GeV.\n",
    "qqbar = QQBarString(0.5, pdb[\"u\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need a new hadron and string end, so we use `StringFlav`. Then, we need a new $z$ for the hadron and so we use our `StringZ`. Since we are going to do this multiple times, we should probably define a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_next(flav, kin, end_pd, step=None):\n",
    "    \"\"\"\n",
    "    Generate the next string end, hadron, and hadron `z`.\n",
    "\n",
    "    flav:   flavor selector of type `StringFlav`.\n",
    "    kin:    kinematic selector of type `StringZ`.\n",
    "    end_pd: particle data for the string end of type `ParticleData`.\n",
    "    step:   if an integer, print the step out.\n",
    "    \"\"\"\n",
    "    # First, get the new string end and hadron.\n",
    "    new_pd, had_pd = flav(end_pd)\n",
    "    # Next, sample the hadron `z`.\n",
    "    had_z = kin(had_pd.mass)\n",
    "    # Print if requested.\n",
    "    if type(step) == int:\n",
    "        print(f\"({step}) {end_pd.name} -> {new_pd.name}, {had_pd.name}\")\n",
    "        print(f\"    {had_pd.name} z: {had_z:.2e}\")\n",
    "    return (new_pd, had_pd, had_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us generate our first new string end and hadron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the flavor selector.\n",
    "flav = StringFlav(rng, pdb)\n",
    "\n",
    "# Create a StringZ instance.\n",
    "kin = StringZ(rng)\n",
    "\n",
    "# Get the end `ParticleData` of the string (from the q end).\n",
    "end0_pd = qqbar.q.data\n",
    "\n",
    "# Generate the new string end, hadron, and hadron `z` for step 1.\n",
    "end1_pd, had1_pd, had1_z = string_next(flav, kin, end0_pd, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compute the string break vertices. From the [String Coordinates](#scrollTo=String_Coordinates) we have the following.\n",
    "\n",
    "$$\n",
    "x^+_i = z_i \\prod_{j = 0}^{i-1}(1 - z_j)\n",
    "$$\n",
    "\n",
    "$$\n",
    "x^-_i = \\frac{m_i^2}{x^+_i M^2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{x}^+_i = \\hat{x}^+_{i-1} - x^+_i\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{x}^-_i = \\hat{x}^-_{i-1} + x^-_i\n",
    "$$\n",
    "\n",
    "For the initial step, before any hadrons have been produced, we have $z_0 = 0$, $\\hat{x}^+_0 = 1$, and $\\hat{x}^-_0 = 0$. This then gives us the following for the first step.\n",
    "\n",
    "$$\n",
    "x^+_1 = z_1\n",
    "$$\n",
    "\n",
    "$$\n",
    "x^-_1 = \\frac{m_1^2}{x^+_1 M^2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{x}^+_1 = 1 - z_1\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{x}^-_1 = \\frac{m_1^2}{x^+_1 M^2}\n",
    "$$\n",
    "\n",
    "Again, since we are going to be doing this a few times, it's useful to define a function that does this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_vertex(string, xhp0, xhm0, prod_z, had_z, had_pd, step=None):\n",
    "    \"\"\"\n",
    "    Calculate the string vertex. Returns (x^+, x^-, xhat^+, xhat^-) of the\n",
    "    current step.\n",
    "\n",
    "    xhp0:   xhat^+ of the previous step.\n",
    "    xhm0:   xhat^- of the previous step.\n",
    "    prod_z: product of (1 - z) up to this step.\n",
    "    had_z:  hadron z of this step.\n",
    "    had_pd: hadron `ParticleData` of the current step.\n",
    "    \"\"\"\n",
    "    xp = had_z * prod_z\n",
    "    xm = had_pd.mass**2 / (xp * string.m2)\n",
    "    xhp = xhp0 - xp\n",
    "    xhm = xhm0 + xm\n",
    "    if type(step) == int:\n",
    "        print(f\"({step}) x^+   : {xp:8.2e}, x^-   : {xm:8.2e}\")\n",
    "        print(f\"    xhat^+: {xhp:8.2e}, xhat^-: {xhm:8.2e}\")\n",
    "    return (xp, xm, xhp, xhm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set our initial values.\n",
    "prod_z = 1\n",
    "xhp0 = 1\n",
    "xhm0 = 0\n",
    "\n",
    "# Calculate the string vertex.\n",
    "xp1, xm1, xhp1, xhm1 = string_vertex(qqbar, xhp0, xhm0, prod_z, had1_z, had1_pd, 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will be useful to visualize each break on the light-cone \"unit square\". We building an actual version of the figure from the [String Coordinates](scrollTo=String_Coordinates) section. Again, since we will be doing this multiple times, it is useful to define a function which make this plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_plot(xhps, xhms, nmax=None):\n",
    "    \"\"\"\n",
    "    Plot the breaks of a string.\n",
    "\n",
    "    xhps: xhat^+ coordinates for the vertices.\n",
    "    xhms: xhat^- coordinates for the vertices.\n",
    "    nmax: maximum number of breaks to plot. If `None`, then determine from\n",
    "          the passed list of coordinates.\n",
    "    \"\"\"\n",
    "    # Create the plot.\n",
    "    fig = plt.figure()\n",
    "\n",
    "    # We typically look at this type of plotted rotated by 45 degrees,\n",
    "    # so we define a transformation here.\n",
    "    transform = Affine2D().rotate_deg(45)\n",
    "    helper = GridHelperCurveLinear(transform, extremes=(0, 1, 0, 1))\n",
    "    ax = FloatingSubplot(fig, 111, grid_helper=helper)\n",
    "    fig.add_subplot(ax)\n",
    "\n",
    "    # Create auxiliary axis to plot in original coordinates.\n",
    "    aux_ax = ax.get_aux_axes(transform)\n",
    "\n",
    "    # Axis labels.\n",
    "    ax.axis[\"left\"].label.set_text(r\"$\\hat{x}^-$\")\n",
    "    ax.axis[\"left\"].label.set_pad(25)\n",
    "    ax.axis[\"left\"].label.set_rotation(0)\n",
    "    ax.axis[\"bottom\"].label.set_text(r\"$\\hat{x}^+$\")\n",
    "    ax.axis[\"bottom\"].label.set_pad(15)\n",
    "    ax.axis[\"bottom\"].major_ticklabels.set_rotation(270)\n",
    "\n",
    "    # Create a color map with distinct colors based on the number of vertices.\n",
    "    if nmax == None:\n",
    "        nmax = len(xhps)\n",
    "    colors = plt.cm.rainbow(np.linspace(0, 1, nmax))\n",
    "\n",
    "    # Loop over the coordinates and draw lines for each vertex.\n",
    "    for i, (xhp, xhm) in enumerate(zip(xhps, xhms)):\n",
    "        # Draw a dotted line at xhat^+.\n",
    "        aux_ax.plot([xhp, xhp], [0, 1], linestyle=\"--\", color=colors[i], linewidth=0.5)\n",
    "        # Draw a dotted line at xhat^+.\n",
    "        aux_ax.plot([0, 1], [xhm, xhm], linestyle=\"--\", color=colors[i], linewidth=0.5)\n",
    "        # Plot a point at the intersection.\n",
    "        aux_ax.plot(xhp, xhm, \"o\", markersize=5, color=colors[i])\n",
    "\n",
    "    # Add a grid.\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "    ax.set_aspect(\"equal\")\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use this function to plot the breaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the vertices up to this point. We are going to look at 3 vertices, so\n",
    "# we set `nmax` to 3.\n",
    "string_plot([xhp0, xhp1], [xhm0, xhm1], 3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the second iteration, which is a little more interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the new string end, hadron, and hadron `z` for step 2.\n",
    "end2_pd, had2_pd, had2_z = string_next(flav, kin, end0_pd, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the second vertex, we can again work out what our vertex coordinates are.\n",
    "\n",
    "$$\n",
    "x^+_2 = z_2 (1 - z_1)\n",
    "$$\n",
    "\n",
    "$$\n",
    "x^-_2 = \\frac{m_2^2}{x^+_2 M^2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{x}^+_2 = \\hat{x}^+_1 - x^+_2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{x}^-_2 = \\hat{x}^-_1 + x^-_2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we already defined a function that does this calculation, we can just use that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the product of (1 - z).\n",
    "prod_z *= 1 - had1_z\n",
    "\n",
    "# Calcuate the next string vertex.\n",
    "xp2, xm2, xhp2, xhm2 = string_vertex(qqbar, xhp1, xhm1, prod_z, had2_z, had2_pd, 2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can plot the vertices again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the vertices up to this point.\n",
    "string_plot([xhp0, xhp1, xhp2], [xhm0, xhm1, xhm2], 3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rinse and repeat. Eventually we will get to a point where energy and momentum conservation of the outgoing hadrons should creep up on us. For example, we will eventually reach a point where the remaining string mass is too small to produce any hadrons that we have access to - we should stop the fragmentation chain before we get here so we can maybe do something a little smarter. A possibly good condition would be to stop right around when the remaining area is roughly the size of two of the largest hadron masses that we can produce (remember, the last vertex that we select is actually producing the final two hadrons), which in our case, is just two pions\n",
    "\n",
    "$$\n",
    "\\hat{x}^+_n(1 - \\hat{x}^-_n)M^2 \\approx (2m_\\pi)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iterative_fragmentation"
   },
   "source": [
    "## Iterative fragmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we implement the full algorithm, we need to be able to convert from the momentum fractions to (in principle observable) hadron four-momenta. Consider the four-vectors\n",
    "$$\n",
    "P_{q/\\bar{q}}^{\\mu} \\equiv E(1, 0, 0, \\pm 1)\n",
    "$$\n",
    "(in our language these are just four-momenta of the $q\\bar{q}$ system that we initialize in `QQBarString` as `self.q_p`. `self.qbar_p`), and remember that the $i$-th ($i \\in 1, ..., N_h$) hadron coordinate can be described generically by\n",
    "$$\n",
    "x_{i}^+ = \\hat{x}_{i-1}^+ - \\hat{x}_i^+,\n",
    "$$\n",
    "$$\n",
    "x_{i}^- = \\hat{x}_i^- - \\hat{x}_{i-1}^-\n",
    "$$\n",
    "with $\\hat{x}^+_0 = 1, \\hat{x}^-_0 = 0$. The hadron momentum is then fully described by the system of equations\n",
    "$$\n",
    "  \tp^\\mu_{i} = x_{i}^+ P^\\mu_q + x_{i}^- P^\\mu_{\\bar{q}}\n",
    "$$\n",
    "or simply\n",
    "$$\n",
    "    E_{i} = E(x^+_{i} + x^-_{i}), \\hspace{0.3in} p_{z, i} =  E(x^+_{i} - x^-_{i})\n",
    "$$\n",
    "constrained by the condition\n",
    "$$\n",
    "    m_{i}^2 = p_{i}^2 = x^+_{i}x^-_{i} M^2.\n",
    "$$\n",
    "In practice, given the mass of the new hadron $m_{i}$ and longitudinal momentum fraction $z_i$, we'll compute the new vertex $i$ via\n",
    "$$\n",
    "    x^{+}_{i} = z^{+}_{i}\\prod_{j=1}^{i-1}(1-z^{+}_j) \\quad \\text{for } \\,\\, i > 1\n",
    "$$\n",
    "$$\n",
    "    x^{-}_{i} = \\frac{m^2_{i}}{x^{+}_{i}M^2}\n",
    "$$\n",
    "where $z^{+}_0 = 0$. Finally, the position ($\\hat{x}^+_i, \\hat{x}^-_i$) of the $i$-th vertex can also be found recursively using the expressions above\n",
    "$$\n",
    "\\hat{x}^+_i = \\hat{x}^+_{i-1} - x_i^+ = (1 - z_i) \\hat{x}^+_{i-1}\n",
    "$$\n",
    "$$\n",
    "\\hat{x}^-_i = \\hat{x}^-_{i-1} + x_i^-.\n",
    "$$\n",
    "\n",
    "Let's build out a `StringFragmentation` class below that will take as input `QQBarString`, `StringFlav`, and `StringZ` instances and recursively fragment the string system resulting in an event record consisting of hadron four-momenta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StringFragmentation:\n",
    "    \"\"\"\n",
    "    Hadronization class using the Lund string model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, flav, kin):\n",
    "        \"\"\"\n",
    "        Initialize the hadronization class.\n",
    "\n",
    "        flav:   flavor selector of type `StringFlav`.\n",
    "        kin:    kinematic sampler of type `StringZ`.\n",
    "        \"\"\"\n",
    "        # Store the samplers.\n",
    "        self.flav = flav\n",
    "        self.kin = kin\n",
    "\n",
    "    def __call__(self, system, steps=None, nmax=1000):\n",
    "        \"\"\"\n",
    "        Hadronize the string passed by `system`.\n",
    "\n",
    "        system: the string system of type `QQbarString` to hadronize.\n",
    "        steps:  if `True`, print the hadronization steps.\n",
    "        nmax:   the number of hadronization steps allowed.\n",
    "        \"\"\"\n",
    "        # Keep a record of the event, starting with the initial string.\n",
    "        self.event = [system.q, system.qbar]\n",
    "\n",
    "        # Initialize arrays for the light-cone coordinates, z, and string end.\n",
    "        self.xhps = [1]\n",
    "        self.xhms = [0]\n",
    "        self.xps = [0]\n",
    "        self.xms = [0]\n",
    "        self.had_zs = [0]\n",
    "        self.end_pds = [system.q.data]\n",
    "        self.prod_z = 1\n",
    "\n",
    "        # Enter the hadronization loop.\n",
    "        for i in range(0, nmax):\n",
    "            # Flag to print the hadronization steps.\n",
    "            step = i + 1 if steps else None\n",
    "\n",
    "            # Determine the flavor and kinematics. We already wrote this!\n",
    "            end_pd, had_pd, had_z = string_next(\n",
    "                self.flav, self.kin, self.end_pds[-1], step\n",
    "            )\n",
    "\n",
    "            # Calculate the vertex the coordinates. We already wrote this!\n",
    "            xp, xm, xhp, xhm = string_vertex(\n",
    "                system, self.xhps[-1], self.xhms[-1], self.prod_z, had_z, had_pd, step\n",
    "            )\n",
    "\n",
    "            # Return if this vertex is unphysical or the stopping condition\n",
    "            # is met.\n",
    "            if (\n",
    "                xhm > 1.0\n",
    "                or xhp < 0.0\n",
    "                or xhp * (1 - xhm) * system.m2 < (2 * self.flav.pdb[\"pi+\"].mass) ** 2\n",
    "            ):\n",
    "                return\n",
    "\n",
    "            # Determine the hadron momentum.\n",
    "            e = system.e * (xp + xm)\n",
    "            pz = system.e * (xp - xm)\n",
    "\n",
    "            # Append the hadron to the event record.\n",
    "            self.event += [Particle(had_pd, FourVector(e, 0, 0, pz))]\n",
    "\n",
    "            # Update the fragmentation state.\n",
    "            self.xps += [xp]\n",
    "            self.xms += [xm]\n",
    "            self.xhps += [xhp]\n",
    "            self.xhms += [xhm]\n",
    "            self.had_zs += [had_z]\n",
    "            self.end_pds += [end_pd]\n",
    "            self.prod_z *= 1 - had_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the fragmentation class.\n",
    "flavor_selector = StringFlav(rng, pdb)\n",
    "kinematic_sampler = StringZ(rng)\n",
    "hadronizer = StringFragmentation(flavor_selector, kinematic_sampler)\n",
    "\n",
    "# Create the system, u/ubar at 3 GeV.\n",
    "qqbar = QQBarString(3.0, pdb[\"u\"])\n",
    "\n",
    "# Hadronize, and print the steps.\n",
    "hadronizer(qqbar, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the event record.\n",
    "for prt in hadronizer.event:\n",
    "    print(\n",
    "        f\"{prt.data.name:6s}:\"\n",
    "        f\" {prt.p[0]:9.2e} {prt.p[1]:9.2e} {prt.p[2]:9.2e} {prt.p[3]:9.2e}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the vertices.\n",
    "string_plot(hadronizer.xhps, hadronizer.xhms);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we make a 2D histogram of $\\hat{x}^+_i$ and $\\hat{x}^-_i$ for a number of events, rather than a scatter plot for just one event?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectors to store xhat^+ and xhat^-.\n",
    "xhps = []\n",
    "xhms = []\n",
    "\n",
    "# Loop over the events.\n",
    "for i in range(0, 10000):\n",
    "    # Hadronize the system.\n",
    "    hadronizer(qqbar)\n",
    "\n",
    "    # Append the values (but not the first).\n",
    "    xhps += hadronizer.xhps[1:]\n",
    "    xhms += hadronizer.xhms[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the plot.\n",
    "fig = plt.figure()\n",
    "\n",
    "# Rotate the plot by 45 degrees as usual.\n",
    "transform = Affine2D().rotate_deg(45)\n",
    "helper = GridHelperCurveLinear(transform, extremes=(0, 1, 0, 1))\n",
    "ax = FloatingSubplot(fig, 111, grid_helper=helper)\n",
    "fig.add_subplot(ax)\n",
    "\n",
    "# Create auxiliary axis to plot in original coordinates.\n",
    "aux_ax = ax.get_aux_axes(transform)\n",
    "\n",
    "# Axis labels.\n",
    "ax.axis[\"left\"].label.set_text(r\"$\\hat{x}^-$\")\n",
    "ax.axis[\"left\"].label.set_rotation(0)\n",
    "ax.axis[\"left\"].label.set_pad(25)\n",
    "ax.axis[\"bottom\"].label.set_text(r\"$\\hat{x}^+$\")\n",
    "ax.axis[\"bottom\"].label.set_pad(15)\n",
    "ax.axis[\"bottom\"].major_ticklabels.set_rotation(270)\n",
    "\n",
    "# Create the histogram.\n",
    "_, _, _, hist_xhat_pm = aux_ax.hist2d(\n",
    "    xhps, xhms, bins=50, range=[[0, 1], [0, 1]], cmap=\"viridis\"\n",
    ")\n",
    "\n",
    "# Add a colorbar\n",
    "cbar = fig.colorbar(hist_xhat_pm, ax=ax, orientation=\"vertical\", fraction=0.04, pad=0.1)\n",
    "cbar.set_label(\"Counts\", size=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll see above that the vertices seem to follow some sort of hyperbolic distribution - this can be traced back to some interesting physics! Generically, the unnormalized probability for a string break to fragment into an $n$-particle final state is given by\n",
    "\n",
    "$$\n",
    "dP_n = \\prod_{j = 1}^n N_j dp_j \\delta(p_j^2 - m_j^2) \\delta\\left( \\sum_{j=1}^n p^\\mu_j - P^\\mu_{\\text{string}} \\right) \\exp(-b \\mathcal{A}),\n",
    "$$\n",
    "\n",
    "where $\\mathcal{A}$ represents the area spanned by the string before the breakup. The probability roughly factorizes into the product of $n$-body phase-space with an exponential area suppression.\n",
    "\n",
    "This competition leads to an interesting compromise. On one hand, phase space wants to pack in as many hadrons as possible, which tends to push fragmentation vertices closer together in time. On the other hand, the exponential suppression penalizes any configuration that sweeps out too much area, i.e., configurations where hadrons are produced too far apart in time or space.\n",
    "\n",
    "The balance point turns out to be when each breakup contributes roughly the same invariant area. That is, the most probable configurations are those where the fragmentation vertices lie along curves of constant invariant time:\n",
    "\n",
    "$$\n",
    "\\tau^2 = t^2 - z^2 = \\text{const}.\n",
    "$$\n",
    "\n",
    "These hyperbolae strike a balance between maximizing multiplicity and minimizing total area. Physically, this means that the string fragments in a boost-invariant fashion.\n",
    "\n",
    "This structure has important observable consequences, for example the coordinate-space rapidity of a vertex is defined as\n",
    "\n",
    "$$\n",
    "\\eta = \\frac{1}{2} \\ln\\left(\\frac{t + z}{t - z}\\right),\n",
    "$$\n",
    "\n",
    "and since the vertices lie along a fixed $\\tau$, their density in $\\eta$ is approximately uniform.\n",
    "\n",
    "This geometric picture is also encoded in our Lund plane that we constructed above. To see this we introduce the the the squared invariant time (from the origin of the initial $q\\bar{q}$ pair) to a string break vertex\n",
    "\n",
    "$$\n",
    "\\Gamma = (\\kappa \\tau)^2 = \\kappa^2 (t^2 - x^2 - y^2 - z^2).\n",
    "$$\n",
    "\n",
    "In the energy-momentum picture, this is simply given by\n",
    "\n",
    "$$\n",
    "\\Gamma_i = (\\hat{x}^+_i P^+ + \\hat{x}^-_i P^-)^2 = \\hat{x}_i^+ \\hat{x}_i^- M^2,\n",
    "$$\n",
    "\n",
    "which corresponds geometrically to the string area in the backwards light cone of the vertex. The area suppression factor from above then becomes\n",
    "\n",
    "$$\n",
    "\\exp(-b \\mathcal{A}) = \\exp\\left(-b \\sum_i \\Gamma_i \\right).\n",
    "$$\n",
    "\n",
    "To avoid exponential suppression, the hadronization configurations will prefer for each $\\Gamma_i$ to be small but roughly equal, i.e., each hadron is produced along a contour of constant $\\hat{x}^+ \\hat{x}^-$, which traces out a hyperbola on the unit square (as we see above!). This is a direct imprint of the same physical principle above: balancing the statistical pressure to produce many hadrons with the geometric penalty for large invariant area.\n",
    "\n",
    "Similar to the coordinate space rapidity, $\\eta$, we can clearly see that the momentum-space rapidity\n",
    "\n",
    "$$\n",
    "y = \\frac{1}{2} \\ln\\left(\\frac{E + p_z}{E - p_z}\\right) = \\frac{1}{2} \\ln\\left(\\frac{p^+}{p^-}\\right) = \\frac{1}{2} \\ln\\left(\\frac{x^+}{x^-}\\right)\n",
    "$$\n",
    "\n",
    "will also remain roughly constant i.e. the number of particles produced, $N$, per unit rapidity\n",
    "\n",
    "$$\n",
    "\\frac{dN}{dy} \\approx \\text{const}.\n",
    "$$\n",
    "\n",
    "To summarize, the area suppression sculpts the entire fragmentation pattern into hyperbolic structure that ensures boost invariance and a flat rapidity distribution. The latter was an experimental motivation for the Lund string model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Observables"
   },
   "source": [
    "## Observables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we continue on to incorporating tranverse momentum, let's look at some observables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Exercise:_multiplicity"
   },
   "source": [
    "### Exercise: multiplicity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because hadronization is non-perturbative, quite a bit of work in high energy particle physics has gone into creating observables that do not depend strongly on hadronization, e.g., inclusive cross-sections, jet physics, etc. However, there are number of variables are very sensitive to hadronization, one of them being the final state multiplicity. Run the hadronization for $10000$ events and make a histogram of the event multiplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "# Initialize the fragmentation class.\n",
    "\n",
    "# Create the system, u/ubar at 3 GeV.\n",
    "\n",
    "# Create a list of mutiplicity.\n",
    "\n",
    "# Generate 10000 events.\n",
    "# Append the number of hadrons. Account for the initial quarks.\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "# Initialize the fragmentation class.\n",
    "flavor_selector = StringFlav(rng, pdb)\n",
    "kinematic_sampler = StringZ(rng)\n",
    "hadronizer = StringFragmentation(flavor_selector, kinematic_sampler)\n",
    "\n",
    "# Create the system, u/ubar at 3 GeV.\n",
    "qqbar = QQBarString(3.0, pdb[\"u\"])\n",
    "\n",
    "# Create a list of mutiplicity.\n",
    "ns = []\n",
    "\n",
    "# Generate 10000 events.\n",
    "for i in range(10000):\n",
    "    hadronizer(qqbar)\n",
    "    # Append the number of hadrons. Account for the initial quarks.\n",
    "    ns += [len(hadronizer.event) - 2]\n",
    "####STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot the multiplicity distribution now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "# Construct a binning. We have to be a little careful of binning effects\n",
    "# to make sure each bin covers a single multiplicity.\n",
    "\n",
    "# Plot the histogram using the keyword `bins`.\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "# Plot the distribution.\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Construct a binning. We have to be a little careful of binning effects\n",
    "# to make sure each bin covers a single multiplicity.\n",
    "bins = [n - 0.5 for n in range(min(ns), max(ns) + 2)]\n",
    "\n",
    "# Plot the histogram of multiplicity.\n",
    "ax.hist(ns, bins=bins, density=True)\n",
    "\n",
    "# Plot the average multiplicity as a vertical line.\n",
    "ax.axvline(\n",
    "    sum(ns) / len(ns),\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    ")\n",
    "\n",
    "# Set the labels.\n",
    "ax.set_xlabel(\"hadron multiplicity\")\n",
    "ax.set_ylabel(\"PDF(n)\");\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Exercise:_rapidity"
   },
   "source": [
    "### Exercise: rapidity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The multiplicity distribution, differential in hadron rapidity $y$, is also an important observable when considering hadronization. Use the definition for rapidity above and plot this distribution. Again, generate $10000$ events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "def rapidity(p):\n",
    "    \"\"\"\n",
    "    Return the rapidity for a four vector.\n",
    "\n",
    "    p: four vector of type `FourVector`.\n",
    "    \"\"\"\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "def rapidity(p):\n",
    "    \"\"\"\n",
    "    Return the rapidity for a four vector.\n",
    "    y = 1/2 ln((E + p_z)/(E - p_z))\n",
    "\n",
    "    p: four vector of type `FourVector`.\n",
    "    \"\"\"\n",
    "    return math.log((p[0] + p[3]) / (p[0] - p[3])) / 2\n",
    "\n",
    "\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "# Initialize the fragmentation class.\n",
    "\n",
    "# Create the system, u/ubar at 3 GeV.\n",
    "\n",
    "# Create a list of rapidities.\n",
    "\n",
    "# Generate 10000 events.\n",
    "# Loop over the particles, skip the initial quarks.\n",
    "# Calculate and append the rapidity.\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "# Initialize the fragmentation class.\n",
    "flavor_selector = StringFlav(rng, pdb)\n",
    "kinematic_sampler = StringZ(rng)\n",
    "hadronizer = StringFragmentation(flavor_selector, kinematic_sampler)\n",
    "\n",
    "# Create the system, u/ubar at 3 GeV.\n",
    "qqbar = QQBarString(3.0, pdb[\"u\"])\n",
    "\n",
    "# Create a list of rapidities.\n",
    "ys = []\n",
    "\n",
    "# Generate 10000 events.\n",
    "for i in range(10000):\n",
    "    hadronizer(qqbar)\n",
    "    # Loop over the particles, skip the initial quarks.\n",
    "    for prt in hadronizer.event[2:]:\n",
    "        # Calculate and append the rapidity.\n",
    "        ys += [rapidity(prt.p)]\n",
    "####STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "# Plot the rapidity distribution. Use 40 bins.\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the plot.\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the histogram of rapidity. Use 40 bins.\n",
    "ax.hist(ys, bins=40, density=True)\n",
    "\n",
    "# Set the labels.\n",
    "ax.set_xlabel(r\"$y$\")\n",
    "ax.set_ylabel(\"PDF($y$)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We mentioned above that the rapidity distribution should be flat? What is going on? The caveat to the statements above is that they hold primarily in the limit of \"infinitely long\" or very massive strings. The reason for this is because the relation doesn't hold near the end of the string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Exercise:_rapidity_energy_dependence"
   },
   "source": [
    "### Exercise: rapidity energy dependence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Let's take a look at the scaling of the rapidity distribution as a function of the string mass. Plot the rapidity distribution for initial quark energies of $5$, $10$, $25$, and $50$ GeV. Generate only $1000$ events per energy to speed things up a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "# Initialize the fragmentation class.\n",
    "\n",
    "# Create a dictionary rapidities with energy keys.\n",
    "\n",
    "# Loop over the energies.\n",
    "# Create the system, u/ubar at the given energy.\n",
    "# Generate 5000 events.\n",
    "# Loop over the particles, skip the initial quarks.\n",
    "# Calculate and append the rapidity.\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "# Initialize the fragmentation class.\n",
    "flavor_selector = StringFlav(rng, pdb)\n",
    "kinematic_sampler = StringZ(rng)\n",
    "hadronizer = StringFragmentation(flavor_selector, kinematic_sampler)\n",
    "\n",
    "# Create a dictionary rapidities with energy keys.\n",
    "es = {e: [] for e in (5, 10, 25, 50)}\n",
    "\n",
    "# Loop over the energies.\n",
    "for e, ys in es.items():\n",
    "    # Create the system, u/ubar at the given energy.\n",
    "    qqbar = QQBarString(e, pdb[\"u\"])\n",
    "\n",
    "    # Generate 5000 events.\n",
    "    for i in range(1000):\n",
    "        hadronizer(qqbar)\n",
    "        # Loop over the particles, skip the initial quarks.\n",
    "        for prt in hadronizer.event[2:]:\n",
    "            # Calculate and append the rapidity.\n",
    "            ys += [rapidity(prt.p)]\n",
    "###STOP_SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_EXERCISE\n",
    "# Create the plot.\n",
    "\n",
    "# Loop over the energies.\n",
    "# Plot the histogram of rapidity. Use 40 bins.\n",
    "# The `histtype` argument plots just a line.\n",
    "# Label the histogram.\n",
    "\n",
    "# Set the labels and create a legend.\n",
    "###STOP_EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###START_SOLUTION\n",
    "# Create the plot.\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Loop over the energies.\n",
    "# Plot the histogram of rapidity. Use 40 bins.\n",
    "# The `histtype` argument plots just a line.\n",
    "# Label the histogram.\n",
    "for e, ys in es.items():\n",
    "    ax.hist(ys, bins=40, density=True, histtype=\"step\", label=f\"$E = {e}$ GeV\")\n",
    "\n",
    "# Set the labels and create a legend.\n",
    "ax.set_xlabel(r\"$y$\")\n",
    "ax.set_ylabel(\"PDF($y$)\")\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Including_$p_T$"
   },
   "source": [
    "## Including $p_T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up until now we have worked exclusively in 1+1 dimensions with each string break (and therefore each hadron) having no transverse momenta. For a realistic hadronization simulation $p_T$ generation must be incorporated!\n",
    "\n",
    "In the Lund string model, each string break corresponds to the nonperturbative creation of a $q'\\bar{q}'$ pair from the vacuum. This is modeled as a quantum tunneling process through the linear confining potential of the string. According to the uncertainty principle, this pair can have non-zero momentum transverse to the string axis. Since they are produced locally, momentum conservation requires that the transverse momenta of the quark and antiquark be equal and opposite i.e., each string break introduces a local transverse momentum kick, with\n",
    "\n",
    "$$\n",
    "\\vec{k}_\\perp^{(q')} = -\\vec{k}_\\perp^{(\\bar{q}')}.\n",
    "$$\n",
    "\n",
    "The resulting hadron inherits this transverse momentum when a quark from one break and an antiquark from the next recombine.\n",
    "\n",
    "The tunneling probability for producing a quark of mass $m_q$ and transverse momentum $p_\\perp$ is given by the Schwinger-like exponential suppression:\n",
    "\n",
    "$$\n",
    "\\mathcal{P}(m_q, p_\\perp) \\propto \\exp\\left( -\\frac{\\pi (m_q^2 + p_\\perp^2)}{\\kappa} \\right)\n",
    "$$\n",
    "\n",
    "where $\\kappa \\sim 1\\,\\mathrm{GeV}/\\mathrm{fm} \\simeq 0.2\\,\\mathrm{GeV}^2$ is the string tension. Note that heavier quarks and large transverse momenta are exponentially suppressed. Thus, strange quark production is rarer than up/down, and charm production is highly suppressed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Algorithmic_overview"
   },
   "source": [
    "### Algorithmic overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, the iterative algorithm only requires minimal changes and can be largely summarized with the transformation: $m^2 \\to m^2_\\perp \\equiv m^2 + p_T^2$ where $m_\\perp$ is the transverse mass.\n",
    "\n",
    "In light-cone coordinates, transverse momentum components completely factorize from the longitudinal components (they are orthogonal). All light-cone variable definition remain the same as defined previously with the key change coming from the on-shell condition:\n",
    "\n",
    "$$\n",
    "p^+ p^- = m^2 + p_T^2 \\equiv m_\\perp^2.\n",
    "$$\n",
    "\n",
    "Likewise, the momentum fractions become\n",
    "\n",
    "$$\n",
    "x^+ x^- = \\frac{m_\\perp^2}{M^2}.\n",
    "$$\n",
    "\n",
    "Because $p_T$ completely factorizes (in terms of it's generation) the $p_T$ of the $i$-th hadron can be computed recursively via the string end transverse momentum $\\vec{k}_T$\n",
    "\n",
    "$$\n",
    "\\vec{p}_{T,i} = \\vec{k}_{T,i} - \\vec{k}_{T, i-1}, \\quad \\text{with} \\quad \\vec{k}_{T,0} = 0.\n",
    "$$\n",
    "\n",
    "Clearly the first hadron will have the same $p_T$ as the first string break $\\vec{k}_{T,1}$, while the second hadron will inherit $p_T$ that is the vector sum of the first string break (whose conjugate end imparted some equal and opposite $\\vec{k}_T$ on the leftover string system) and the $\\vec{k}'_T$ of the new string break."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sampling_$z$"
   },
   "source": [
    "### Sampling $z$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the fragmentation happens longitudinally, the string area law (which governs hadron production probability) becomes sensitive to the full mass of the hadron, including transverse motion. So transverse momentum acts like an effective mass penalty - heavier hadrons or those with larger $p_T$ are suppressed. As you may have guessed, the fragmentation function becomes:\n",
    "\n",
    "$$\n",
    "f(z, p_\\perp^2) \\propto \\frac{1}{z}(1 - z)^a \\exp\\left( -b\\frac{m^2_\\perp}{z} \\right).\n",
    "$$\n",
    "\n",
    "Note that this implies that when determining kinematics, we first need to generate the string-end transverse momentum components before determining the longitudinal component."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sampling_$p_T$"
   },
   "source": [
    "### Sampling $p_T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, the transverse momentum of the produced hadron is sampled at each string break, assuming that the distribution is azimuthally symmetric.\n",
    "\n",
    "The transverse momentum is sampled from a 2D Gaussian:\n",
    "\n",
    "$$\n",
    "f(\\vec{p}_\\perp = p_x,p_y) = \\mathcal{N}(p_x,0,\\sigma)\\mathcal{N}(p_y,0,\\sigma)\n",
    "\\quad \\text{with} \\quad \\sigma^2 \\approx \\frac{\\kappa}{\\pi}\n",
    "$$\n",
    "\n",
    "where $\\sigma$ is a tuneable parameter fit from experimental data. In Pythia, the default value is typically $\\sigma \\sim 0.3$ GeV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Exercise:_tuning"
   },
   "source": [
    "### Exercise: tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout this tutorial we have chosen the Lund model parameters based off of the current Pythia defaults: `a = 0.68, b = 0.98, sigma = 0.335`. Change these parameters and investigate how this changes the observables of interest. Think about how you could set up an iterative tuning of these parameters if given experimental data.\n",
    "\n",
    "As a challenge, set up a mock tuning exercise using two simulated samples (of observables) at different parameterizations. Set one as the \"experimental\" dataset and the other as output from the simulation. See also the `tuning.ipynb` tutorial. We do not provide a solution for this exercise as it is more open-ended exploration."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Requirements",
    "Lund_string_model",
    "String_breaking",
    "Exercise:_particle_data",
    "Exercise:_string_system",
    "String_Coordinates",
    "Flavor",
    "Exercise:_include_baryons",
    "Kinematics",
    "Exercise:_the_Lund_fragmentation_function",
    "Exercise:_better_sampling",
    "Algorithmic_overview",
    "Iterative_fragmentation",
    "Observables",
    "Exercise:_multiplicity",
    "Exercise:_rapidity",
    "Exercise:_rapidity_energy_dependence",
    "Including_$p_T$",
    "Algorithmic_overview",
    "Sampling_$z$",
    "Sampling_$p_T$",
    "Exercise:_tuning"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}