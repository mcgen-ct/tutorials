{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams.update(\n",
    "    {\n",
    "        \"text.usetex\": True,\n",
    "        \"font.family\": \"serif\",\n",
    "        \"font.serif\": \"Computer Modern Roman\",\n",
    "    }\n",
    ")\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "from matplotlib.transforms import Affine2D\n",
    "from mpl_toolkits.axisartist.floating_axes import FloatingSubplot, GridHelperCurveLinear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "**Hadronization**"
   },
   "source": [
    "# **Hadronization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Summary: In this tutorial, we'll develop an algorithm to hadronize a simple color-connected quark anti-quark ($q\\bar{q}$) system.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Colliders probe energy scales where quarks and gluons interact perturbatively. As we saw in the previous tutorial, hard scattering events often produce colored partons that evolve via parton showers, radiating additional quarks and gluons. At the detector level, far below the QCD confinement scale, only color-neutral composite particles such as mesons, baryons, and occasionally exotic hadrons (e.g. tetraquarks or pentaquarks) are observed. To bridge this gap, Monte Carlo event generators must model the **nonperturbative** process that converts colored final state particles from the parton shower into observable hadrons. This process is known as ***hadronization***. Many phenomenological models of hadronization exist, however, in modern event generators two models are favored: the ***Lund string model*** (Pythia) and the ***cluster model*** (Herwig, Sherpa). In this tutorial, we'll focus exclusively on the Lund string model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "**Lund_string_model**"
   },
   "source": [
    "## **Lund string model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In QCD the potential between a static quark and anti-quark as a function of the distance between them is found to be\n",
    "$$\n",
    "V_{q\\bar{q}}(r) \\approx -\\frac{4\\alpha_s}{3}\\frac{1}{r} + \\kappa r .\n",
    "$$\n",
    "At short distances ($r < 0.1$ fm), the $1/r$ piece (stemming from one-gluon exchange (stemming from one-gluon exchange) dominates and the quarks behave as free 'Coulomb-like' charged particles. At long distances, the linear component dominates - representing the collapse of gluonic field lines into a thin color flux tube or **string** with a constant **tension** (linear energy density) $\\kappa \\simeq 1 \\text{ GeV/fm} \\simeq 0.2 \\text{ GeV}^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Exercise:"
   },
   "source": [
    "## Exercise:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show that the short distance potential is given above by computing explicitly in QFT."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "String_breaking"
   },
   "source": [
    "## String breaking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider center-of-mass frame of a $q_i \\bar{q}_i$ system where the (massless) partons, each with flavor index $i$ and initial energy $E$, travel with equal and opposite momenta along the $z$-axis. As the separation increases the confining force causes an approximately uniform cylindrical string (flux tube) of color field to form between the quark pair. In the absence of string breaks, our $q\\bar{q}$ system would follow an infinite ***\"yo-yo\" motion*** whereby the the systems energy oscillates between the kinetic energy of the quarks and the energy contained in the string.\n",
    "\n",
    "If we allow for string breaking during the separation process the energy in the string can be used to create $q'\\bar{q}'$ pairs out of the vacuum. This production breaks the original string into two fragments: a composite hadron $h \\equiv  q_i\\bar{q}'$ (or $q' \\bar{q_i}$) and another $q'\\bar{q}_i$ (or $q_i \\bar{q}'$)-string system. The ejected hadron inherits kinematics according to the model (and whose microscopic description in this model would be that of a mini-string following stable yo-yo motion as described above, i.e., **yoyo-hadrons**). The remaining string system continues its evolution and potentially fragments further into more hadrons.\n",
    "<p align=\"center\">\n",
    "  <img src=\"./hadronization.png\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from utils.vector import FourVector\n",
    "from utils.particle import ParticleData, Particle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a small particle database which we will use throughout using the predefined `ParticleData` utility class located `./utils/`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Define up and down quarks as Particle instances\n",
    "pid_u = 2\n",
    "name_u = \"u\"\n",
    "mass_u = 0.0\n",
    "charge_u = 2 / 3\n",
    "\n",
    "pid_d = 1\n",
    "name_d = \"d\"\n",
    "mass_d = 0.0\n",
    "charge_d = -1 / 3\n",
    "\n",
    "# Create ParticleData instances for u, ubar, d, and dbar\n",
    "u = ParticleData(pid=pid_u, name=name_u, mass=mass_u, charge=charge_u)\n",
    "ubar = -u\n",
    "d = ParticleData(pid=pid_d, name=name_d, mass=mass_d, charge=charge_d)\n",
    "dbar = -d\n",
    "\n",
    "# Print out the ParticleData instances\n",
    "print(u)\n",
    "print()\n",
    "print(d)\n",
    "print()\n",
    "print(ubar)\n",
    "print()\n",
    "print(dbar)\n",
    "\n",
    "# Define pions as Particle instances\n",
    "pid_pi_plus = 211\n",
    "name_pi_plus = \"pi+\"\n",
    "mass_pi_plus = 0.13957  # GeV\n",
    "charge_pi_plus = 1\n",
    "\n",
    "pid_pi0 = 111\n",
    "name_pi0 = \"pi0\"\n",
    "mass_pi0 = 0.134977  # GeV\n",
    "charge_pi0 = 0.0\n",
    "\n",
    "pi_plus = ParticleData(\n",
    "    pid=pid_pi_plus, name=name_pi_plus, mass=mass_pi_plus, charge=charge_pi_plus\n",
    ")\n",
    "pi_minus = -pi_plus\n",
    "\n",
    "print(pi_minus, \"\\n\")\n",
    "\n",
    "pi0 = ParticleData(pid=pid_pi0, name=name_pi0, mass=mass_pi0, charge=charge_pi0)\n",
    "\n",
    "ParticleDatabase = {}\n",
    "\n",
    "# Add the quarks and pions to the particle database\n",
    "ParticleDatabase[f\"{u.name}\"] = u\n",
    "ParticleDatabase[f\"{ubar.name}\"] = ubar\n",
    "ParticleDatabase[f\"{d.name}\"] = d\n",
    "ParticleDatabase[f\"{dbar.name}\"] = dbar\n",
    "ParticleDatabase[f\"{pi_plus.name}\"] = pi_plus\n",
    "ParticleDatabase[f\"{pi_minus.name}\"] = pi_minus\n",
    "ParticleDatabase[f\"{pi0.name}\"] = pi0\n",
    "\n",
    "print(\"Particle database:\\n\", ParticleDatabase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a class to represent our string system built out of `FourVector` and `ParticleData` instances:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class QQBarString:\n",
    "    \"\"\"\n",
    "    Class to represent a quark-antiquark pair.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, Eq, Eqbar, ParticleData):\n",
    "        if Eq == Eqbar:\n",
    "            self.E = Eq\n",
    "        # We'll be using the convention (E, px, py, pz) for FourVectors.\n",
    "        self.q_p = FourVector(Eq, 0, 0, Eq)  # GeV\n",
    "        self.qbar_p = FourVector(Eqbar, 0, 0, -Eqbar)  # GeV\n",
    "\n",
    "        self.q = Particle(data=ParticleData, p=self.q_p, h=0.0)\n",
    "        self.qbar = Particle(data=-ParticleData, p=self.qbar_p, h=0.0)\n",
    "\n",
    "        # Define the invariant mass squared of the qqbar pair\n",
    "        self.M2 = 2 * Eq * 2 * Eqbar  # GeV^2\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (\n",
    "            f\"QBarQ(   q:FourVector(E={self.q_p[0]:.3f}, px={self.q_p[1]:.3f}, py={self.q_p[2]:.3f}, pz={self.q_p[3]:.3f}, m={np.sqrt(self.q_p[0]**2 - self.q_p[1]**2 - self.q_p[2]**2 - self.q_p[3]**2):.3f}),\\n\"\n",
    "            + f\"      qbar:FourVector(E={self.qbar_p[0]:.3f}, px={self.qbar_p[1]:.3f}, py={self.qbar_p[2]:.3f}, pz={self.qbar_p[3]:.3f}, m={np.sqrt(self.qbar_p[0]**2 - self.qbar_p[1]**2 - self.qbar_p[2]**2 - self.qbar_p[3]**2):.3f}))\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Define the energy for each string end\n",
    "e = 50.0  # GeV\n",
    "\n",
    "# Create a QQBarString instance with the predefined quarks\n",
    "qqbar = QQBarString(Eq=e, Eqbar=e, ParticleData=u)\n",
    "print(qqbar)\n",
    "\n",
    "# We can access the data of both string ends straightforwardly\n",
    "print(f\"{qqbar.q.data.name}:\\n\", qqbar.q.data, \"\\n\")\n",
    "print(f\"{qqbar.qbar.data.name}:\\n\", qqbar.q.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Coordinates"
   },
   "source": [
    "## Coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the string model, hadronization is typically implemented in **momentum space** as an iterative stochastic walk through production (string-break) vertices, $v_i$. If we assume each string end to be massless (mass corrections can be incorporated straightforwardly), they both follow lightlike trajectories, motivating the use of ***light-cone coordinates***. Given an arbitrary four-momentum $p^\\mu = (E, \\vec{p})$, the light-cone momenta are defined as:\n",
    "$$\n",
    "p^\\pm = E \\pm p_z\n",
    "$$\n",
    "and satisfy (in 1 + 1 dimensions)\n",
    "$$\n",
    "p^+ p^- = m^2.\n",
    "$$\n",
    "Under Lorentz boosts, light-cone momenta have simple transformation properties\n",
    "$$\n",
    "p^{\\pm'} = e^{\\pm \\psi} p^\\pm, \\quad \\text{where } \\psi = \\frac{1}{2}\\ln{\\frac{1+\\beta}{1-\\beta}}\n",
    "$$\n",
    "with $\\beta$ denoting the boost velocity.\n",
    "\n",
    "The string itself has total light-cone momenta (defined at $t = 0$):\n",
    "$$\n",
    "P^+ = p_q^+ + p_{\\bar{q}}^+, \\quad P^- = p_q^- + q_{\\bar{q}}^-\n",
    "$$\n",
    "which in the string rest frame (both ends with equal energy, $E$, and opposite momenta along the $z$-axis, $p_z$) becomes\n",
    "$$\n",
    "P^+ = 2E, \\quad P^- = 2E, \\quad P^+ P^- = M^2 = 4 E^2\n",
    "$$\n",
    "where $M$ is the **string mass**.\n",
    "\n",
    "To further describe the fragmentation in dimensionless, string-normalized coordinates we also introduce:\n",
    "- **Light-cone momentum fractions**, $x^{\\pm}$, representing the light-cone separation between two breaks and defined as $$ x_i^{\\pm} = \\frac{p_i^\\pm}{P^\\pm}$$ for the $i$-th hadron. These satisfy: $$x^+_i x^-_i = \\frac{m_i^2}{M^2}.$$ For a specified hadron mass, we thus have a fixed relationship between $x^+_i$ and $x^-_i$. Note that the momentum fractions are normalized to the quark turning points such that $0 \\leq x^{\\pm} \\leq 1$. The figure below gives a useful schematic depiction of a fully hadronized string in energy-momentum space\n",
    "<p align=\"center\">\n",
    "  <img src=\"./momentum_space_string.png\" />\n",
    "</p>\n",
    "\n",
    "where $\\hat{x}^{\\pm}$ represent **light-cone vertex coordinates**, describing the location of production vertices.\n",
    "\n",
    "Very broadly, the hadronization of a string can be categorized into two methods:\n",
    "1. ***Flavor production***: we need to choose the flavor of the hadrons that get produced and\n",
    "2. ***Kinematics***: we need to assign some four-momenta to each of the produced hadrons.\n",
    "Before jumping into the full hadronization algorithm we'll take a detour to build each of these components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Flavor"
   },
   "source": [
    "## Flavor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, for simplicity, we'll restrict the string breaks to $u\\bar{u}$ and $d\\bar{d}$ pairs, implying that the only (stable) hadrons available for production are the pions $\\pi^\\pm, \\pi^0$. This makes the problem of choosing hadron flavor trivial, for example, each of the four possible string ends have a unique assignment depending on the flavor of the break:\n",
    "1. $u$ string end (what will be called `endA`), $u\\bar{u}$ string break $\\to \\pi^0$\n",
    "2. $u$ string end, $d\\bar{d}$ string break $\\to \\pi^+$\n",
    "3. $\\bar{u}$ string end (what will be called `endB`), $u\\bar{u}$ string break $\\to \\pi^0$\n",
    "4. $\\bar{u}$ string end, $d\\bar{d}$ string break $\\to \\pi^-$\n",
    "5. $d$ string end, $u\\bar{u}$ string break $\\to \\pi^-$\n",
    "6. $d$ string end, $d\\bar{d}$ string break $\\to \\pi^0$\n",
    "7. $\\bar{d}$ string end, $u\\bar{u}$ string break $\\to \\pi^+$\n",
    "8. $\\bar{d}$ string end, $d\\bar{d}$ string break $\\to \\pi^0$\n",
    "\n",
    "So, given a string end (`endA` or `endB`), we can flip a coin to decide between a $u\\bar{u}$ or $d\\bar{d}$ break and assign hadron flavor accordingly."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class StringFlav:\n",
    "    def __init__(self, ParticleDatabase):\n",
    "        \"\"\"\n",
    "        Select a hadron flavor.\n",
    "        \"\"\"\n",
    "        self.pdb = ParticleDatabase\n",
    "\n",
    "    def select_flavor(self, end_id):\n",
    "        if end_id == 1:\n",
    "            hadron_ids = np.array([self.pdb[\"pi0\"], self.pdb[\"pi-\"]])\n",
    "        elif end_id == -1:\n",
    "            hadron_ids = np.array([self.pdb[\"pi0\"], self.pdb[\"pi+\"]])\n",
    "        elif end_id == 2:\n",
    "            hadron_ids = np.array([self.pdb[\"pi0\"], self.pdb[\"pi+\"]])\n",
    "        elif end_id == -2:\n",
    "            hadron_ids = np.array([self.pdb[\"pi0\"], self.pdb[\"pi-\"]])\n",
    "        else:\n",
    "            print(\"Error: unsupported end_id\", end_id)\n",
    "\n",
    "        # 50-50 shot between uubar or ddbar break\n",
    "        weights = np.array([0.5, 0.5])\n",
    "\n",
    "        # Select a hadron flavor based on the weights\n",
    "        output_had_id = np.random.choice(hadron_ids, p=weights)\n",
    "\n",
    "        # Hadron quark cancellation\n",
    "        # These digits encode the quark content of the hadron.\n",
    "        pid_hundreds_id = (\n",
    "            abs(output_had_id.pid) // 100\n",
    "        ) % 10  # Hundreds digit: first quark type\n",
    "        pid_tens_id = (\n",
    "            abs(output_had_id.pid) // 10\n",
    "        ) % 10  # Tens digit: second quark type\n",
    "\n",
    "        if pid_hundreds_id == abs(end_id):\n",
    "            # If the first quark matches the string end, keep the second quark as the new string end\n",
    "            if end_id > 0:\n",
    "                new_string_id = pid_tens_id\n",
    "            else:\n",
    "                new_string_id = -pid_tens_id\n",
    "        elif pid_tens_id == abs(end_id):\n",
    "            # If the second quark matches, keep the first quark as the new string end\n",
    "            if end_id > 0:\n",
    "                new_string_id = pid_hundreds_id\n",
    "            else:\n",
    "                new_string_id = -pid_hundreds_id\n",
    "        else:\n",
    "            # If neither matches, retain the original string end\n",
    "            new_string_id = end_id\n",
    "\n",
    "        # Instead of returning the pids, let's return the ParticleData instances\n",
    "        output_hadron = self.pdb[output_had_id.name]\n",
    "\n",
    "        # I don't like this - but let's do it anyway for now...the other alternative is to use pids\n",
    "        # for pdb dict keys, but this somewhat destroys code readability unless familiar with pid vals.\n",
    "        if new_string_id < 0 and abs(new_string_id) == 1:\n",
    "            new_string_end = self.pdb[\"dbar\"]\n",
    "        elif new_string_id < 0 and abs(new_string_id) == 2:\n",
    "            new_string_end = self.pdb[\"ubar\"]\n",
    "        elif new_string_id > 0 and abs(new_string_id) == 1:\n",
    "            new_string_end = self.pdb[\"d\"]\n",
    "        elif new_string_id > 0 and abs(new_string_id) == 2:\n",
    "            new_string_end = self.pdb[\"u\"]\n",
    "\n",
    "        return new_string_end, output_hadron"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "end_id = -1\n",
    "print(\"input string:\", end_id, \"\\n\")\n",
    "flavor_selector = StringFlav(ParticleDatabase)\n",
    "# Select a flavor and get the new string and output hadron\n",
    "new_string, output_had = flavor_selector.select_flavor(end_id)\n",
    "print(\"output hadron:\\n\", output_had, \"\\n\")\n",
    "print(\"new string id:\\n\", new_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Exercise"
   },
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How could ***baryon*** production be minimally implemented in the string model?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Your answer here\n",
    "# Hint: It will still involve production vertices along the string!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kinematics"
   },
   "source": [
    "## Kinematics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "The_Lund_fragmentation_function"
   },
   "source": [
    "### The Lund fragmentation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can finally introduce the **longitudinal momentum fraction**, $z^{\\pm}$, defined as the fraction of longitudinal momentum (light-cone momentum $p^{\\pm}_i$) absorbed by the $i$-th hadron **from the remaining longitudinal momentum in the string system**. This is similar but distinct from the light-cone momentum fractions we defined above. They are related by\n",
    "\n",
    "$$\n",
    "x^+_1 = z^+_1, \\quad x^+_i = z^+_i \\prod_{j = 1}^{i-1}(1-z_j) \\, \\, \\text{ for }\\,\\, i > 1.\n",
    "$$\n",
    "From the transformations defined above, we see that $z^\\pm$ is manifestly invariant under boosts. The distribution from which $z$ is sampled is called the **Lund left-right symmetric  scaling (fragmentation) function** and is proportional to the following\n",
    "$$\n",
    "    f(z)dz \\propto \\frac{(1-z)^a}{z}\\exp \\left(-b \\frac{m_h^2}{z} \\right) dz\n",
    "$$\n",
    "where $a$ and $b$ are tuneable phenomenological parameters fit to empirical data.\n",
    "\n",
    "We will need a function that will return samples of $z$. Let's implement a quick and dirty rejection sampling algorithm."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def zLund(a, b, m):\n",
    "    \"\"\"\n",
    "    Generate z from the Lund fragmentation function using standard accept-reject.\n",
    "    \"\"\"\n",
    "    _OVERHEAD = 10\n",
    "    # Fragmentation function\n",
    "    fz = lambda z, m: ((1 - z) ** a / z) * np.exp(-(b * m**2) / z)\n",
    "    # Sample trial value between 0 and 1\n",
    "    z = np.random.uniform(0, 1)\n",
    "    # Compute the acceptance probability\n",
    "    paccept = fz(z, m) / _OVERHEAD\n",
    "    # Accept or reject the sample\n",
    "    if np.random.uniform(0, 1) < paccept:\n",
    "        return z\n",
    "    else:\n",
    "        return zLund(a, b, m)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create a sample of 1000 z values\n",
    "a = 0.68  # Monash default\n",
    "b = 0.98  # Monash default\n",
    "m = 0.139  # GeV, pion mass\n",
    "\n",
    "# Generate the sample using the accept-reject algorithm above\n",
    "n_samples = 100000\n",
    "Z = [zLund(a, b, m) for _ in range(n_samples)]"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "# Plot histogram of sampled values\n",
    "ax.hist(Z, bins=100, density=True, alpha=0.7, label=\"Sampled\")\n",
    "ax.set_xlabel(r\"$z$\", size=14)\n",
    "ax.set_ylabel(\"Density\")\n",
    "\n",
    "# Place parameters as text on the plot\n",
    "params_text = f\"$a$ = {a}\\n$b$ = {b}\\n$m$ = {m} GeV\"\n",
    "ax.text(\n",
    "    0.7,\n",
    "    0.7,\n",
    "    params_text,\n",
    "    transform=ax.transAxes,\n",
    "    fontsize=12,\n",
    "    verticalalignment=\"top\",\n",
    "    bbox=dict(facecolor=\"white\", alpha=0.5),\n",
    ")\n",
    "ax.set_title(r\"$f(z; a, b, m)$\")\n",
    "\n",
    "# Overlay the theoretical Lund fragmentation function\n",
    "fz = lambda z, m: ((1 - z) ** a / z) * np.exp(-(b * m**2) / z)\n",
    "z_range = np.linspace(1e-5, 0.99, 1000)\n",
    "\n",
    "# Calculate normalization factor by numerical integration\n",
    "dz = z_range[1] - z_range[0]\n",
    "norm_factor = np.sum(fz(z_range, m) * dz)\n",
    "\n",
    "# Plot the normalized theoretical function\n",
    "ax.plot(z_range, fz(z_range, m) / norm_factor, color=\"red\", label=\"Analytic\")\n",
    "ax.plot(z_range, np.ones(len(z_range)), color=\"gold\", label=\"Proposal\")\n",
    "ax.legend(frameon=False)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uniform accept-reject sampling isn't cutting it. We'll need to modify an implement some form of importance sampling. Let's also wrap it in its own class for posterity."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class StringZ:\n",
    "    def __init__(self, a=0.68, b=0.98):\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "\n",
    "    def zLund(self, m):\n",
    "        \"\"\"\n",
    "        Generate z from the Lund fragmentation function using importance sampling.\n",
    "        \"\"\"\n",
    "        # Overhead constant\n",
    "        _OVERHEAD = 5\n",
    "        # Fragmentation function\n",
    "        fz = lambda z, m: ((1 - z) ** self.a / z) * np.exp(-(self.b * m**2) / z)\n",
    "        # Proposal function\n",
    "        g = lambda z: _OVERHEAD - z\n",
    "        # Sample trial value between 0 and 1\n",
    "        # This should be sampled according to g\n",
    "        # In this case, z ~ g is also uniformly distributed\n",
    "        z = np.random.uniform(0, 1)\n",
    "        # Compute the weight\n",
    "        w = fz(z, m) / g(z)\n",
    "        # Compute the acceptance probability\n",
    "        paccept = w / _OVERHEAD\n",
    "        # Accept or reject the sample\n",
    "        if np.random.uniform(0, 1) < paccept:\n",
    "            return z\n",
    "        else:\n",
    "            return self.zLund(m)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create a sample of 1000 z values\n",
    "a = 0.68  # Monash default\n",
    "b = 0.98  # Monash default\n",
    "m = 0.139  # GeV, pion mass\n",
    "\n",
    "# Instantiate the StringZ class\n",
    "stringZ = StringZ()\n",
    "\n",
    "# Generate the sample using the accept-reject algorithm above\n",
    "n_samples = 100000\n",
    "Z = [stringZ.zLund(m) for _ in range(n_samples)]"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "# Plot histogram of sampled values\n",
    "ax.hist(Z, bins=100, density=True, alpha=0.7, label=\"Sampled\")\n",
    "ax.set_xlabel(r\"$z$\", size=14)\n",
    "ax.set_ylabel(\"Density\")\n",
    "\n",
    "# Place parameters as text on the plot\n",
    "params_text = f\"$a$ = {a}\\n$b$ = {b}\\n$m$ = {m} GeV\"\n",
    "ax.text(\n",
    "    0.7,\n",
    "    0.7,\n",
    "    params_text,\n",
    "    transform=ax.transAxes,\n",
    "    fontsize=12,\n",
    "    verticalalignment=\"top\",\n",
    "    bbox=dict(facecolor=\"white\", alpha=0.5),\n",
    ")\n",
    "ax.set_title(r\"$f(z; a, b, m)$\")\n",
    "\n",
    "# Overlay the theoretical Lund fragmentation function\n",
    "fz = lambda z, m: ((1 - z) ** a / z) * np.exp(-(b * m**2) / z)\n",
    "z_range = np.linspace(1e-5, 0.99, 1000)\n",
    "\n",
    "# Calculate normalization factor by numerical integration\n",
    "dz = z_range[1] - z_range[0]\n",
    "norm_factor = np.sum(fz(z_range, m) * dz)\n",
    "\n",
    "# Plot the normalized theoretical function\n",
    "ax.plot(z_range, fz(z_range, m) / norm_factor, color=\"red\", label=\"Analytic\")\n",
    "ax.plot(z_range, (5 - z_range) / 4, color=\"gold\", label=\"Proposal\")\n",
    "ax.legend(frameon=False)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Algorithmic_overview"
   },
   "source": [
    "## Algorithmic overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, let's consider the fragmentation of the $q\\bar{q}$ system in 1 + 1 dimensions $(E, p_z)$ or $(t, z)$. Later we'll see how transverse momentum is included via string breaking. In terms of the iterative program for the left-right symmetric Lund model it can be summarized as follows:\n",
    "\n",
    "1. Randomly select from which string end the fragmentation will take place\n",
    "2. Select new $q'\\bar{q}'$ and hadron to be produced (`StringFlav`)\n",
    "3. Sample $z$ according to the Lund fragmentation function (`StringZ`)\n",
    "4. Compute production vertices\n",
    "5. Update all momenta\n",
    "6. Proceed through steps (1)-(5) until the center of mass energy of the new string system falls below a given cut off threshold $M^2_{\\text{min}}$.\n",
    "\n",
    "It's instructive to iterate through the algorithm a few time to get a feel. Let's assume, for simplicity, that we will only fragment from the $q$ side of the string (denoted as `fromPos` in the code). This is not how it's done in practice (typically a 50-50 coin flip between the $q$ or $\\bar{q}$ end) but the simplification reduces the algorithmic complexity and readability. At the end of the day, allowing for the string to randomly fragment from either side only requires extra bookkeeping. We'll leave this implementation as an exercise.\n",
    "\n",
    "To start, we need to set up our $q\\bar{q}$ system:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Define the energy for each string end\n",
    "e = 0.5  # GeV\n",
    "# Create a QQBarString instance with the predefined quarks\n",
    "qqbar = QQBarString(Eq=e, Eqbar=e, ParticleData=ParticleDatabase[\"u\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need a new hadron and string end, `StringFlav` is what we need:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Initialize flavor selector\n",
    "flavor_selector = StringFlav(ParticleDatabase)\n",
    "\n",
    "# Get the end id of the string (from the q end)\n",
    "end_id_0 = qqbar.q.data.pid\n",
    "\n",
    "# Select a flavor and get the new string and output hadron\n",
    "new_string_end_1, output_had_1 = flavor_selector.select_flavor(end_id_0)\n",
    "print(\"Output hadron:\\n\", output_had_1, \"\\n\")\n",
    "print(\"New string id:\\n\", new_string_end_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to sample a $z$ for the hadron, `StringZ` to the rescue:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Instantiate the StringZ class\n",
    "stringZ = StringZ()\n",
    "\n",
    "# Generate one value of z, remember that this requires the mass of the hadron\n",
    "z_had_1 = stringZ.zLund(output_had_1.mass)\n",
    "\n",
    "print(\"z value for hadron 1:\", z_had_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compute the string break vertices. From above we know that\n",
    "$$\n",
    "x^+_1 = z_1, \\quad x^-_1 = \\frac{m_1^2}{x^+_1 M^2}\n",
    "$$\n",
    "$$\n",
    "\\hat{x}^+_1 = \\hat{x}^+_0 - x^+_1 = 1 - z_1^+\n",
    "$$\n",
    "$$\n",
    "\\hat{x}^-_1 = \\hat{x}^-_0 + x^-_1 = \\frac{m_1^2}{x^+_1 M^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "x_plus_1 = z_had_1\n",
    "x_minus_1 = output_had_1.mass**2 / (x_plus_1 * qqbar.M2)\n",
    "xhat_plus_1 = 1 - x_plus_1\n",
    "xhat_minus_1 = x_minus_1\n",
    "\n",
    "print(f\"x_plus_1: {x_plus_1:.3f}, x_minus_1: {x_minus_1:.3f}\")\n",
    "print(f\"xhat_plus_1: {xhat_plus_1:.3f}, xhat_minus_1: {xhat_minus_1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will be useful visualize each break on the light-cone \"unit square\""
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Visualize the light-cone energy-momentum Lund plane\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "\n",
    "# Define the transformation (rotate by 45 degrees)\n",
    "transform = Affine2D().rotate_deg(45)\n",
    "helper = GridHelperCurveLinear(transform, extremes=(0, 1, 0, 1))\n",
    "ax = FloatingSubplot(fig, 111, grid_helper=helper)\n",
    "fig.add_subplot(ax)\n",
    "\n",
    "\n",
    "# Create auxiliary axis to plot in original coordinates\n",
    "aux_ax = ax.get_aux_axes(transform)\n",
    "\n",
    "# Axis labels\n",
    "ax.axis[\"left\"].label.set_text(r\"$\\hat{x}^-$\")\n",
    "ax.axis[\"left\"].label.set_size(17)\n",
    "ax.axis[\"left\"].label.set_rotation(0)\n",
    "ax.axis[\"left\"].label.set_pad(25)\n",
    "\n",
    "ax.axis[\"bottom\"].label.set_text(r\"$\\hat{x}^+$\")\n",
    "ax.axis[\"bottom\"].label.set_size(17)\n",
    "ax.axis[\"bottom\"].label.set_pad(15)\n",
    "ax.axis[\"bottom\"].major_ticklabels.set_rotation(270)\n",
    "\n",
    "# Draw a dotted line at xhat_plus_1 and xhat_minus_1\n",
    "aux_ax.plot(\n",
    "    [xhat_plus_1, xhat_plus_1], [0, 1], linestyle=\"--\", color=\"red\", linewidth=0.5\n",
    ")\n",
    "aux_ax.plot(\n",
    "    [0, 1], [xhat_minus_1, xhat_minus_1], linestyle=\"--\", color=\"red\", linewidth=0.5\n",
    ")\n",
    "\n",
    "# Plot a point at (0.7, 0.1) using unrotated coordinates\n",
    "aux_ax.plot(xhat_plus_1, xhat_minus_1, \"o\", markersize=5, color=\"red\")\n",
    "\n",
    "# Add grid and legend\n",
    "ax.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "# aux_ax.legend(frameon=False, loc='upper right')\n",
    "ax.set_aspect(\"equal\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the second iteration, which is a little more interesting"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Now we start with the new string end pid\n",
    "new_string_end_2, output_had_2 = flavor_selector.select_flavor(new_string_end_1.pid)\n",
    "print(\"Output hadron:\\n\", output_had_2, \"\\n\")\n",
    "print(\"New string id:\\n\", new_string_end_2, \"\\n\")\n",
    "\n",
    "# Generate one value of z, remember that this requires the mass of the hadron\n",
    "z_had_2 = stringZ.zLund(output_had_2.mass)\n",
    "\n",
    "print(\"z value for hadron 1:\", z_had_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the new vertices let's rewrite everything in terms of quantities that we have access to, past or present:\n",
    "$$\n",
    "x^+_2 = z^+_2 (1 - z^+_1), \\quad x^-_2 = \\frac{m_2^2}{x^+_2 M^2}\n",
    "$$\n",
    "$$\n",
    "\\hat{x}^+_2 = \\hat{x}^+_1 - x^+_2, \\quad \\hat{x}^-_2 = \\hat{x}^-_1 + x^-_2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "x_plus_2 = z_had_2 * (1 - z_had_1)\n",
    "x_minus_2 = output_had_2.mass**2 / (x_plus_2 * qqbar.M2)\n",
    "xhat_plus_2 = xhat_plus_1 - x_plus_2\n",
    "xhat_minus_2 = xhat_minus_1 + x_minus_2\n",
    "\n",
    "print(f\"x_plus_2: {x_plus_2:.3f}, x_minus_2: {x_minus_2:.3f}\")\n",
    "print(f\"xhat_plus_2: {xhat_plus_2:.3f}, xhat_minus_2: {xhat_minus_2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Visualize the light-cone energy-momentum Lund plane\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "\n",
    "# Define the transformation (rotate by 45 degrees)\n",
    "transform = Affine2D().rotate_deg(45)\n",
    "helper = GridHelperCurveLinear(transform, extremes=(0, 1, 0, 1))\n",
    "ax = FloatingSubplot(fig, 111, grid_helper=helper)\n",
    "fig.add_subplot(ax)\n",
    "\n",
    "# Create auxiliary axis to plot in original coordinates\n",
    "aux_ax = ax.get_aux_axes(transform)\n",
    "\n",
    "# Axis labels\n",
    "ax.axis[\"left\"].label.set_text(r\"$\\hat{x}^-$\")\n",
    "ax.axis[\"left\"].label.set_size(17)\n",
    "ax.axis[\"left\"].label.set_rotation(0)\n",
    "ax.axis[\"left\"].label.set_pad(25)\n",
    "\n",
    "ax.axis[\"bottom\"].label.set_text(r\"$\\hat{x}^+$\")\n",
    "ax.axis[\"bottom\"].label.set_size(17)\n",
    "ax.axis[\"bottom\"].label.set_pad(15)\n",
    "ax.axis[\"bottom\"].major_ticklabels.set_rotation(270)\n",
    "\n",
    "# Draw a dotted line at xhat_plus_1 and xhat_minus_1\n",
    "aux_ax.plot(\n",
    "    [xhat_plus_1, xhat_plus_1], [0, 1], linestyle=\"--\", color=\"red\", linewidth=0.5\n",
    ")\n",
    "aux_ax.plot(\n",
    "    [0, 1], [xhat_minus_1, xhat_minus_1], linestyle=\"--\", color=\"red\", linewidth=0.5\n",
    ")\n",
    "\n",
    "aux_ax.plot(\n",
    "    [xhat_plus_2, xhat_plus_2], [0, 1], linestyle=\"--\", color=\"blue\", linewidth=0.5\n",
    ")\n",
    "aux_ax.plot(\n",
    "    [0, 1], [xhat_minus_2, xhat_minus_2], linestyle=\"--\", color=\"blue\", linewidth=0.5\n",
    ")\n",
    "\n",
    "# Plot a point at (0.7, 0.1) using unrotated coordinates\n",
    "aux_ax.plot(xhat_plus_1, xhat_minus_1, \"o\", markersize=5, color=\"red\")\n",
    "aux_ax.plot(xhat_plus_2, xhat_minus_2, \"o\", markersize=5, color=\"blue\")\n",
    "\n",
    "# Add grid\n",
    "ax.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "ax.set_aspect(\"equal\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rinse and repeat. Eventually we will get to a point where energy and momentum conservation of the outgoing hadrons should creep up on us. For example, we will eventually reach a point where the remaining string mass is too small to produce any hadrons that we have access to - we should stop the fragmentation chain before we get here so we can maybe do something a little smarter. A possibly good condition would be to stop right around when the remaining area is roughly the size of two of the largest hadron masses that we can produce (remember, the last vertex that we select is actually producing the **final two** hadrons), which in our case, is just two pions\n",
    "$$\n",
    "\\hat{x}^+_n(1 - \\hat{x}^-_n)M^2 \\approx (2m_\\pi)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iterative_fragmentation"
   },
   "source": [
    "### Iterative fragmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we implement the full algorithm, we need to be able to convert from the momentum fractions to (in principle observable) hadron four-momenta. Consider the four-vectors\n",
    "$$\n",
    "P_{q/\\bar{q}}^{\\mu} \\equiv E(1, 0, 0, \\pm 1)\n",
    "$$\n",
    "(in our language these are just four-momenta of the $q\\bar{q}$ system that we initialize in `QQBarString` as `self.q_p`. `self.qbar_p`), and remember that the $i$-th ($i \\in 1, ..., N_h$) hadron coordinate can be described generically by\n",
    "$$\n",
    "x_{i}^+ = \\hat{x}_{i-1}^+ - \\hat{x}_i^+,\n",
    "$$\n",
    "$$\n",
    "x_{i}^- = \\hat{x}_i^- - \\hat{x}_{i-1}^-\n",
    "$$\n",
    "with $\\hat{x}^+_0 = 1, \\hat{x}^-_0 = 0$. The hadron momentum is then fully described by the system of equations\n",
    "$$\n",
    "  \tp^\\mu_{i} = x_{i}^+ P^\\mu_q + x_{i}^- P^\\mu_{\\bar{q}}\n",
    "$$\n",
    "or simply\n",
    "$$\n",
    "    E_{i} = E(x^+_{i} + x^-_{i}), \\hspace{0.3in} p_{z, i} =  E(x^+_{i} - x^-_{i})\n",
    "$$\n",
    "constrained by the condition\n",
    "$$\n",
    "    m_{i}^2 = p_{i}^2 = x^+_{i}x^-_{i} M^2.\n",
    "$$\n",
    "In practice, given the mass of the new hadron $m_{i}$ and longitudinal momentum fraction $z_i$, we'll compute the new vertex $i$ via\n",
    "$$\n",
    "    x^{+}_{i} = z^{+}_{i}\\prod_{j=1}^{i-1}(1-z^{+}_j) \\quad \\text{for } \\,\\, i > 1\n",
    "$$\n",
    "$$\n",
    "    x^{-}_{i} = \\frac{m^2_{i}}{x^{+}_{i}M^2}\n",
    "$$\n",
    "where $z^{+}_0 = 0$. Finally, the position ($\\hat{x}^+_i, \\hat{x}^-_i$) of the $i$-th vertex can also be found recursively using the expressions above\n",
    "$$\n",
    "\\hat{x}^+_i = \\hat{x}^+_{i-1} - x_i^+ = (1 - z_i) \\hat{x}^+_{i-1}\n",
    "$$\n",
    "$$\n",
    "\\hat{x}^-_i = \\hat{x}^-_{i-1} + x_i^-.\n",
    "$$\n",
    "\n",
    "Let's build out a `StringFragmentation` class below that will take as input `QQBarString`, `StringFlav`, and `StringZ` instances and recursively fragment the string system resulting in an event record consisting of hadron four-momenta."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class StringFragmentation:\n",
    "    def __init__(self, QQBarString, StringFlav, StringZ, ParticleDatabase):\n",
    "        \"\"\"\n",
    "        Initialize the Hadronization class with a QQBarString and particle database.\n",
    "        \"\"\"\n",
    "        self.qqbar = QQBarString\n",
    "        self.string_z = StringZ\n",
    "        self.flav_sel = StringFlav\n",
    "        self.pdb = ParticleDatabase\n",
    "\n",
    "        # Initialize the event records\n",
    "        self.event_record = np.array([self.qqbar.q, self.qqbar.qbar])\n",
    "\n",
    "        # Initialize arrays for our light-cone coordinates\n",
    "        self.x_plus = np.array([])\n",
    "        self.x_minus = np.array([])\n",
    "        self.xhat_plus = np.array([1.0])\n",
    "        self.xhat_minus = np.array([0.0])\n",
    "\n",
    "        # Initialize arrays for z values\n",
    "        self.z = np.array([0.0])\n",
    "\n",
    "        # Since we're starting from the positive end we can initialize the first string end id\n",
    "        self.end_id = self.qqbar.q.data.pid\n",
    "\n",
    "    def fragment(self, end_id):\n",
    "        \"\"\"\n",
    "        Perform a single fragmentation step.\n",
    "        \"\"\"\n",
    "        # Select a flavor for the new hadron\n",
    "        new_string_end, output_hadron = self.flav_sel.select_flavor(end_id)\n",
    "        # Sample z\n",
    "        z = self.string_z.zLund(output_hadron.mass)\n",
    "\n",
    "        return z, output_hadron, new_string_end\n",
    "\n",
    "    def hadronize(self):\n",
    "        \"\"\"\n",
    "        Recursively hadronize the string.\n",
    "        \"\"\"\n",
    "        # Fragment the string\n",
    "        z, output_hadron, new_string_end = self.fragment(self.end_id)\n",
    "\n",
    "        # Record z and x_+/-, xhat_+/-\n",
    "        self.z = np.append(self.z, z)\n",
    "        self.x_plus = np.append(self.x_plus, z * np.prod(1 - self.z[:-1]))\n",
    "        self.x_minus = np.append(\n",
    "            self.x_minus, output_hadron.mass**2 / (self.x_plus[-1] * self.qqbar.M2)\n",
    "        )\n",
    "        self.xhat_plus = np.append(self.xhat_plus, self.xhat_plus[-1] - self.x_plus[-1])\n",
    "        self.xhat_minus = np.append(\n",
    "            self.xhat_minus, self.xhat_minus[-1] + self.x_minus[-1]\n",
    "        )\n",
    "\n",
    "        # Add the new hadron to the event record\n",
    "        E_i = self.qqbar.E * (self.x_plus[-1] + self.x_minus[-1])\n",
    "        pz_i = self.qqbar.E * (self.x_plus[-1] - self.x_minus[-1])\n",
    "        p_i = FourVector(E_i, 0, 0, pz_i)\n",
    "        # At new Particle instance to the event record\n",
    "        self.event_record = np.append(\n",
    "            self.event_record,\n",
    "            Particle(data=ParticleDatabase[output_hadron.name], p=p_i, h=0.0),\n",
    "        )\n",
    "\n",
    "        # Set the new string end id\n",
    "        self.end_id = new_string_end.pid\n",
    "\n",
    "        # If the final vertex goes into an unphysical region, pop the last vertex and terminate\n",
    "        if self.xhat_minus[-1] > 1.0 or self.xhat_plus[-1] < 0.0:\n",
    "            # Pop the last vertex from all arrays and return\n",
    "            self.xhat_plus = self.xhat_plus[:-1]\n",
    "            self.xhat_minus = self.xhat_minus[:-1]\n",
    "            self.x_plus = self.x_plus[:-1]\n",
    "            self.x_minus = self.x_minus[:-1]\n",
    "            self.z = self.z[:-1]\n",
    "            self.event_record = self.event_record[:-1]\n",
    "            return\n",
    "        # Check the stopping condition\n",
    "        elif (\n",
    "            self.xhat_plus[-1] * (1 - self.xhat_minus[-1]) * self.qqbar.M2\n",
    "            < (2 * self.pdb[\"pi+\"].mass) ** 2\n",
    "        ):\n",
    "            return\n",
    "        else:\n",
    "            self.hadronize()\n",
    "\n",
    "    def neuralize(self):\n",
    "        \"\"\"\n",
    "        Reset the string fragmentation state (sorry for the MIB reference).\n",
    "        \"\"\"\n",
    "        self.event_record = np.array([self.qqbar.q, self.qqbar.qbar])\n",
    "        self.x_plus = np.array([])\n",
    "        self.x_minus = np.array([])\n",
    "        self.xhat_plus = np.array([1.0])\n",
    "        self.xhat_minus = np.array([0.0])\n",
    "        self.z = np.array([0.0])\n",
    "        self.end_id = self.qqbar.q.data.pid"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "e = 3.0  # GeV\n",
    "stringZ = StringZ()\n",
    "stringFlav = StringFlav(ParticleDatabase)\n",
    "qqbar = QQBarString(Eq=e, Eqbar=e, ParticleData=ParticleDatabase[\"u\"])\n",
    "stringFrag = StringFragmentation(qqbar, stringFlav, stringZ, ParticleDatabase)\n",
    "stringFrag.hadronize()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"z:\\n\", stringFrag.z, \"\\n\")\n",
    "print(\"xhat_plus:\\n\", stringFrag.xhat_plus, \"\\n\")\n",
    "print(\"xhat_minus:\\n\", stringFrag.xhat_minus, \"\\n\")\n",
    "print(\"x_plus:\\n\", stringFrag.x_plus, \"\\n\")\n",
    "print(\"x_minus:\\n\", stringFrag.x_minus)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"Hadronizing system:\\n\")\n",
    "print(qqbar, \"\\n\")\n",
    "\n",
    "print(\"Event record:\\n\")\n",
    "for event in stringFrag.event_record:\n",
    "    name = event.data.name\n",
    "    p = event.p\n",
    "    print(\n",
    "        f\"{name:>6}: (E={p[0]:.3f}, px={p[1]:.3f}, py={p[2]:.3f}, pz={p[3]:.3f}, m={np.sqrt(p[0]**2 - p[1]**2 - p[2]**2 - p[3]**2):.3f})\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Visualize the light-cone energy-momentum Lund plane\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "\n",
    "# Define the transformation (rotate by 45 degrees)\n",
    "transform = Affine2D().rotate_deg(45)\n",
    "helper = GridHelperCurveLinear(transform, extremes=(0, 1, 0, 1))\n",
    "ax = FloatingSubplot(fig, 111, grid_helper=helper)\n",
    "fig.add_subplot(ax)\n",
    "\n",
    "# Create auxiliary axis to plot in original coordinates\n",
    "aux_ax = ax.get_aux_axes(transform)\n",
    "\n",
    "# Axis labels\n",
    "ax.axis[\"left\"].label.set_text(r\"$\\hat{x}^-$\")\n",
    "ax.axis[\"left\"].label.set_size(17)\n",
    "ax.axis[\"left\"].label.set_rotation(0)\n",
    "ax.axis[\"left\"].label.set_pad(25)\n",
    "\n",
    "ax.axis[\"bottom\"].label.set_text(r\"$\\hat{x}^+$\")\n",
    "ax.axis[\"bottom\"].label.set_size(17)\n",
    "ax.axis[\"bottom\"].label.set_pad(15)\n",
    "ax.axis[\"bottom\"].major_ticklabels.set_rotation(270)\n",
    "\n",
    "# Create a colormap with distinct colors based on the number of vertices\n",
    "num_vertices = len(stringFrag.xhat_plus)\n",
    "colors = plt.cm.rainbow(np.linspace(0, 1, num_vertices))\n",
    "\n",
    "for i, (xhat_plus, xhat_minus) in enumerate(\n",
    "    zip(stringFrag.xhat_plus, stringFrag.xhat_minus)\n",
    "):\n",
    "    # Draw a dotted line at xhat_plus and xhat_minus\n",
    "    aux_ax.plot(\n",
    "        [xhat_plus, xhat_plus], [0, 1], linestyle=\"--\", color=colors[i], linewidth=0.5\n",
    "    )\n",
    "    aux_ax.plot(\n",
    "        [0, 1], [xhat_minus, xhat_minus], linestyle=\"--\", color=colors[i], linewidth=0.5\n",
    "    )\n",
    "    # Plot a point at (xhat_plus, xhat_minus) using unrotated coordinates\n",
    "    aux_ax.plot(xhat_plus, xhat_minus, \"o\", markersize=5, color=colors[i])\n",
    "\n",
    "# Add grid\n",
    "ax.grid(True, linestyle=\"--\", alpha=0.2)\n",
    "\n",
    "ax.set_aspect(\"equal\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Let's also create a 2d histogram of an ensemble of xhat_plus and xhat_minus values\n",
    "nevents = 10000\n",
    "xhat_plus_values = np.array([])\n",
    "xhat_minus_values = np.array([])\n",
    "\n",
    "# Initialize the string fragmentation instance\n",
    "stringFrag_i = StringFragmentation(qqbar, stringFlav, stringZ, ParticleDatabase)\n",
    "\n",
    "for i in range(nevents):\n",
    "    # Reset the state for each event\n",
    "    stringFrag_i.neuralize()\n",
    "    # Hadronize the string\n",
    "    stringFrag_i.hadronize()\n",
    "    # Append all of the xhat_plus and xhat_minus values to the arrays (flattened)\n",
    "    xhat_plus_values = np.append(xhat_plus_values, stringFrag_i.xhat_plus[1:])\n",
    "    xhat_minus_values = np.append(xhat_minus_values, stringFrag_i.xhat_minus[1:])"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig = plt.figure(figsize=(6, 6))\n",
    "\n",
    "# Define the transformation (rotate by 45 degrees)\n",
    "transform = Affine2D().rotate_deg(45)\n",
    "helper = GridHelperCurveLinear(transform, extremes=(0, 1, 0, 1))\n",
    "ax = FloatingSubplot(fig, 111, grid_helper=helper)\n",
    "fig.add_subplot(ax)\n",
    "\n",
    "# Create auxiliary axis to plot in original coordinates\n",
    "aux_ax = ax.get_aux_axes(transform)\n",
    "\n",
    "# Axis labels\n",
    "ax.axis[\"left\"].label.set_text(r\"$\\hat{x}^-$\")\n",
    "ax.axis[\"left\"].label.set_size(17)\n",
    "ax.axis[\"left\"].label.set_rotation(0)\n",
    "ax.axis[\"left\"].label.set_pad(25)\n",
    "\n",
    "ax.axis[\"bottom\"].label.set_text(r\"$\\hat{x}^+$\")\n",
    "ax.axis[\"bottom\"].label.set_size(17)\n",
    "ax.axis[\"bottom\"].label.set_pad(15)\n",
    "ax.axis[\"bottom\"].major_ticklabels.set_rotation(270)\n",
    "\n",
    "_, _, _, hist_xhat_pm = aux_ax.hist2d(\n",
    "    xhat_plus_values, xhat_minus_values, bins=50, range=[[0, 1], [0, 1]], cmap=\"viridis\"\n",
    ")\n",
    "# Add a colorbar\n",
    "cbar = fig.colorbar(hist_xhat_pm, ax=ax, orientation=\"vertical\", fraction=0.04, pad=0.1)\n",
    "cbar.set_label(\"Counts\", size=14)\n",
    "\n",
    "ax.set_aspect(\"equal\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll see above that the vertices seem to follow some sort of hyperbolic distribution - this can be traced back to some interesting physics! Generically, the unnormalized probability for a string break to fragment into an $n$-particle final state is given by\n",
    "$$\n",
    "dP_n = \\prod_{j = 1}^n N_j dp_j \\delta(p_j^2 - m_j^2) \\delta\\left( \\sum_{j=1}^n p^\\mu_j - P^\\mu_{\\text{string}} \\right) \\exp(-b \\mathcal{A})\n",
    "$$\n",
    "where $\\mathcal{A}$ represents the area spanned by the string before the breakup. The probability roughly factorizes into the product of $n$-body phase space with an exponential area suppression. This competition leads to an interesting compromise. On one hand, phase space wants to pack in as many hadrons as possible \u2014 which tends to push fragmentation vertices closer together in time. On the other hand, the exponential suppression penalizes any configuration that sweeps out too much area \u2014 i.e., configurations where hadrons are produced too far apart in time or space. The balance point turns out to be when each breakup contributes roughly the same invariant area. That is, the most probable configurations are those where the fragmentation vertices lie along curves of constant invariant time:\n",
    "$$\n",
    "\\tau^2 = t^2 - z^2 = \\text{const}.\n",
    "$$\n",
    "These hyperbolae strike a balance between maximizing multiplicity and minimizing total area. Physically, this means that the string fragments in a boost-invariant fashion.\n",
    "\n",
    "This structure has important observable consequences, for example the coordinate-space rapidity of a vertex is defined as\n",
    "$$\n",
    "\\eta = \\frac{1}{2} \\ln\\left(\\frac{t + z}{t - z}\\right),\n",
    "$$\n",
    "and since the vertices lie along a fixed $\\tau$, their density in $\\eta$ is approximately uniform.\n",
    "\n",
    "This geometric picture is also encoded in our **Lund plane** that we constructed above. To see this we introduce the the the squared invariant time (from the origin of the initial $q\\bar{q}$ pair) to a string break vertex\n",
    "$$\n",
    "\\Gamma = (\\kappa \\tau)^2 = \\kappa^2 (t^2 - x^2 - y^2 - z^2).\n",
    "$$\n",
    "In the energy-momentum picture, this is simply given by\n",
    "$$\n",
    "\\Gamma_i = (\\hat{x}^+_i P^+ + \\hat{x}^-_i P^-)^2 = \\hat{x}_i^+ \\hat{x}_i^- M^2,\n",
    "$$\n",
    "which corresponds geometrically to the string area in the backwards light cone of the vertex. The area suppression factor from above then becomes\n",
    "$$\n",
    "\\exp(-b \\mathcal{A}) = \\exp\\left(-b \\sum_i \\Gamma_i \\right).\n",
    "$$\n",
    "To avoid exponential suppression, the hadronization configurations will prefer for each $\\Gamma_i$ to small but roughly equal, i.e., each hadron is produced along a contour of constant $\\hat{x}^+ \\hat{x}^-$, which traces out a **hyperbola** on the unit square (as we see above!). This is a direct imprint of the same physical principle above: balancing the statistical pressure to produce many hadrons with the geometric penalty for large invariant area.\n",
    "\n",
    "Similar to the coordinate space rapidity, $\\eta$, we can clearly see that the momentum-space rapidity\n",
    "$$\n",
    "y = \\frac{1}{2} \\ln\\left(\\frac{E + p_z}{E - p_z}\\right) = \\frac{1}{2} \\ln\\left(\\frac{p^+}{p^-}\\right) = \\frac{1}{2} \\ln\\left(\\frac{x^+}{x^-}\\right)\n",
    "$$\n",
    "will also remain roughly constant i.e. the number of particles produced, $N$, per unit rapidity\n",
    "$$\n",
    "\\frac{dN}{dy} \\approx \\text{const}.\n",
    "$$\n",
    "To summarize, the area suppression sculpts the entire fragmentation pattern into hyperbolic structure that ensures boost invariance and a **flat rapidity distribution**. The latter was an experimental motivation for the Lund string model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we continue on to incorporating tranverse momentum, let's look at some observables."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Let's run many events and see what some observables look like\n",
    "n_events = 10000\n",
    "multiplicity = np.zeros(n_events)\n",
    "\n",
    "stringFrag_i = StringFragmentation(qqbar, stringFlav, stringZ, ParticleDatabase)\n",
    "for i in range(n_events):\n",
    "    # Reset the state for each event\n",
    "    stringFrag_i.neuralize()\n",
    "    # Hadronize the string\n",
    "    stringFrag_i.hadronize()\n",
    "    multiplicity[i] = len(stringFrag_i.event_record) - 2  # Subtract the two string ends"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "\n",
    "# Fix the number of bins to the min and max multiplicity\n",
    "mult_max = int(np.max(multiplicity))\n",
    "mult_min = int(np.min(multiplicity))\n",
    "\n",
    "# Construct a binning\n",
    "bins = np.arange(mult_min, mult_max + 1) + 0.5  # Add 0.5 to center the bins\n",
    "\n",
    "# Compute the average multiplicity\n",
    "avg_multiplicity = np.mean(multiplicity)\n",
    "\n",
    "# Plot histogram of multiplicity\n",
    "ax.hist(multiplicity, bins=bins)\n",
    "\n",
    "# Plot the average multiplicity as a vertical line\n",
    "ax.axvline(\n",
    "    avg_multiplicity,\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    label=rf\"$\\langle N_h \\rangle=$ {avg_multiplicity:.2f}\",\n",
    ")\n",
    "\n",
    "# Set labels and legend\n",
    "ax.set_xlabel(\"Hadron multiplicity\")\n",
    "ax.set_ylabel(\"Counts\")\n",
    "\n",
    "ax.legend(frameon=False)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "n_events = 10000\n",
    "rapidity = np.array([])\n",
    "# Define the rapidity function\n",
    "y = lambda x_plus, x_minus: 0.5 * np.log(x_plus / x_minus)\n",
    "\n",
    "stringFrag_i = StringFragmentation(qqbar, stringFlav, stringZ, ParticleDatabase)\n",
    "\n",
    "for i in range(n_events):\n",
    "    # Reset the state for each event\n",
    "    stringFrag_i.neuralize()\n",
    "    # Hadronize the string\n",
    "    stringFrag_i.hadronize()\n",
    "    # Compute rapidity for each hadron in the event record\n",
    "    for i, hadron in enumerate(stringFrag_i.event_record):\n",
    "        if i < 2:\n",
    "            continue\n",
    "        # Compute rapidity for the hadron\n",
    "        rapidity = np.append(\n",
    "            rapidity, y(stringFrag_i.x_plus[i - 2], stringFrag_i.x_minus[i - 2])\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "\n",
    "# Plot histogram of rapidity\n",
    "ax.hist(rapidity, bins=100, density=True, alpha=0.7)\n",
    "# Set labels\n",
    "ax.set_xlabel(r\"$y$\")\n",
    "ax.set_ylabel(\"Density\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We mentioned above that the rapidity distribution should be flat? What is going on? The caveat to the statements above is that they hold primarily in the limit of \"infinitely long\" or very massive strings. The reason for this is because the relation doesn't hold near the end of the string. Let's take a look at the scaling of the rapidity distribution as a function of the string mass."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "n_events = 5000\n",
    "rapidity = []\n",
    "# Define the rapidity function\n",
    "y = lambda x_plus, x_minus: 0.5 * np.log(x_plus / x_minus)\n",
    "\n",
    "# Let's see how the rapidity evolves with the mass of the string\n",
    "E = [5.0, 10.0, 25.0, 50.0]  # Gev\n",
    "\n",
    "for e in E:\n",
    "    qqbar = QQBarString(Eq=e, Eqbar=e, ParticleData=ParticleDatabase[\"u\"])\n",
    "    stringFrag_i = StringFragmentation(qqbar, stringFlav, stringZ, ParticleDatabase)\n",
    "    rapidity_e = []\n",
    "    for i in range(n_events):\n",
    "        # Reset the state for each event\n",
    "        stringFrag_i.neuralize()\n",
    "        # Hadronize the string\n",
    "        stringFrag_i.hadronize()\n",
    "        # Compute rapidity for each hadron in the event record\n",
    "        for j, hadron in enumerate(stringFrag_i.event_record):\n",
    "            if j < 2:\n",
    "                continue\n",
    "            # Compute rapidity for the hadron\n",
    "            rapidity_e.append(\n",
    "                y(stringFrag_i.x_plus[j - 2], stringFrag_i.x_minus[j - 2])\n",
    "            )\n",
    "    rapidity.append([rapidity_e])"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "\n",
    "# Plot histogram of rapidity\n",
    "for i, e in enumerate(E):\n",
    "    # Plot each rapidity distribution with a label\n",
    "    ax.hist(rapidity[i], bins=100, density=True, alpha=0.7, label=f\"$E = {e}$ GeV\")\n",
    "\n",
    "# Set labels and legend\n",
    "ax.set_xlabel(r\"$y$\")\n",
    "ax.set_ylabel(\"Density\")\n",
    "ax.legend(frameon=False)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "What_about_$p_T$?"
   },
   "source": [
    "## What about $p_T$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up until now we have worked exclusively in 1+1 dimensions with each string break (and therefore each hadron) having no transverse momenta. For a realistic hadronization simulation $p_T$ generation must be incorporated!\n",
    "\n",
    "In the Lund string model, each string break corresponds to the nonperturbative creation of a $q'\\bar{q}'$ pair from the vacuum. This is modeled as a quantum tunneling process through the linear confining potential of the string. According to the uncertainty principle, this pair can have non-zero momentum transverse to the string axis. Since they are produced locally, momentum conservation requires that the transverse momenta of the quark and antiquark be equal and opposite i.e. each string break introduces a local transverse momentum kick, with\n",
    "$$\n",
    "\\vec{k}_\\perp^{(q')} = -\\vec{k}_\\perp^{(\\bar{q}')}.\n",
    "$$\n",
    "The resulting hadron inherits this transverse momentum when a quark from one break and an antiquark from the next recombine.\n",
    "\n",
    "The tunneling probability for producing a quark of mass $m_q$ and transverse momentum $p_\\perp$ is given by the Schwinger-like exponential suppression:\n",
    "$$\n",
    "\\mathcal{P}(m_q, p_\\perp) \\propto \\exp\\left( -\\frac{\\pi (m_q^2 + p_\\perp^2)}{\\kappa} \\right)\n",
    "$$\n",
    "where $\\kappa \\sim 1\\,\\mathrm{GeV}/\\mathrm{fm} \\simeq 0.2\\,\\mathrm{GeV}^2$ is the string tension. Note that heavier quarks and large transverse momenta are exponentially suppressed. Thus, strange quark production is rarer than up/down, and charm production is highly suppressed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Algorithmic_overview_w/_$p_T$"
   },
   "source": [
    "## Algorithmic overview w/ $p_T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, the iterative algorithm only requires minimal changes and can be largely summarized with the transformation: $m^2 \\to m^2_\\perp \\equiv m^2 + p_T^2$ where $m_\\perp$ is the **transverse mass**.\n",
    "\n",
    "In light-cone coordinates, transverse momentum components completely factorize from the longitudinal components (they are orthogonal). All light-cone variable definition remain the same as defined previously with the key change coming from the on-shell condition:\n",
    "$$\n",
    "p^+ p^- = m^2 + p_T^2 \\equiv m_\\perp^2.\n",
    "$$\n",
    "Likewise, the momentum fractions become\n",
    "$$\n",
    "x^+ x^- = \\frac{m_\\perp^2}{M^2}.\n",
    "$$\n",
    "Because $p_T$ completely factorizes (in terms of it's generation) the $p_T$ of the $i$-th hadron can be computed recursively via the string end transverse momentum $\\vec{k}_T$\n",
    "$$\n",
    "\\vec{p}_{T,i} = \\vec{k}_{T,i} - \\vec{k}_{T, i-1}, \\quad \\text{with} \\quad \\vec{k}_{T,0} = 0.\n",
    "$$\n",
    "Clearly the first hadron will have the same $p_T$ as the first string break $\\vec{k}_{T,1}$, while the second hadron will inherit $p_T$ that is the vector sum of the first string break (whose conjugate end imparted some equal and opposite $\\vec{k}_T$ on the leftover string system) and the $\\vec{k}'_T$ of the new string break."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sampling_$z$"
   },
   "source": [
    "### Sampling $z$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the fragmentation happens longitudinally, the string area law (which governs hadron production probability) becomes sensitive to the full mass of the hadron, including transverse motion. So transverse momentum acts like an effective mass penalty - heavier hadrons or those with larger $p_T$ are suppressed. As you may have guessed, the fragmentation function becomes:\n",
    "$$\n",
    "f(z, p_\\perp^2) \\propto \\frac{1}{z}(1 - z)^a \\exp\\left( -b\\frac{m^2_\\perp}{z} \\right).\n",
    "$$\n",
    "Note that this implies that when determining kinematics, we first need to generate the string end transverse momentum components before determining the longitudinal component."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sampling_$p_T$"
   },
   "source": [
    "### Sampling $p_T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, the transverse momentum of the produced hadron is sampled **at each string break**, assuming that the distribution is azimuthally symmetric.\n",
    "\n",
    "The transverse momentum is sampled from a 2d Gaussian:\n",
    "$$\n",
    "f(\\vec{p}_\\perp = p_x,p_y) = \\mathcal{N}(p_x,0,\\sigma)\\mathcal{N}(p_y,0,\\sigma)\n",
    "\\quad \\text{with} \\quad \\sigma^2 \\approx \\frac{\\kappa}{\\pi}\n",
    "$$\n",
    "where $\\sigma$ is a tuneable parameter fit from experimental data. In PYTHIA, the default value is typically $\\sigma \\sim 0.3\\,\\mathrm{GeV}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Exercise"
   },
   "source": [
    "### Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, write a `StringPT` class to generate samples of transverse momentum and then modify `StringFragmentation` to incorporate $p_T$ generation."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Exercise"
   },
   "source": [
    "### Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout this tutorial we have chosen the Lund model parameters based off of the current PYTHIA defaults: `a = 0.68, b = 0.98, sigma = 0.335`. Change these parameters and investigate how this changes the observables of interest. Think about how you could set up an iterative tuning of these parameters if given experimental data. **Challenge:** Set up a mock tuning exercise using two simulated samples (of observables) at different parameterizations. Set one as the \"experimental\" dataset and the other as output from the simulation. See also the `tuning.ipynb` tutorial."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "**TBD**"
   },
   "source": [
    "# **TBD**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "**Energy-momentum_conservation_(the_$\\texttt{finalTwo}$_hadrons)**"
   },
   "source": [
    "## **Energy-momentum conservation (the $\\texttt{finalTwo}$ hadrons)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "**Gluons_as_string_\"kinks\"**"
   },
   "source": [
    "## **Gluons as string \"kinks\"**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "**Lund_string_model**",
    "Exercise:",
    "String_breaking",
    "Coordinates",
    "Flavor",
    "Exercise",
    "Kinematics",
    "The_Lund_fragmentation_function",
    "Algorithmic_overview",
    "Iterative_fragmentation",
    "What_about_$p_T$?",
    "Algorithmic_overview_w/_$p_T$",
    "Sampling_$z$",
    "Sampling_$p_T$",
    "Exercise",
    "Exercise",
    "**TBD**",
    "**Energy-momentum_conservation_(the_$\\texttt{finalTwo}$_hadrons)**",
    "**Gluons_as_string_\"kinks\"**"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}